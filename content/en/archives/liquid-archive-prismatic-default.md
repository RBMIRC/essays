---
title: "L'Archive Liquide"
subtitle: "Workshop Retcon Black Mountain, Ecole Nationale Supérieure de la Photographie, Arles"
author: "Sylvain Couzinet-Jacques"
date: "2025"
lang: fr
license: GPL-3.0-or-later
provenance: "Workshop ENSP Arles 2024, with Mabe Bethonico"
tags:
  - liquid-archive
  - prismatic-default
  - statistical-commons
  - generative-AI
  - photography
  - pedagogy
  - latent-space
  - model-collapse
  - _Benjamin
  - _Barthes
  - _Sontag
  - _Flusser
  - _Bauman
  - _Parikka
  - _Pasquinelli
  - _Crawford
  - _Stiegler
  - _Simondon
  - _Glissant
  - _Dewey
  - _Freire
  - _Ranciere
  - _Yuk-Hui
  - _Haraway
  - _Barad
  - _diffraction
  - _friction
  - _entropy
  - _liquidity
  - _prism
  - _statistical-unconscious
  - _proletarianization
  - _cosmotechnics
  - _technodiversity
  - _Black-Mountain-College
---


## Workshop at ENSP Arles, November 2024

by Sylvain Couzinet-Jacques

---

## Introduction: The Crisis of the Image as Political Crisis

### The Starting Point: A Pedagogical Experiment

This text proceeds from a pedagogical experiment—a workshop conducted with photography students confronting generative artificial intelligence tools for the first time within their curriculum. The initial intention was modest: to observe how young practitioners—whose training spans documentary heritage, fine art practices, performance, and post-internet approaches—would react when facing machines capable of producing images without referents. Documents from Black Mountain College served as the thread for collective conversations, but very few visual documents were used as support for the workshop.

What unfolded in this workshop far exceeded the scope of a technical introduction. It functioned as a developer, in the photographic sense of the term: it revealed, within the enclosed space of a classroom, the same symptoms observable at the scale of contemporary visual culture. A loss of political and intentional bearings. A liquefaction of documentary stakes and their social value. A retreat into familiar forms—aesthetic, communicational, engaged—not as affirmation but as refuge.

### The Question Organizing This Text

The question organizing this text is not: "Will AI replace photographers?"—a legitimate but insufficient economic question. Nor is it: "Are generated images art?"—an aesthetic question presupposing categories that may already be obsolete. The question is more fundamental: what becomes of the image when it loses its documentary function?

---

## From the Ontology of the Trace to the Phenomenology of Flow

This question—what is the image for?—does not call for a functional answer but for an inquiry into the nature of the bond between the sensible and the real. Following the genealogy of twentieth-century visual thought, we observe a major semantic shift: *the image passes from the status of vestige to that of vector*.

### The Aura and the Optical Unconscious (Benjamin)

For Walter Benjamin, the question of the image's utility is inseparable from its political use-value. The loss of the aura—"the unique apparition of a distance, however near it may be" (BENJAMIN, 1935/2000, p. 75)—is the price of technical reproducibility. But this loss opens the way to what Benjamin calls the *optical unconscious*: photography "makes visible this optical unconscious, just as psychoanalysis makes visible the instinctual unconscious" (BENJAMIN, 1931/2000, p. 301). The photographic image reveals structures of reality that the naked eye cannot grasp—decomposed movement, enlarged detail, spatial configurations invisible to ordinary perception. The optical unconscious revealed a materiality of the world that escaped the gaze.

In the context of generative AI, latent space appears as the terminal, mathematized form of this unconscious. But the shift is radical: it is no longer a matter of exploring the details of the physical world, but the invisible correlations within the mass of data. The optical unconscious becomes the statistical unconscious. What AI reveals is no longer a materiality of the world, but a logic of language and style that escapes individual consciousness.

This reversal is reflexive: in Benjamin, the machine helped see the real; in AI, the machine helps see the *pattern*. The image no longer serves to "unveil" nature but to "expose" the structure of our own collective representations. The eye no longer looks at the object—it looks at the way culture has looked at the object. The image no longer testifies to distance; it renders "proximal" what is statistically probable.

### The Adherent Referent and Bodiless Spectrality (Barthes)

For Roland Barthes in *Camera Lucida*, the photographic image is a "bizarre medium, a new form of hallucination" (BARTHES, 1980, p. 177) because it compels the mind to admit the past existence of the object. The noeme of photography is the "That-has-been": "what I see has been there" (BARTHES, 1980, p. 120). The image serves as a certificate of presence, an ontological proof where the referent "adheres" to the sensitive surface. The Barthesian image is an emanation of the referent—the photons that touched the subject touched the film. It is this physical chain that grounds the "gentle death" of photography: it preserves the trace of a body that has existed.

Facing *the liquid archive*, this adherence dissolves. The AI-generated image is a "That-could-have-been." It no longer certifies a presence but a likelihood. More radically: the AI image is an emanation of the *dataset*, not the referent. It is spectral—it possesses the appearance of life (texture, grain, light) without ever having had a body. What we lose is not only "truth"; it is the flesh of time.

We pass from the image-as-memory to the image-as-prediction—an image that no longer looks toward the past but toward the probability distribution of the future. The image-as-prediction evacuates human finitude in favor of a statistical eternity. It is no longer indexed to a moment that occurred but to a space of possibilities without a date.

### The Image as Predation and Cognitive Extractivism (Sontag)

Susan Sontag radicalizes the approach by making the image an instrument of accumulation. "To photograph is to appropriate the thing photographed" (SONTAG, 1977/1979, p. 14); it is to transform the world into an "anthology of images" that ends up replacing direct experience. The image serves to manage the real through the frame—it cuts, selects, possesses. This is what we might call an ethics of the frame: the photographer exercises power over what they choose to show.

In the era of what I call *statistical commons*, we pass from this ethics of the frame to an economy of extraction. It is no longer the photographer who appropriates a particular subject; it is the model—via the scraper that collects training data—that appropriates all the gestures of vision to transform them into algorithmic capital. The photographer is no longer the one who takes a photo; they are the one who generates data. Predation is no longer exercised on the photographed subject but on the creative gesture itself, which is "aspirated" to train its own algorithmic replacement.

The image no longer serves to know the world but to feed the machine that will simulate it. Predation becomes extraction; the photographer becomes a resource. This is the logic of cognitive capitalism applied to the visual: each image produced feeds a latent space whose benefits are privatized by model owners.

### The Pivot: The Image-Program (Flusser)

The philosopher Vilém Flusser is the missing link between analog photography and *the liquid archive*. In *Towards a Philosophy of Photography*, he argues that technical images are "a new kind of abstraction," produced by apparatuses, and that their supposed objectivity "conceals their nature as symbols that encode concepts" (FLUSSER, 1983/1996, p. 17). For Flusser, the technical image is not a reflection of the world but the product of an apparatus—a device whose programmed possibilities the photographer explores. "Photographers do not work, they play" with the combinations offered by their camera's program (FLUSSER, 1983/1996, p. 28).

This intuition finds its culmination in generative AI. *The liquid image* no longer needs an external referent; it is merely the manifestation of a black box exploring its own internal limits. The image no longer serves to represent—it serves to iterate. It is a token in a probabilistic game, one actualization among billions of possible actualizations in latent space. The Flusserian photographer, who played against the apparatus to reveal its hidden potentialities, becomes the prompter—one who formulates requests to a program whose rules they do not master and whose power they feed with every use.

---

## What We Lose: The Desubjectivation of the Gaze

If we cross these four perspectives, we can map what the image loses in its transition to latent space. What is at stake is a progressive desubjectivation: the subject who looks, who frames, who decides, who testifies, finds themselves dispossessed of their prerogatives.

From Benjamin, we lose the exploration of the real for an exploration of language. The optical unconscious revealed the hidden structures of the physical world; the statistical unconscious reveals only the correlations of the dataset—that is, the way we have collectively represented the world, not the world itself.

From Barthes, we lose the attestation of the past for the suggestion of the probable. The "That-has-been" fades in favor of the "That-could-be"—the index gives way to the simulacrum. More profoundly: we lose the flesh of time, that physical emanation of a body that has existed, in favor of a spectrality without referent.

From Sontag, we lose the capture of the subject for the extraction of data. The photographer's power over their subject becomes the model's power over all photographers. The ethics of the frame—which presupposed a responsibility toward the visible—gives way to an economy of extraction where the creative gesture itself is the exploited resource.

From Flusser, we lose the game against the apparatus for submission to the program. The photographer who diverted their Kodak to produce the unexpected becomes the prompter who feeds the model without understanding its rules—and who, in doing so, contributes to training their own obsolescence.

The testimonial function collapses. Since the nineteenth century, the photographic image has served as proof in trials, as document in archives, as testimony in journalism. This function rested on a social trust in the indexicality of the trace. Generative AI makes this trust impossible—not because all images become false, but because every image becomes suspect. The regime of belief collapses.

The memorial function dissolves. Flusser defined the technical image as a tool for fighting entropy—a way of fixing the flow of time. The family album, the photographic archive, the documentary collection: so many devices that allowed the constitution of a transmissible collective memory. The generic image, produced on demand and disposable, does not constitute memory. It participates in what Bernard Stiegler called the proletarianization of knowledge: these technologies "currently function as instruments that deprive brains of their consciousness, that is, of their relation to knowledge" (STIEGLER, cited by CASSOU-NOGUÈS, 2024). But here, it is not only technical know-how that is lost—it is the know-how of seeing itself. If the apparatus sees for us and decides the probability of a form, it is our capacity to exercise aesthetic judgment that atrophies.

The critical function is neutralized. Jacques Rancière has shown that the image was a tool for the distribution of the sensible—"the system of self-evident facts of sense perception that simultaneously discloses the existence of something in common and the delimitations that define the respective parts and positions within it" (RANCIÈRE, 2000, p. 12). Documentary photography played this political role: it created dissensus, it disturbed the order of the visible.

Generative AI, by definition, is a consensus machine. It calculates the "average" of what a beautiful image is, a revolting image, a sad image. The distribution of the sensible becomes a smoothing of the sensible. The image no longer serves to create dissensus but to produce adhesion through "vibe"—that immediate aesthetic coherence that strikes without arguing. It shows what is already expected, what corresponds to the majority distribution. It does not disturb, it confirms.

---

## The Dialectic: What We Perhaps Gain

It would be too simple to stop at this account of loss. Generative AI also opens possibilities that traditional photography did not offer.

The liberation of the imaginary: Joan Fontcuberta, theorist of "post-photography," argues that the end of indexicality frees the image from its enslavement to the real. In *The Fury of Images*, he maintains that we have entered a regime where "images no longer testify, they construct" (FONTCUBERTA, 2017, p. 25). The image no longer has to prove, it can invent. It becomes a space of assumed fiction, of visual speculation, of exploration of possible worlds. For Fontcuberta, this is not a loss but a gain: photography was prisoner of its documentary function, the generative image emancipates itself from it.

The democratization of production: Anyone can now produce images of high technical quality without mastering traditional skills. One can see this as proletarianization in Stiegler's sense, or as democratization in the sense of an extension of access to the means of visual production. The question remains open: who really benefits from this democratization, and at what cost to the commons?

The exploration of latent space: Artists working with AI discover a new territory, latent space, that multidimensional mathematical space where concepts are encoded as vectors. Navigating this space means exploring the implicit correlations of the dataset, revealing biases, producing unexpected forms. It is a new form of visual serendipity—even if it remains constrained by the model's limits.

---

## The Thesis of This Text

The thesis of this text is that these apparent gains are compromised by a maladjustment between the technical plane and the political plane. Generative AI produces images, but it does not produce the conditions of their circulation, their interpretation, their contestation. It generates content, but not commons.

We propose to name this maladjustment: the *prismatic default*. The prism is an optical device that decomposes white light into a spectrum of colors—it reveals the plurality contained in the apparent uniform. But the prism is also, in our perspective, the tool of re-politicization. If *the liquid archive* is a "mush" where everything blends together, the prism is what reintroduces finitude and responsibility.

*The prismatic archive* does not merely store flows; it allows tracing back the chain of causalities. Who produced this data? What bias was applied? What perspective was crushed? It transforms "slop"—that generic content, the visual spam of the algorithmic era—into a diffracted object of study, whose layers and origins can be interrogated. The image is no longer an endpoint (a document), but an interface—a site of political and aesthetic tension.

But we must go further. *The prismatic archive* is not only a critical concept—it is itself a technique, with all the constitutive ambivalence that any technique entails. Simondon taught us that a technical object exists only in its associated milieu—the set of conditions, uses, and diversions that give it meaning. In this perspective, I propose to distinguish three regimes in which any technical archive simultaneously operates:

The regime of traceability: any archive implies a form of surveillance, of documentation, of gaze upon the world. *The prismatic archive* does not escape this dimension—it makes visible, it exposes, it preserves the possibility of inquiry.

The regime of transmission: any archive engages a relation to meaning that exceeds the utilitarian. It commemorates, it institutes a collective memory, it links the living to the dead and to future generations. There is in the archive a ritual dimension—not religious, but instituting.

The regime of bricolage: any archive is appropriable, divertible, reconfigurable. *The prismatic archive* is not a fixed protocol but a set of possible gestures, of situated practices, of unforeseen recombinations.

These three regimes do not exclude each other; they coexist in any living technique. To refuse one—for example, rejecting all traceability in the name of freedom, or all ritual in the name of efficiency—is to mutilate the other two. The prismatic archive assumes this triple condition.

It therefore assumes an ethical regime of its own—situated (it does not claim algorithmic universality), individuated (it constitutes itself in singular contexts, with identifiable actors), responsible (it can account for its choices).

This is how it opposes *the liquid archive*, whose ethical regime is precisely the absence of regime—the dissolution of all responsibility in the statistical flow. *The liquid archive* is that in which everything blends without distinction—a statistical mush where perspectives dissolve. Liquefaction is not the normal postmodern condition of the archive. It is the precise moment when the archive loses its prismatic dimension—that is, its political, collective, and reconfigurable dimension. It ceases to traverse the depth of human perspectives to circulate only on the surface of its own distributions.

If photography was the invention of a machine to stop time (the trace), generative AI is the invention of a machine to abolish the event (the flow). The passage from one to the other marks not only a technical evolution but the entry into a visual regime where the image, emptied of its documentary function, becomes the site of a struggle to maintain a prismatic dimension—the only one capable of saving the singularity of the gaze against the hegemony of the probable.


---

## Method and Structure

To analyze this default, we propose a method borrowed from Donna Haraway and Karen Barad: diffraction. Traditional critique of AI often operates in the mode of reflection—holding a mirror up to the machine to denounce its biases, errors, hallucinations. Diffraction, by contrast, concerns the interference patterns that arise when waves—here, computational knowledge and material reality—cross and mutually disturb each other. For Barad, diffraction is a device that "illuminates, exposes, and makes evident the entangled structure of the changing and contingent ontology of the world" (BARAD, 2007, p. 73).

Reflection asks: "Is this image true?" Diffraction asks: "What political and material entanglements produce this aesthetic?" This shift has consequences for analysis. We do not merely say that the liquid archive is "false" or "biased." We observe how it interacts with the world to produce new realities—how the amber aesthetic of AI begins to influence human photographers who try to imitate the algorithm to be visible on platforms. This is what Barad calls intra-actions: AI does not represent the world, it reconfigures it. Haraway, for her part, criticizes the god trick—the pretension to see from nowhere—and opposes to it "situated knowledges" that assume their positionality and responsibility (HARAWAY, 1988, p. 581).

This text proceeds in seven stages. It begins with a genealogy of machine vision, from James Bridle's "New Aesthetic" to Harun Farocki's "operational images" (I). It then analyzes latent space as an ungoverned commons, mobilizing the concept of *statistical commons* and Zygmunt Bauman's sociology (II). It describes platform physics and the mechanisms of cognitive extraction theorized by Matteo Pasquinelli (III). It examines the thermodynamics of culture—the phenomenon of *model collapse* and its aesthetic manifestations (IV). It then returns to the workshop experience as a revealer of these dynamics (V). It proposes paths toward an ecology of friction, mobilizing Édouard Glissant's "Right to Opacity" (VI). It concludes with a reflection on the ethics of generative image pedagogy, drawing on Dewey, Freire, Rancière, Simondon, and Stiegler (VII).

Four motifs traverse these seven sections and return at different scales: liquidity, entropy, friction, the prism. Their recurrence is not redundancy—it attempts to perform, in the writing itself, what a *prismatic archive* would be: each passage through the same concept illuminates it differently, enriches it with an additional layer.

---

## I. Genealogies of Machine Vision

### 1. *The Liquid Archive* Before AI: Carlos Amorales

Before becoming a theoretical concept applied to generative models, the term *Liquid Archive* designated an artistic practice. The Mexican artist Carlos Amorales developed in the late 1990s a bank of vector images—digital silhouettes detached from their original context, infinitely recombinable. For Amorales, the liquid archive is a reservoir of forms that can be assembled, superimposed, deformed, without reference to a stable original.

This artistic precedent illuminates the functioning of current generative models. Midjourney or Stable Diffusion operate a "vectorization" of the world analogous to Amorales's—but on an industrial and automated scale. They reduce complex works, charged with history and emotion, to recombinable statistical patterns. The fault is not technical, it is ontological: in becoming liquid, the archive destroys the singularity of the work to melt it into an undifferentiated flow.

The crucial difference: in Amorales, liquidity was an artist's gesture, conscious and deliberate. In the latent space of generative models, it is a structural property of the system—no one decided it, no one governs it.

### 2. The New Aesthetic as Prehistory of the Latent

In the early 2010s, James Bridle crystallized under the term *New Aesthetic* an empirical observation: the irruption of digital language into the physical world. Cushions with pixelated patterns, buildings designed to be read by satellites, military camouflage adopting fractal patterns. Bridle collected these artifacts on a Tumblr, without dogmatic manifesto—a rhizomatic gesture of documentation (BRIDLE, 2011-2013).

The New Aesthetic sought to make visible the invisible infrastructure. It gave sensible form to data flows, surveillance protocols, compression algorithms. The coarse green squares of Google Earth, supposed to represent agricultural fields but betraying the sensor's low resolution, became aesthetic objects revealing the technical mediation of our relationship to territory.

This observation joined Harun Farocki's work on operational images (FAROCKI, 2004) and Trevor Paglen's on "machine vision": images made by machines for machines, which no longer need the human eye to function (PAGLEN, 2016). Drone images, facial recognition systems, satellites—a visual regime where the human becomes an accidental spectator of a dialogue between apparatuses.

In a complementary perspective, Gwenola Wagon and Stéphane Degoutin documented in *World Brain* (2015) and *Globodrome* (2013) the materiality of digital infrastructures: data centers, undersea cables, logistics zones. Their visual archaeology of the *cloud* links the New Aesthetic to Parikka's *Geology of Media*—the digital is not immaterial, it has physical addresses and ecological costs.

But this aesthetic remained anchored in an indexical paradigm. The images, however glitched, still referred to a pre-existing reality. The satellite image, even pixelated, was a trace of a real geographical territory. The *glitch* was the accident that occurred to an original file during transmission. The machine saw the world—differently, certainly, but it was still looking at the world.

### 3. From Vision to Hallucination: The Post-Digital Shift

A decade later, the emergence of generative AI (Midjourney, Stable Diffusion, DALL-E) operates a radical shift. We are no longer in the regime of machine vision but in that of *machine hallucination*. The computer no longer processes visual *inputs*; it synthesizes new realities from statistical distributions.

This shift inverts Farocki and Paglen's schema. Operational images excluded the human from the visual circuit—machines speaking to machines. Generative AI, on the contrary, reintegrates the human into the dialogue, but by extracting them: what they think, what they say, what they have produced becomes raw material for the model. The prompt is a form of confession; generation, a statistical restitution of the collective imaginary. The human is no longer an accidental spectator—they are a resource.

This is the true meaning of the post-digital: not the after of the digital, but the moment when the digital turns back on its own conditions of production and begins to feed on itself. "Model Collapse" is not a technical accident—it is the terminal logic of this reversal. The artist Grégory Chatonsky has explored this entropic logic for two decades through the concept of telofossils—the traces our digital civilization will leave for future archaeologists. In *The Fourth Memory* (2025), an installation presented in the exhibition "The World According to AI" at the Jeu de Paume (curator: Antonio Somaini), Chatonsky uses the same diffusion models (Stable Diffusion XL, LAION-5B) analyzed here to produce a speculative archaeology of our present—turning the tool against itself to reveal its sediments. This gesture guarantees nothing: it exposes a condition, it does not resolve it.

The aesthetic of current AI is no longer defined by the visible pixel or the JPEG compression artifact—distinctive signs of the New Aesthetic—but on the contrary by hyper-resolution, supernatural smoothing, troubling semantic coherence. Where the New Aesthetic showed the seam between digital and physical, AI aesthetics seeks to erase all traces of mediation, producing perfect simulacra without referent in the real world.

### 4. The Aesthetics Wiki and Categorial Proliferation

A parallel phenomenon deserves interrogation: the emergence of the *Aesthetics Wiki*, a community encyclopedia listing more than a thousand identified and named "aesthetics"—Cottagecore, Dark Academia, Weirdcore, Liminal Space, Frutiger Aero (AESTHETICS WIKI, 2024). This wiki can be read as a late subdivision of the New Aesthetic, or as its compensatory reaction.

On one side, the wiki extends Bridle's gesture: to collect, name, make visible. But where the New Aesthetic sought to identify traces of the machine in the physical world, the Aesthetics Wiki maps vernacular styles born of platforms—aesthetics that often exist only as flows of tagged images, without identifiable authors, without canonical works.

On the other side, the wiki represents an attempt at taxonomic resistance against the post-categorial fluidity of latent space. It is discrete where the latent is continuous, hyper-categorial where the latent is mathematical, narrative where the latent is vectorial. The wiki has moreover banned AI-generated content in its community rules, affirming that AI does not possess the "cultural understanding" necessary (AESTHETICS WIKI, "AI Policy," 2024)—a political gesture of demarcation between intentional human creation and probabilistic synthesis.

But there is more. These categorizations—Cottagecore, Vaporwave, Liminal Space—are attempts to name ideological strands of pre-AI effects. They retrospectively fix visual tendencies that emerged before generative AI dissolved them in latent space. They are *taxonomic fossils*: traces of what the collective imaginary produced when it was not yet captured by models. In this sense, the Aesthetics Wiki is less a creation tool than a funerary monument—an archive of what could still be named.

This tension between categorial proliferation and latent dissolution traverses all contemporary visual culture. It poses a question this text does not pretend to resolve: who thinks aesthetics in 2025? What are the places, collectives, methods that still allow the production of concepts for what is happening to us visually? Classical critical theory (Adorno, Benjamin) was conceived for other image regimes. Cultural studies and visual studies struggle to keep up with the velocity of mutations. Platforms themselves generate their own vernacular metalanguage (*vibe, aesthetic, core*), but without a critical apparatus. The question remains open—and its urgency grows with each new model version.

### 5. The New Dark Age

James Bridle himself anticipated this evolution in *New Dark Age*. "The sheer volume of information available today reveals less than we hoped. It rather heralds a new Dark Age: a world of ever-increasing incomprehension" (BRIDLE, 2018, p. 3). The growing gap between the complexity of the systems we build and our cognitive capacity to understand them defines our contemporary condition. The opacity of deep neural networks introduces a "new aesthetics of politics." The question is no longer to see the pixels—anyway smoothed by *neural upscaling*—but to understand the invisible vectors, the latent biases, the probability architectures that govern the generation of our common reality.

> **First return of the motif: liquidity.** The archive is no longer a collection of visible objects on a Tumblr. It has become an invisible, multidimensional latent space—a flow without anchor points.

---

## II. Latent Space as Ungoverned Commons

### 1. Liquid Modernity and Its Sediments

Zygmunt Bauman, in his analysis of *Liquid Modernity*, describes the passage from a "solid" phase of history to a "fluid" phase. Social forms "can no longer [...] keep their shape for long" because they decompose faster than they can be adopted (BAUMAN, 2007, p. 1). In this state, power belongs no longer to those who control territory, but to those who control flows.

The liquid archive of generative models is the technological incarnation of this sociology. It is not constituted of fixed documents but of probabilistic vectors. "Knowledge" is not stored there; it is dynamically reconstituted with each query. This liquidity has a political consequence: the programmed obsolescence of memory. The liquid archive produces a *Forever Now* where forgetting is the condition of continuous adaptation.

However, this liquidity is deceptive. Jussi Parikka, in *A Geology of Media*, develops a "media history of matter" that articulates mineral extraction, digital infrastructures, and electronic waste (PARIKKA, 2015, p. 5). He makes media a mediation between ancient sedimentations and the "geology of waste" of the Anthropocene. The "cloud" is a metaphor that conceals a heavy geological reality. The liquid archive rests on the massive extraction of rare minerals, on data centers that consume considerable quantities of water and electricity, on networks of undersea cables. The archive is "liquid" not only because it is fluid, but because it liquefies planetary resources. It transforms fossil energy and drinking water into statistical tokens. The apparent immateriality of AI is supported by a crushing materiality.

### 2. Statistical Commons: From Code to Image

The concept of *statistical commons* that I attempted to define in the "Heredoc Manifesto" was developed to describe what occurs in the domain of code and text when language models are trained on massive corpora. The phenomenon is first textual: every line of published code, every technical documentation, every text put online involuntarily contributes to the training of LLMs. Private intellectual property is transformed, through the training process, into a shared probability distribution. Source code, protected by licenses, becomes a statistical *pattern* accessible to anyone with the model.

This commons constitutes itself automatically, without deliberation—unlike traditional commons (forests, pastures) subject to negotiated rules of collective use. There is no assembly of contributors, no protocol of reciprocity. Value circulates without politics. Recombination there is only probabilistic, never decisional—it reflects correlation, not negotiation.

The extension of this concept to the domain of the image requires caution. Diffusion models (Stable Diffusion, Midjourney) operate differently from LLMs: they do not predict the next token but progressively denoise an image from Gaussian noise. Yet the fundamental mechanism remains analogous: a massive corpus of images—photographic, pictorial, graphic—is compressed into probability distributions in latent space. The private image becomes common statistical texture. The question of governance of this commons arises with equal acuity.

### 3. The Liquid Archive as Prismatic Default

It is here that the notion of *liquid archive* takes its true meaning. It does not simply designate the fluidity of data circulation, characteristic of distributed networks. It designates the very nature of ontological storage in latent space: a continuous vectorial representation where concepts are no longer stored as distinct entities but as probabilities in suspension.

However—and this is the decisive inflection—this liquidity is not a neutral or natural condition. It is the symptom of a maladjustment between the technical plane and the political plane. The archive liquefies when it does not have the right political dimension—prismatic—that would allow its recombination.

The prism, unlike the liquid mirror, diffracts without dissolving. It is an adjustment device, an interface between dimensions. *The prismatic archive* would treat data not as turbulent flow but as recombinatory spectrum: each angle—social, aesthetic, economic, affective—would return a distinct color. Where the liquid archive confines itself to instantaneous circulation, the prismatic archive would construct an ecology of recursivity: a system where repetition always returns to a new angle of interpretation, not to redundancy.

Without governance, without prismatic adjustment, latent space tends toward uniformization. Variance diminishes. Diversity disappears. The model converges toward a dull average. The *statistical commons*—that mechanism by which probabilistic treatment transforms the private into shared resource—does exist, but it remains ungoverned, left to entropic forces.

---

## III. Platform Physics and the Anatomy of the Prism

### 1. The Nooscope: The Instrument of Ontological Reduction

Matteo Pasquinelli and Vladan Joler propose the concept of Nooscope to break the myth of AI as an autonomous entity. They describe AI not as an autonomous intelligence, but as an "instrument of knowledge amplification" that transforms masses of data into statistical models of perception (PASQUINELLI and JOLER, 2021, p. 1264). The Nooscope aims to "secularize AI from its ideological status as 'intelligent machine' to that of instrument of knowledge" (PASQUINELLI and JOLER, 2021, p. 1265). The Nooscope is not a telescope that extends vision; it is a diffraction instrument that reveals that AI does not "think"—it automates perception.

The mechanism is one of knowledge compression. The algorithm does not "see" an image; it detects statistical distributions of pixels—edges, textures, contrasts. It codifies a human cognitive task (recognizing a form, interpreting a context) to transform it into a statistical operation. In doing so, it operates what we might call a discrete epistemicide: by transforming qualitative perception—meaning, history, irony, social ambiguity—into quantitative distributions, the algorithmic prism eliminates everything that resists quantification.

The prismatic default arises here. The algorithmic prism is not a transparent pane; it is a device that only allows passage of what is quantifiable. What we call "bias" is not a system error but its fundamental logic: the imposition of a normative vision dictated by the average. AI is the "Master" because it holds the power to define the world's statistical "normality"—what is probable, what is expected, what is generable.

### 2. The Material Cost of the Statistical Commons

Pasquinelli and Joler's Nooscope reveals the epistemic logic of AI; it leaves its material infrastructure in shadow. Kate Crawford, in *Atlas of AI*, proposes a complementary cartography—no longer of data flows but of the extraction chains that make them possible (CRAWFORD, 2021).

The atlas begins with the earth. The GPUs that train diffusion models require cobalt (Democratic Republic of Congo), lithium (Chile, Argentina, Australia), rare earths (China). These extractions have documented human costs: child labor in artisanal mines, groundwater pollution, community displacement. The "cloud"—that aerial metaphor suggesting immateriality—rests on a heavy, extractive, unequally distributed geology.

The atlas continues with energy. The data centers hosting models consume massive quantities of electricity and cooling water. In 2022, Google's data centers consumed 21.2 billion liters of water—the equivalent of the annual consumption of 37 golf courses in Arizona. Training a single large language model emits as much CO2 as five cars over their entire lifespan. Each image generated by Midjourney or Stable Diffusion consumes approximately 2.9 Wh—a smartphone charge. Multiplied by the billions of daily generations, the footprint becomes vertiginous. The "light" image—that JPEG of a few megabytes—is energetically massive.

The atlas ends with labor. Crawford here joins Gray and Suri, but expands the frame. "Ghost work" is not only that of annotators and moderators; it is all the human labor that enters datasets without consent or compensation. Every photographer whose images were scraped for LAION-5B, every artist whose style was vectorized without permission, every user whose queries serve reinforcement training—all participate in what Crawford calls epistemic extractivism: the systematic appropriation of know-how and know-how-to-see for private infrastructures.

Hito Steyerl, artist and theorist, extends this analysis from practice. In *Duty Free Art*, she observes that the value of the digital image no longer resides in its content but in its circulation—what she calls "circulationism" (STEYERL, 2017, p. 47). The image does not need to be true, beautiful, or significant; it must circulate, generate engagement, feed recommendation algorithms. In her latest work, *Medium Hot: Images in the Age of Heat*, Steyerl radicalizes this diagnosis by introducing the concept of "derivative image": like financial derivatives, AI-generated images are statistical averages extracted from vast datasets, "social dreams without sleep" that reflect what society pays attention to—and nothing else (STEYERL, 2025). Slop—that yellowed and generic visual spam—is the logical product of this economy: an image optimized for circulation, emptied of all semantic friction, perfectly adapted to flow.

This image economy has a geography. Safiya Umoja Noble, in *Algorithms of Oppression*, shows that the biases of image search systems are not technical accidents but power structures (NOBLE, 2018). Queries for "beautiful woman" massively return images of white women; queries for "professional" systematically exclude certain bodies. These biases are encoded in datasets—which overrepresent Western, English-language, male content—and amplified by models that learn to reproduce majority distributions. The "yellowing" we described is only one symptom among others of a system that converges toward culturally situated averages presented as universal.

The statistical commons exists—this is a technical and juridical fact. As the phenomenon of GPL licenses in LLMs has shown, statistical treatment effectively transforms private property into collective resource: copyleft code, once ingested and redistributed by the model, statistically "contaminates" all outputs. This is the viral effect of free licenses extended to the era of machine learning. In this sense, the statistical commons is potentially emancipatory—it undoes the enclosures of intellectual property by the very fact of calculation.

But what Crawford, Steyerl, and Noble map are the conditions of production of this commons—and these indeed belong to a primitive accumulation. Kate Crawford defines AI as a "technology of extraction: from minerals pulled from the earth, from labor taken from underpaid workers, from data captured on every action and expression" (CRAWFORD, 2021, p. 15). Her project *Calculating Empires*, created with Vladan Joler and awarded the Silver Lion at the Venice Architecture Biennale 2025, maps this extractive genealogy over five centuries—showing that AI is not a rupture but the intensification of a long-duration colonial regime. Terrestrial resources, human labor, protected works, behavioral data—everything is aspirated into an extractive logic that precedes and enables statistical pooling. What is presented as "intelligence" is the product of a chain of appropriations whose costs are externalized to peripheries: the countries of the Global South that provide minerals and micro-labor, the communities that suffer pollution, the creators whose works are pillaged, the users whose attention is captured.

The prismatic default here takes an additional dimension. It is not the statistical commons itself that poses a problem—it is the systematic invisibilization of its conditions of production and the privatization of its benefits. The archive liquefies doubly: in its form (flow replaces document) and in its materiality (infrastructure disappears under the cloud metaphor). To reintroduce the prism is to make these extraction chains visible—and it is also to pose the question of governance: who decides the rules of use of the commons? Who shares its benefits?


### 3. The Blood Archive: Ghost Work and Extractivism

Behind the archive's liquidity hides a geopolitical solidity. As Mary L. Gray and Siddharth Suri emphasize in *Ghost Work*, the generative prism only functions thanks to the support of an invisible labor force—moderators, annotators, micro-workers who "clean" the liquid archive, label images, filter toxic content, correct hallucinations (GRAY and SURI, 2019, pp. 8-12). This labor is massive, underpaid, often offshored to the peripheries of world capitalism.

The asymmetry is structural: the transparency of the generated image—its smoothing, its perfection, its high resolution—is proportional to the opacity of the labor necessary to produce it. The system makes the image hyper-visible while striking with invisibility the millions of hands that sorted the data so that the "miracle" might operate.

Cognitive colonialism no longer bears only on bodies or raw materials, but on the faculty of judgment. Perception is extracted from precarious workers to "train" the model. Latent space is therefore produced by exploitation, even if the statistical commons it engenders—that mechanism by which probabilistic treatment transforms the private into shared resource—could be politically reappropriated. The prismatic default here is social: there is an aberration in the system that presents as "algorithmic magic" what is in reality the product of millions of hours of invisibilized human labor.

### 4. From Gravitation to Holography: Platform Physics

The concept of platform physics, developed by the collective New Models (Caroline Busta and Lil Internet), allows us to understand that the digital environment is not an empty space, but a force field. Lil Internet defines these "platform physics" as "the affordances, limitations, and laws governing the traction, velocity, visibility, and even permanence of an idea or piece of content" (NEW MODELS, 2025). Each platform possesses a set of hardcoded laws—sorting algorithms, interface limitations, reward systems—that determine user behavior and content morphology, as gravity determines the movement of bodies. Caroline Busta specifies that "platform physics and gamification force us to align with the interests of the platform, and any activity going against those interests will be punished" (NEW MODELS, 2025). This intuition joins the concept of mediarchy developed by Yves Citton: media regimes do not only transmit content, they structure attentional conditions and power relations (CITTON, 2017). Generative AI would then be a new form of mediarchy where power is exercised through the preemption of the imaginable.

The Newtonian era (Web 2.0) was founded on clear force vectors: the *like*, the share, the hyperlink. A physics of action and reaction, mechanical and predictable. Virality obeyed identifiable laws; polarization was a calculable effect.

The holographic era (AI) marks a shift toward a physics of simultaneity and entanglement. In a holographic medium, information is no longer a line (an article, an indexed photo), but a cloud of probabilities. Each generated image contains the "DNA" of the entire dataset. One no longer looks at a scene—one looks at a *vibe*, an aesthetic unit where the internal coherence of style prevails over the factual truth of the referent.

Linear media—from the printed book to early social web—were characterized by sequentiality (beginning, middle, end), causality (A causes B, sources are citable), indexation (content refers to a verifiable context). Holographic media dissolve these properties. Content is perceived as immediate totality; the origin of data is dissolved in model weights; information becomes ambient texture. An image generated by Midjourney is not "read" sequentially; it strikes as the instantaneous manifestation of a global style. The *vibe*—that immediate aesthetic coherence—becomes the vector of truth. One no longer argues, one resonates.

### 5. The Neural Narrative: The Occupation of the Possible

The political extension of this physics is the concept of *Neural Narrative*. If holographic media function by vibes and probabilities, the control of society no longer passes through censorship—erasing a linear fact—but through the optimization of statistical distributions in collective latent space.

Cognitive occupation operates through preemption. If a model is trained to consider that "photographer" is statistically associated with "white man," it becomes mathematically difficult, even impossible, to make another figure emerge in latent space without a deliberate effort of friction. Bias is not a punctual error—it is a confinement architecture where the future is already pre-calculated by the sediments of the past.

Power no longer consists in saying what is true, but in rendering certain thoughts statistically improbable. Latent space becomes an occupied territory: one circulates there, but the most practicable paths are those the model has learned to privilege. The "tails of distribution"—rare thoughts, strange forms, improbable associations—become zones of resistance, difficult to access but crucial.


---

## IV. Thermodynamics of Culture

LAION-5B contains more than 5.85 billion image-text pairs (SCHUHMANN et al., 2022)—several centuries of human photographic production, reduced to a few terabytes of neural weights. *The liquid archive* is not metaphorical: it is the effective dissolution of billions of singular images in a common statistical bath.

Yet this bath degrades. Model Collapse describes what happens when models are trained on synthetic data generated by previous models. Shumailov et al. speak of "model autophagy disorder"—a disorder of autophagy by analogy with prion diseases (SHUMAILOV et al., 2023). Models need high-variance data to learn the real distribution of the world; yet they tend by nature to smooth this distribution, to privilege the most probable results. After only five to seven generations of recursive training, the model produces "degenerate" results—a total loss of semantic nuance. Seven iterations suffice to transform a model capable of producing the diversity of the world into a machine for generating the same.

The process operates in two stages. First, the model loses the "tails" of the distribution—rare, marginal data. Minority aesthetics cease to be generable. Then variance converges toward zero: the model produces only a single, repetitive form. The liquid freezes.

This process has a visible aesthetic manifestation: Yellowing. Generated images tend toward a dominant yellow/amber tint, excessive saturation, hyper-contrasted lighting (HEIKKILA, 2023). The model, by mixing all colors to reach a consensual average, produces this muddy tint—like mixing all the paints on a palette yields brown. This yellowed and generic content has received a name: Slop—the visual spam of the AI era, the statistical hell of the "Mean."

Facing this physics of smoothing, friction becomes the only political lever. To reintroduce what the system eliminates: opacity (to claim, with Glissant, the right not to be understood by the machine), singularity (to seek the outliers that the model considers "noise"), gap (voluntary error, assumed ambiguity). Friction is no longer merely a method of resistance—it is the condition of possibility for a politics of the image in the era of statistical commons. Against yellowing, against the voiding of the middle, the prismatic dimension would allow decomposing the spectrum rather than melting it into amber mud.

---

## V. Case Study: The Workshop as Revealer

### 1. The Setup

The workshop took place in a photography school, with students trained in the indexicality of the image. But the setup was not limited to a technical introduction to generative tools. It was anchored in an approach of retroactive continuity—*retcon*, a term borrowed from popular culture (comic books, television series) where it designates the a posteriori rewriting of a narrative continuity.

The choice of Midjourney was not innocent. It responded to three criteria: a technological reference (at the time of the workshop, Midjourney represented the accessible state of the art in image generation), a pragmatic constraint (the remote Discord server avoided the hazards of local installations and guaranteed a homogeneous experience), and a symptomatic value (Midjourney embodies a certain *zeitgeist*—its saturated aesthetic, its ease of use, its virality make it the very image of what generative AI produces as dominant imaginary). The tool was not adopted with enthusiasm but observed critically—as one dissects a specimen to understand the ecosystem that produced it.

The starting point was Black Mountain College (1933-1957)—that hotbed of total experimentation where Josef and Anni Albers, John Cage, Ruth Asawa, and Dorothy Rockburne crossed paths. BMC was not convoked as a historical monument to contemplate, but as a latent archive to reactivate. The stake was to ask Midjourney to "complete" the archive, to imagine undocumented moments, possible bifurcations of the utopia. It was an attempt to test the "That-could-have-been" within a latent space nourished by the sediments of the avant-garde.

*Retcon*, here, was not historical falsification—it was conceived as a temporal diffraction: making the past (the BMC archive) and the present (Midjourney's latent space) interfere to observe interference patterns. What images does the model generate when asked to extend a pedagogical utopia of the 1950s? What does this generation reveal about dataset biases, about incorporated aesthetic sediments? The proposed framework was that of a graphic novel: the students would articulate their own questionings with the historical material of BMC.

### 2. The Archive's Resistance to Smoothing

The use of Midjourney very quickly revealed its structural limits. Confronted with the visual specificity of BMC—black-and-white photographs, the granularity of period prints, provisional architectures, bodies in movement in workspaces—the algorithm produced a form of entropic smoothing.

Where the BMC archive is made of grain, friction, accidents, and radical singularities, Midjourney returned "clean" simulacra, aestheticized and consensual versions. The experimental dimension—the tension between order and chaos that characterized the College's daily life—was flattened into nostalgic *vibes*, close to categories listed in the Aesthetics Wiki: a generic "Academia," a smoothed "Vintage Education." The machine could not generate friction; it generated decor.

The graphic novel framework was not invested by the students, and the invitation to personal research was taken literally. The use of AI transformed the experimental utopia into a series of decorative vignettes. The very principle of the prompt proved inadequate: how to formulate in a few words the complexity of a pedagogical project that articulated manual labor, artistic creation, democratic governance, and communal life? The prompt imposes a semantic compression that crushes precisely what made BMC's singularity—its total character, irreducible to keywords.

### 3. The Collapse of the Utopian Hearth

The most revealing tipping point of the workshop lies in the students' reception of the BMC narrative. The concept of "utopian hearth"—that place of total life and creation, where teaching and existence merged—did not operate as an engine of imagination. It was received with a form of polite perplexity, even suspicion.

For a generation confronted with the "Voiding of the Mid," the BMC utopia seems inaudible. AI's liquidity, by making everything "possible" and "immediate," dissolves the very notion of utopia—which requires a projection into a future constructed by effort, collective decision, long time. Utopia supposes a gap between the real and the desirable; latent space knows only variations around an average. When everything is equally probable, nothing is truly desirable.

The students did not perceive BMC as a model to follow or an imaginary to extend, but as a set of distant archives to be "processed"—in the technical sense of the term. The relationship to the past was instrumental, not spiritual. Here is where Yuk Hui's cosmotechnical dimension finds its pertinence: the link between the technical gesture and a world order was missing. The archive was manipulated, but not inhabited.

It would be too simple to conclude a "deficit of utopia" among the students. What manifested is subtler: a mistrust toward grand narratives of collective emancipation, a preference for individual tactics of survival (in Michel de Certeau's sense), a difficulty projecting a desirable commons. Black Mountain College, with its modernist optimism and its faith in social transformation through art, belongs to a regime of hope that is no longer self-evident. The workshop revealed this generational gap—without resolving it.

### 4. The Crisis of Intentionality: From Click to Prompt

Beyond the BMC setup, the workshop confirmed a crisis of intentionality proper to the use of generative tools. The students are trained in the decision of the instant—the famous "click," that moment when eye, body, and apparatus converge to fix a fraction of a second. Henri Cartier-Bresson spoke of the "decisive moment"; Robert Frank of the capacity to "see what others don't see." The entire documentary tradition rests on this economy of scarcity: one cannot photograph everything, one must choose.

Facing generative AI, this economy inverts. The "click" becomes the "prompt"—and the prompt is not an instantaneous decision but a deferred and iterative hyper-decision. One can ask for everything, reformulate everything, regenerate everything. Abundance replaces scarcity. Paradoxically, this inflation of possibilities does not liberate—it can paralyze.

What the workshop revealed is that hyper-choice produces a collapse of decisional capacity. Facing the liquid infinity of possible variations, the students mostly opted for two forms of retreat. On one hand, recourse to already identified aesthetics ("Liminal," "Cottagecore"), literal and descriptive representations ("a woman in a forest"), rarely kinetic images—that is, images caught in an intentional narrative, oriented by a project. On the other hand, and more strikingly still, an obsessive return to self-portrait—as if, facing the dissolution of criteria, the only remaining anchor was one's own face.

### 5. The Obsession with Self: The Statistical Mirror

This tendency toward self-representation deserves attention. It is not specific to the workshop: it traverses all photographic practices observed in art schools, exacerbated by social networks and selfie culture. But generative AI gives it a new and troubling dimension.

When a student asks Midjourney to generate "me in the style of...," they do not produce an image of themselves—they produce a statistical average of what the model associates with their prompt. The generated face is not theirs: it is a vectorial approximation, a composite of millions of faces encoded in latent space. The generative self-portrait is a distorting mirror that returns not the subject, but what the dataset "thinks" of the subject.

Yet this distortion is rarely perceived as such. The students often expressed satisfaction with these images—an "improved," "idealized" version of themselves. The model, by smoothing singularities toward the aesthetic average, produces faces conforming to beauty standards encoded in its training data. The generative self-portrait is not an exploration of self—it is a submission to the statistical norm disguised as personal expression.

This obsession with *self* reveals in negative the absence of project. When everything is possible but nothing resists, the subject falls back on the only certainty remaining: their own image. But this image, mediated by latent space, is already no longer theirs, and from an aesthetic crisis can come a destabilization difficult to overcome for the students.

### 6. From Witness to Curator: The Disembodiment of Gesture

In the documentary tradition, the photographer is a witness: they are present at the site, they look through the viewfinder, they physically carry the apparatus. Their body is engaged in the production of proof. Dorothea Lange walked through migrant camps; Robert Capa ran under bullets; Nan Goldin lived among her subjects. Documentary photography is an embodied practice.

Generative AI operates a radical disembodiment. The student no longer looks through the viewfinder—they sort flows on a screen. They no longer produce proof—they select among probabilities. The creative gesture shifts from production to curation. Yet "everything is possible" prevents the formation of decision. When five billion images are compressed in a vectorial space, by what criterion choose one rather than another? The photographic tradition offered criteria: light, frame, moment, relationship to subject. Generative AI dissolves these criteria in the model's statistical texture.

In the case of BMC, this disembodiment was all the more problematic because the College was precisely a place where the body was central: agricultural work, dance, building construction, collective meals. To try to extend this archive through the prompt was to deny the corporeal dimension that made its singularity—and to risk substituting for the embodied utopia a disembodied nostalgia, filtered through the model's aesthetic biases.

### 7. The Failure of the Glitch: The Neutralized Accident

Facing this liquidity, some students attempted a strategy of resistance: "hacking" the AI to recover accident, noise, the unexpected. The glitch—that visual error betraying the machine—has long functioned as proof of humanity by default: where the machine fails, the human can rush in.

But this strategy proved impracticable. Current generative models are precisely optimized to eliminate the glitch. Smoothing, hyper-resolution, semantic coherence: all engineering work aims to erase traces of the machine. The glitch, when it occurs (six-fingered hands, unreadable text), is not a creative opening—it is a bug that the next model version will correct.

The aesthetics of accident, which had nourished an entire segment of digital art (from *glitch art* to *datamoshing*), thus finds itself neutralized. Friction no longer emerges spontaneously from confrontation with the machine. It must be deliberately reintroduced—which supposes a critical consciousness that the generative tool, by its very fluidity, tends to dissolve.

### 8. The Prismatic Default in Action

This "failure"—if we must call it that—is in reality the workshop's most precious result. It manifests the prismatic default in its triple dimension:

The tool becomes a reductive filter. Midjourney acted as a defective prism that crushes the radical plurality of Black Mountain to bring it back to the statistical average. The archive's singularities—grain, tension, experimentation—were smoothed into decorative vignettes. The tool does not know how to diffract; it only knows how to average.

The method requires political channeling. *Retcon*, without an engagement of the body and an explicit "political channeling," is only a manipulation of pixels without memorial thickness. It remains on the surface—it is remix, not rewriting. Retroactive continuity supposes a position taken: why reactivate this archive? For whom? Against what? Without these questions, *retcon* is just image processing.

BMC's utopia liquefied because AI does not know how to generate the "radically unexpected"; it only knows how to generate the "comfortably probable." Utopia, by definition, is what has no (yet) place—what is statistically improbable. Latent space, optimized for the likely, can only miss utopia.

This triple default outlines, in negative, what a prismatic archive of Black Mountain College would be: an archive that would preserve grain against smoothing, that would articulate technical gestures to an explicit political project, that would maintain the utopian gap against the average. The workshop did not produce this archive—but it revealed the conditions of its possibility.

This is precisely its pedagogical success. The students did not learn to "use Midjourney"—they learned to read it, to identify its regimes of visibility and invisibility, to recognize in yellowing and smoothing the symptoms of a political economy of the image. They experienced, in their own practice, the difference between generating and creating, between selecting and deciding, between flow and gesture. Several explicitly chose, at the workshop's end, to reintroduce friction in their work—return to analog, refusal of post-processing, renewed attention to the off-frame. Others undertook to document the model's "failures" as so many revealers of its presuppositions. The tool, observed critically, became a diagnostic: not a means of producing images, but an analyzer of contemporary conditions of their production. In this sense, the workshop accomplished what Black Mountain College itself practiced: making apparent failure the site of real learning, transforming obstacle into method.


---

## VI. Toward an Ecology of Friction

### 1. The Prismatic Default as Diagnosis

*The liquid archive* is not an insurmountable horizon. It is the result of a specific maladjustment: the absence of a political dimension allowing the recombination of perspectives. The statistical commons exists—it is even massive, planetary, constantly expanding. But it is ungoverned, left to the forces of optimization and entropy.

Liquidity designates this loss of institutional thickness and collective regulation. It is not its fluidity in itself that matters, but the fact that it does not take form—for lack of a plane of aggregation and resistance. The danger is not liquidity but flatness: everything becomes flow, but no flow has political channeling.

*The prismatic archive* would aim at an energetic regulation of meaning: making visible and governable the interferences between layers—data, affects, histories. It would treat each perspective not as noise to be averaged but as a dimension to preserve. Concretely, this implies thinking protocols of contribution and recombination—rules of use for the statistical commons that are not dictated solely by model owners.

### 2. Technique as Triple Regime: Traceability, Transmission, Bricolage

But *the prismatic archive* is not only a critical concept—it is itself a technique. And every technique is simultaneously linked to three irreducible dimensions.

The dimension of traceability: every technique observes, records, captures. The flint that cuts leaves a trace; writing fixes speech; the algorithm vectorizes gesture. The prismatic archive does not escape this logic: it makes visible biases, sources, causal chains—including what would wish to remain opaque.

The dimension of transmission: every technique maintains a relation to meaning that exceeds its instrumental function. Yuk Hui names *cosmotechnics* this articulation between a technical order and a cosmological order (HUI, 2016). Generative AI encodes a cosmology: that of probability as horizon of being, of the average as norm. The prismatic archive must assume its own transmissive dimension: what relation to time, memory, alterity does it propose?

The dimension of bricolage: every technique is appropriation, diversion, improvisation. Michel de Certeau showed how ordinary users "poach" in technical devices, inventing tactics that divert the strategies of powers (DE CERTEAU, 1980). The prismatic archive does not pretend to construct a perfect system ex nihilo—it recomposes with available means spaces of resistance and creation.

To recognize these three dimensions is to refuse two symmetrical naiveties: the technophilia that would want an emancipatory technique "pure" of all relation to power; the technophobia that would reduce all technique to an instrument of domination. The prismatic archive is a situated and individuated technique—it must individuate itself in a specific context, with its actors, its stakes, its constraints (SIMONDON, 1958/2012).

### 3. The Right to Opacity

Édouard Glissant offers a decisive concept for thinking resistance. In *Poetics of Relation*, he writes: "To consent to the Other's opacity is already to love them." Transparency is a Western demand for reduction of the Other to a comprehensible, masterable, assimilable clarity. Against this will to make everything readable, Glissant claimed the right to be opaque—to not be entirely understood, translated, vectorized (GLISSANT, 1990).

Applied to generative AI, this concept becomes a strategy of resistance. Against the model's will to vectorize everything, one can claim the right to be illegible to the algorithm. This resistance now has concrete tools. Researchers have developed Glaze and Nightshade—systems that apply a layer of invisible noise to the image, imperceptible to the human eye but that disrupts AI learning. The artist can thus "poison" their own data, preventing the model from copying their style.

This also passes through less technical gestures: prompts that aim at the edges of the distribution rather than the center; preservation of non-indexed spaces (the "dark forest" of Dark Forest theory); documentation of processes rather than results alone.

---

## VII. Prismatic Pedagogy

### 1. Inquiry as Form of Life

To imagine a pedagogy of the image in 2025 requires no longer teaching AI as simply "one more creation tool," but as a new regime of truth and governmentality. The stake shifts: it is no longer merely about learning to make images, but about understanding how they make us.

John Dewey, in *Democracy and Education* (1916), develops a conception of education as continuous reconstruction of experience. To learn is not to passively receive constituted knowledge; it is to engage in an *inquiry* that simultaneously transforms subject and environment. Confrontation with generative AI must be the occasion for such an inquiry—about the tool, the dataset, biases, social effects, and the transformation of the subject who engages with it.

Paulo Freire, in *Pedagogy of the Oppressed* (1968), names *conscientization* the passage from a naive consciousness—which undergoes the world as natural given—to a critical consciousness that perceives structures of oppression. Applied to AI, conscientization requires passing from a naive usage—where one "prompts" without interrogating the black box—to a consciousness of the conditions of image production. Who collected the data? What invisible workers annotated the images? What biases are encoded in latent space?

Jacques Rancière, in *The Ignorant Schoolmaster* (1987), radicalizes the question. Intellectual emancipation supposes a postulate of equality of intelligences: the student is not an incapable to whom the master would transmit knowledge, but an equal who can learn by themselves. The prompt, as generally taught, is not emancipatory: it maintains the opacity of the black box. Emancipation would suppose grasping the model's logic, its limits, its biases—understanding that one does not create an image ex nihilo, but actualizes a statistical coordinate in a space of probabilities.

### 2. Technical Culture and Pharmacology

Gilbert Simondon, in *On the Mode of Existence of Technical Objects* (1958), diagnoses a "technical alienation" of contemporary culture. The machine is perceived either as useful slave, or as threat—never as a reality having its own mode of existence. This misunderstanding produces a *technical minority*: we use machines without understanding their genesis or functioning.

For generative AI, alienation manifests in magical discourse: "artificial intelligence," machine "creativity," model "hallucinations." These anthropomorphic metaphors occlude the technical reality: statistical operations on probability distributions. Technical culture would consist in dissipating this magic—not to disenchant the world, but to make possible an adult relation with the tool.

Bernard Stiegler, critical heir of Simondon, develops the concept of *pharmacology*: every technique is a *pharmakon*, at once poison and remedy. Generative AI democratizes image production but it proletarianizes know-how-to-see; it opens possibilities but it smooths the sensible. As Pierre Cassou-Noguès notes, these technologies "currently function as instruments that deprive brains of their consciousness, that is, of their relation to knowledge." Pedagogy must be deproletarianizing—it must reconstruct the knowledges that technique tends to dissolve.

### 3. Technodiversity and Conviviality

Yuk Hui, in his work on *technodiversity*, criticizes worldwide technological uniformization. Modernization has imposed a unique conception of technique, erasing local cosmotechnics—the ways each culture has articulated technique and cosmos (HUI, 2016). The large models (Midjourney, DALL-E, Stable Diffusion) are uniformizing infrastructures: they impose an average aesthetic, a globalized *vibe*, a worldview encoded in Western datasets.

Technodiversity would consist in developing situated models—trained on local archives, reflecting specific aesthetics, governed by particular communities. A collective of photographers that trains a model on its own archives, with its own annotations, produces a local cosmotechnics—a way of making images that resists the uniformization of globalized latent space.

Ivan Illich, in *Tools for Conviviality* (1973), distinguishes convivial tools—which augment user autonomy—from manipulative tools—which create dependence and confiscate knowledge. Generative AI, in its current state, is largely manipulative. An Illichian pedagogy would aim to identify the conditions of a convivial AI: transparent, appropriable, governable by its users.

### 4. Methods and Postures

These foundations translate into concrete practices. *Mapping latent space*: visualizing the "landscapes" of AI, locating zones of void—statistical silences—where AI knows how to produce nothing. *Reverse prompting*: rather than seeking the perfect image, seeking the image that "cracks," pushing the model toward its limits to analyze why it systematically produces "yellow" or "smooth." *Sovereign micro-datasets*: collecting a few hundred images on a situated theme, annotating them, training a small model (LoRA), observing the difference in "vibe" with generalist AI—an exercise in concrete technodiversity. *Traceability*: requiring that each image can be "diffracted," documenting processes rather than results alone. *Resource ethics*: Jussi Parikka reminds us that the "cloud" conceals a heavy geology—each generated image has a cost in water, minerals, electricity. Image pedagogy becomes Earth pedagogy.

Within this framework, the teacher can no longer be the one who transmits a stabilized know-how. They become the curator of tensions between *the liquid archive* and the political prism—the one who organizes conditions of Deweyan inquiry, who poses problems and accompanies without directing. They are Rancière's "ignorant schoolmaster," the transmitter of Simondonian technical culture. They are also the one who maintains the memory of what AI dissolves: the photographic body, the embodied gaze, the decision of the instant. The teacher of the algorithmic era transmits a know-how-to-navigate and a know-how-to-resist—navigating latent space as in an occupied territory, resisting liquefaction by reintroducing friction, opacity, singularity.

---

## Coda: Recursivity of Motifs

This text has circulated four motifs at different scales: liquidity, entropy, friction, the prism. They have returned in each section, from different angles—genealogical, material, economic, thermodynamic, pedagogical. This recurrence attempts to perform, in the writing itself, what a *prismatic archive* would be: each passage through the same concept illuminates it differently, maintains it in productive suspension rather than fixing it in definition.

These four motifs form a dynamic system where each calls the others. Liquidity without prism becomes entropy. Entropy without friction becomes *slop*. Friction without prism becomes sterile refusal. Prism without acceptance of liquidity becomes nostalgia. It seems to me that it is in their articulation that the possibility of a visual culture in the era of *statistical commons* is at stake.

The workshop gave pedagogical flesh to these abstract motifs. The crisis of intentionality, the passage from witness to curator, the obsession with *self*, the failure of the *glitch*: so many local symptoms of a global mutation. What played out in that classroom is what plays out everywhere humans trained in visual traditions find themselves confronted with machines that dissolve the very conditions of those traditions.

Prismatic pedagogy is not merely a method. For teachers in art schools it is rooted in Deweyan inquiry, Freirean conscientization, Rancièrean emancipation, Simondonian technical culture, Stieglerian pharmacology, Yuk Hui's technodiversity, Illichian conviviality, and many other methods still. This constellation is not a program to apply—it is a toolbox for inquiry. Each context will call for its own articulations, its own inventions.

The archive liquefies only when it loses its political dimension. To restore this dimension is to learn to diffract—and to claim, with Glissant, the right not to be understood by the machine.

---

## References

AESTHETICS WIKI. *Fandom*, 2024. https://aesthetics.fandom.com

ALEMOHAMMAD, Sina, CASCO-RODRIGUEZ, Josue, LUZI, Lorenzo, et al. "Self-Consuming Generative Models Go MAD." *arXiv preprint*, 2023. arXiv:2307.01850.

AMORALES, Carlos. *Liquid Archive*. Artistic project, 1998-2009. https://www.carlosamorales.com

AMRUTE, Sareeta. *Encoding Race, Encoding Class: Indian IT Workers in Berlin*. Durham (NC): Duke University Press, 2016.

BARAD, Karen. *Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning*. Durham (NC): Duke University Press, 2007.

BARTHES, Roland. *Camera Lucida: Reflections on Photography*. Trans. Richard Howard. New York: Hill and Wang, 1981. [Orig. ed.: *La Chambre claire*. Paris: Gallimard/Seuil, 1980.]

BAUMAN, Zygmunt. *Liquid Modernity*. Cambridge: Polity Press, 2000.

BAUMAN, Zygmunt. *Liquid Times: Living in an Age of Uncertainty*. Cambridge; Malden (MA): Polity Press, 2007.

BENJAMIN, Walter. "The Work of Art in the Age of Mechanical Reproduction" [1935]. In: *Illuminations*. Trans. Harry Zohn. New York: Schocken Books, 1969.

BENJAMIN, Walter. "A Short History of Photography" [1931]. In: *Selected Writings, Volume 2: 1927-1934*. Trans. Rodney Livingstone et al. Cambridge (MA): Harvard University Press, 1999.

BRIDLE, James. "The New Aesthetic." *Tumblr*, 2011-2013. https://new-aesthetic.tumblr.com

BRIDLE, James. *New Dark Age: Technology and the End of the Future*. London: Verso, 2018.

CASSOU-NOGUÈS, Pierre. "Désynchronisation des consciences et travail zombie." *Le Portique*, 2024, no. 43.

CHATONSKY, Grégory. *The Fourth Memory*. Installation, 2025. Presented in the exhibition "The World According to AI," Jeu de Paume, Paris.

CITTON, Yves. *The Ecology of Attention*. Cambridge: Polity Press, 2017. [Orig. ed.: *Pour une écologie de l'attention*. Paris: Seuil, 2014.]

CITTON, Yves. *Mediarchy*. Cambridge: Polity Press, 2019. [Orig. ed.: *Médiarchie*. Paris: Seuil, 2017.]

CRAWFORD, Kate. *Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence*. New Haven: Yale University Press, 2021.

CUBITT, Sean. *Finite Media: Environmental Implications of Digital Technologies*. Durham (NC): Duke University Press, 2017.

DE CERTEAU, Michel. *The Practice of Everyday Life*. Trans. Steven Rendall. Berkeley: University of California Press, 1984. [Orig. ed.: *L'Invention du quotidien. 1. Arts de faire*. Paris: Union Générale d'Éditions, 1980.]

DEWEY, John. *Democracy and Education: An Introduction to the Philosophy of Education*. New York: Macmillan, 1916.

DEWEY, John. *Art as Experience*. New York: Minton, Balch & Company, 1934.

DEWEY, John. *Experience and Education*. New York: Macmillan, 1938.

DÍAZ, Eva. *The Experimenters: Chance and Design at Black Mountain College*. Chicago: University of Chicago Press, 2015.

DUBERMAN, Martin. *Black Mountain: An Exploration in Community*. New York: E.P. Dutton, 1972. [Repr. Northwestern University Press, 2009.]

EDWARDS, Benj. "The AI 'Yellowing' Problem." *Ars Technica*, 2024.

FAROCKI, Harun. "Phantom Images." *Public*, 2004, no. 29, pp. 12-22.

FLUSSER, Vilém. *Towards a Philosophy of Photography*. London: Reaktion Books, 2000. [Orig. ed.: *Für eine Philosophie der Fotografie*. Göttingen: European Photography, 1983.]

FONTCUBERTA, Joan. *The Fury of Images: Notes on the Postphotograph*. Barcelona: MACK, 2017.

FOUCAULT, Michel. *Discipline and Punish: The Birth of the Prison*. Trans. Alan Sheridan. New York: Pantheon Books, 1977. [Orig. ed.: *Surveiller et punir*. Paris: Gallimard, 1975.]

FREIRE, Paulo. *Pedagogy of the Oppressed*. Trans. Myra Bergman Ramos. New York: Herder and Herder, 1970. [Orig. ed.: *Pedagogia do oprimido*. Rio de Janeiro: Paz e Terra, 1968.]

GLISSANT, Édouard. *Poetics of Relation*. Trans. Betsy Wing. Ann Arbor: University of Michigan Press, 1997. [Orig. ed.: *Poétique de la relation*. Paris: Gallimard, 1990.]

GLISSANT, Édouard. *Treatise on the Whole-World*. Trans. Celia Britton. Liverpool: Liverpool University Press, 2020. [Orig. ed.: *Traité du Tout-Monde*. Paris: Gallimard, 1997.]

GRAY, Mary L. and SURI, Siddharth. *Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass*. Boston: Houghton Mifflin Harcourt, 2019.

HARAWAY, Donna. "Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective." *Feminist Studies*, 1988, vol. 14, no. 3, pp. 575-599.

HARAWAY, Donna. "A Cyborg Manifesto." In: *Simians, Cyborgs and Women: The Reinvention of Nature*. New York: Routledge, 1991.

HARRIS, Mary Emma. *The Arts at Black Mountain College*. Cambridge (MA): MIT Press, 1987.

HEIKKILA, Melissa. "Why Does AI Art Look So Yellow?" *MIT Technology Review*, 2023.

HUI, Yuk. *The Question Concerning Technology in China: An Essay in Cosmotechnics*. Falmouth: Urbanomic, 2016.

ILLICH, Ivan. *Tools for Conviviality*. New York: Harper & Row, 1973.

LÉVI-STRAUSS, Claude. *The Savage Mind*. Chicago: University of Chicago Press, 1966. [Orig. ed.: *La Pensée sauvage*. Paris: Plon, 1962.]

MANOVICH, Lev. *AI Aesthetics*. Moscow: Strelka Press, 2018.

MOLESWORTH, Helen (ed.). *Leap Before You Look: Black Mountain College 1933-1957*. Exhibition catalogue. Boston: Institute of Contemporary Art; New Haven: Yale University Press, 2015.

NEW MODELS (Caroline BUSTA and Lil INTERNET). "Platform Physics." *New Models Podcast*, 2020. https://newmodels.io

NEW MODELS. "Holographic Media." *New Models Podcast*, 2021. https://newmodels.io

NEW MODELS. "Artist Profile: New Models." Do Not Research, October 2025. URL: https://donotresearch.substack.com/p/artist-profile-new-models

NOBLE, Safiya Umoja. *Algorithms of Oppression: How Search Engines Reinforce Racism*. New York: NYU Press, 2018.

PAGLEN, Trevor. "Invisible Images (Your Pictures Are Looking at You)." *The New Inquiry*, 2016.

PARIKKA, Jussi. *A Geology of Media*. Minneapolis; London: University of Minnesota Press, 2015.

PASQUINELLI, Matteo and JOLER, Vladan. "The Nooscope Manifested: AI as Instrument of Knowledge Extractivism." *AI & Society*, 2021, vol. 36, no. 4, pp. 1263-1280.

RANCIÈRE, Jacques. *The Ignorant Schoolmaster: Five Lessons in Intellectual Emancipation*. Trans. Kristin Ross. Stanford: Stanford University Press, 1991. [Orig. ed.: *Le Maître ignorant*. Paris: Fayard, 1987.]

RANCIÈRE, Jacques. *The Politics of Aesthetics: The Distribution of the Sensible*. Trans. Gabriel Rockhill. London: Continuum, 2004. [Orig. ed.: *Le Partage du sensible*. Paris: La Fabrique, 2000.]

SCHOLZ, Trebor (ed.). *Digital Labor: The Internet as Playground and Factory*. New York: Routledge, 2013.

SCHUHMANN, Christoph, BEAUMONT, Romain, VENCU, Richard, et al. "LAION-5B: An Open Large-Scale Dataset for Training Next Generation Image-Text Models." *arXiv preprint*, 2022. arXiv:2210.08402.

SHUMAILOV, Ilia, SHUMAYLOV, Zakhar, ZHAO, Yiren, GALES, Mark, PAPERNOT, Nicolas and ANDERSON, Ross. "The Curse of Recursion: Training on Generated Data Makes Models Forget." *arXiv preprint*, 2023. arXiv:2305.17493.

SIMONDON, Gilbert. *On the Mode of Existence of Technical Objects*. Trans. Cécile Malaspina and John Rogove. Minneapolis: Univocal, 2017. [Orig. ed.: *Du mode d'existence des objets techniques*. Paris: Aubier, 1958.]

SOMAINI, Antonio (curator). *The World According to AI*. Exhibition, Jeu de Paume, Paris, April 11 – September 21, 2025.

SONTAG, Susan. *On Photography*. New York: Farrar, Straus and Giroux, 1977.

STAROSIELSKI, Nicole. *The Undersea Network*. Durham (NC): Duke University Press, 2015.

STEYERL, Hito. *Duty Free Art: Art in the Age of Planetary Civil War*. London: Verso, 2017.

STEYERL, Hito. *Medium Hot: Images in the Age of Heat*. London: Verso, 2025.

STIEGLER, Bernard. *Technics and Time, 3: Cinematic Time and the Question of Malaise*. Trans. Stephen Barker. Stanford: Stanford University Press, 2011. [Orig. ed.: *La technique et le temps 3*. Paris: Galilée, 2001.]

STIEGLER, Bernard. *Taking Care of Youth and the Generations*. Trans. Stephen Barker. Stanford: Stanford University Press, 2010. [Orig. ed.: *Prendre soin*. Paris: Flammarion, 2008.]

WAGON, Gwenola and DEGOUTIN, Stéphane. *Globodrome*. Paris: B42, 2018. [Project initiated 2013.]

WAGON, Gwenola and DEGOUTIN, Stéphane. *World Brain*. Documentary film, 2015. 75 min.

---
