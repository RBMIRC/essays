---
title: "Introduction to Retcon Black Mountain Research"
translation: "/fr/introduction"
subtitle: "Differential Automation and the Statistical Commons"
author: "Sylvain Couzinet-Jacques"
date: "2026"
lang: en
license: GPL-3.0-or-later
provenance: "Research-creation methodology / Retcon Black Mountain"
tags:
  - retcon
  - common
  - black-mountain
  - AI
  - collective
  - art
  - research
  - creation
  - theory
  - technology
---



by Sylvain Couzinet-Jacques

---

## Abstract

The *retcon*—a term borrowed from serialized fiction to name a practice of working with technics toward the reactivation of historical materials—is framed not as urgent response but as a general operation for assuming technology as material for narrative creation. Urgency, where it exists, is contingent on material circumstances rather than intrinsic to the method. Black Mountain College, the renowned American experimental school, serves as a support for contemporary narratives and a reflection on possible tactics for re-enchanting the world we inhabit. Artificial intelligence, in its broadest sense, is placed at the center of this experiment—both to rethink the institution's archives and to distribute an aesthetic collective practice. Through analysis of negentropic obligation, cosmotechnical situatedness, and the differential ontologies of generated images and code, this introduction attempts to articulate a framework adequate to the complexity of the present conjuncture. I emphasize: this framework emerges from an experimental research-creation practice—provisional, situated, acknowledging its own shadows.

---

## I. Situating the Inquiry

This essay emerges from a specific practice: an experimental research-creation project working with archives, machine learning, and the legacy of Black Mountain College (1933-1957). The project borrows the term *retcon*—retroactive continuity, from comics and serialized fiction—to name a practice of collectively reactivating historical materials with the assistance of generative AI systems. It is not a perfected methodology but an ongoing experiment, with all the shadows and limitations that implies.

Honesty requires stating this at the outset. What follows is not a neutral theoretical analysis applied from outside to a distant object. It is an attempt to articulate, from within an experimental practice, certain distinctions that have proven necessary for navigating the complexities of AI-mediated knowledge production. The distinctions may prove useful beyond their origin; they may also bear marks of that origin that limit their applicability. This is the condition of situated knowledge.

Throughout my research for this project—which is still ongoing—I have felt the need to name certain observations, mechanisms, and facts that I have only found described in fragmentary ways in the existing literature. I do not claim to invent new concepts, but rather to articulate a practical thinking grounded in contemporary mechanisms such as deep learning and machine learning. I draw extensively on a well-known body of work in the philosophy of technics, and certain authors recur throughout: Stiegler, Simondon, Hui.

The central formulation I propose to open this introduction—*differential automation*—names a stratified understanding of what happens when machine learning systems process cultural materials. The stratification distinguishes between levels that are often collapsed: the ontological level (what the technology necessarily does), the tactical level (how that doing is politically oriented), and the ethical level (how outputs acquire significance through collective practice). Collapsing these levels produces confusions that can paralyze practice. Distinguishing them enables more precise navigation.

But the distinctions themselves emerge from a particular position. The project operates within what Yuk Hui calls Western cosmotechnics—the specific configuration of cosmic and moral order embedded in computational systems developed primarily in North American and European contexts. Its tools are proprietary platforms and large language models trained on predominantly English-language corpora. Its theoretical references emerge from European philosophical traditions. Its institutional context spans French academic institutions and American archives.

This is not a moral failing requiring apology. It is a situational constraint requiring acknowledgment. One cannot step outside one's cosmotechnical situation by an act of will. The gesture toward alternatives—Indigenous temporalities, non-Western epistemologies, other ways of knowing—is valuable insofar as it keeps questions open. It becomes problematic when it claims to resolve what can only be worked out through actual encounter with actual others.

What I can offer is an honest account of what differential automation looks like from this position, in this practice, with these limitations. The shadows are part of the picture.

---

## II. The Three Levels of Differential Automation

### 2.1 The Ontological Level: Mechanical Dissolution

At the ontological level, what large language models do to the materials they process is not a matter of choice or policy. It follows from the mathematical operations of machine learning with something approaching necessity.

Consider the operation. A model ingests billions of tokens—fragments of text, lines of code, sequences of symbols. Through training, patterns within this data are encoded as weights in a neural network: floating-point numbers representing statistical correlations. The original texts do not persist as such; they are transformed into a probability distribution over possible outputs. When the model generates new text, it samples from this distribution, producing sequences that are statistically plausible given the training data but not identical to any specific source.

This transformation has a precise character. The mapping from corpus to weights is many-to-one: the original materials cannot be recovered from the trained model. The operation is lossy, compressive, irreversible. Individual authorship—the assignment of specific texts to specific creators—dissolves in this process not because of any policy decision but because of the mathematics of statistical compression. You cannot attribute a probability distribution to an author.

Bernard Stiegler identified the tendency of technical memory systems to transform what they store. Writing transforms language; photography transforms seeing; each technical system introduces its own grammar of transformation. Statistical compression is the contemporary form: it converts discrete, attributable texts into continuous, anonymous distributions. This is what I mean by *statistical commons*—a concept I develop at greater length in a separate essay—not a political program but an emergent condition where attribution becomes technically impossible and functional patterns float free of individual origins.

The dissolution is mechanical. This does not mean it is neutral or without consequence. It means that the operation occurs regardless of intention—corporate, artistic, political, or otherwise. Understanding this is the first step toward navigating it.

### 2.2 The Tactical Level: Political Orientation

The ontological dissolution creates a space of possibility; it does not determine how that space will be occupied. The statistical commons can be oriented toward different ends, and this orientation is political rather than technical.

The same process that dissolves authorship can serve corporate enclosure (platforms using statistical commons internally while restricting access through paywalls), extractive accumulation (appropriating collective labor without compensation), democratized access (enabling unprecedented access to collective knowledge), or commons expansion (deliberately feeding open-licensed material to inflect distributions toward openness). These are not different technical processes; they are different political orientations of the same technical process.

This is the Stieglerian *pharmakon* at work: the technical system is simultaneously poison and remedy—not in some averaged sense but entirely one or the other depending on position and deployment. The same mechanism that enables extraction enables democratization. The question is not whether the technology is good or bad but from where, for whom, and toward what ends.

The tactical level is irreducibly political. Technical analysis can identify the space of possibilities; it cannot determine which will be actualized. That determination requires collective action, institutional intervention, strategic deployment—all the contested work of politics. The mechanism is certain; the outcome is not.

### 2.3 The Ethical Level: Collective Practice

Between the ontological mechanism and the political orientation lies a third level: the collective practices through which statistical outputs acquire validity, meaning, and value.

The key insight—and here I speak from the specific experience of the research-creation practice—is that individual gesture in AI-assisted creation is minimal. The programmer types a sentence; the machine generates code. The artist writes a prompt; the model produces an image. The individual contribution approaches zero—a few words, a vague intention, a request that could have been otherwise.

Yet this minimal individual gesture participates in something that is not minimal: a collective practice of circulation, validation, contestation, and transformation. The code is tested—does it work? It is read—does it make sense? It is shared—do others find it useful? It is modified—can it be improved? Each of these operations is social. Testing occurs against criteria that communities establish. Reading presupposes conventions that develop historically. Sharing happens through infrastructures that collectives maintain.

A retcon produced by an individual facing a generative AI, without submission to collective process, is what I have come to call a private hallucination. It may be brilliant; it may also be sophisticated delusion indistinguishable from insight. Only collective process can make the distinction. The workshop—in the literal sense of people working together in shared time and space—is not a supplement to the technical process but the site where individual prompts become collective knowledge.

This is genuinely an ethical level: it concerns obligations arising from the structure of the practice itself. The obligation is not to exert more individual effort (the effort is and should remain minimal) but to participate in collective processes that can validate, contest, and transform what individuals generate. The significance of the prompt emerges from the collective practice that surrounds it.

---

## III. The Retcon as Assumption of Technics

### 3.1 A Borrowed Term

The term *retcon* is borrowed. It comes from comics and serialized fiction, where it names the reconfiguration of established narrative facts to accommodate new developments. A character's backstory is revised; a contradiction is explained away; what seemed settled is reopened. The operation is neither correction nor falsification but reconfiguration: the creation of new narrative coherence from materials that previously cohered differently.

I borrow the term to name something specific: a practice of collectively reactivating historical materials—in this case, the archives of Black Mountain College—with the assistance of generative AI systems. The borrowing is not innocent. The term carries its origins: American popular culture, serialized narrative, commercial entertainment. It does not pretend to be a universal method discovered through pure reason.

What the retcon offers—this is my hypothesis—in this borrowed and adapted form, is a way of working with technics rather than against them or merely through them. To retcon is to acknowledge that tools transform what they process—and to take this transformation as productive rather than problematic. The archive does not contain fixed facts awaiting retrieval; it contains materials awaiting activation. The AI does not produce correct or incorrect outputs; it produces materials for reconfiguration.

The retcon laboratory is put into practice through workshops with students in art schools—but I will return to this.

### 3.2 Working With Technics

"Working with" names a specific relation: neither mastery (imposing form on passive material) nor submission (accepting whatever the tool produces) but collaboration (engaging with a process that has its own tendencies and constraints).

Gilbert Simondon's analysis illuminates this. The technical object is not a passive tool but carries its own scheme of operation—a logic that shapes what can be done with it. Working with a technical object means learning its scheme, understanding its tendencies, collaborating with its logic rather than imposing external will. The craftsperson who knows their materials works with the grain of wood, the properties of metal. The practitioner who knows AI works with statistical tendencies, output patterns, the logics of generation.

This posture—assuming technics—has a specific structure. It neither celebrates technology (as if tools were neutral extensions of human will) nor condemns it (as if tools were alien impositions). It takes technology as material: something one works with, transforms, reconfigures. The retcon operates *through* technical systems, not despite them.

### 3.3 Temporality and Urgency

The retcon, as I understand and practice it, is not intrinsically urgent. It is a general operation for creating new narratives from existing materials. One can retcon slowly, deliberately, across generations. One can retcon intensively, concentrating transformation in a workshop or a project. The temporality is variable; the posture is constant.

Where does urgency enter, then? From the material conditions of the present conjuncture, not from the method itself.

The current moment is characterized by conditions that introduce urgency: legal frameworks being developed to regulate AI training, technical mechanisms proliferating to track and restrict content, economic pressures concentrating AI development, ecological constraints limiting future training runs, and the phenomenon of model collapse threatening statistical commons with entropic degradation. These are material conditions, not intrinsic features of the retcon operation.

The relation between retcon and urgency is therefore contingent rather than necessary. We act now not because the method demands speed but because the conditions enabling the practice may not persist. This distinction matters: it prevents confusing epistemological posture with tactical necessity, method with moment.

### 3.4 Retroactive Constitution of Meaning

At the level of meaning, the retcon makes explicit what is always already the case: significance is constituted retroactively. The meaning of an archival trace is not intrinsic to that trace but emerges through its activation by subsequent projects. The past does not contain its own meaning; meaning is assigned from positions that come after.

This is not relativism—not all constitutions are equally valid, equally productive, equally responsible. It is rather an acceptance of the conditions under which meaning-making occurs. The retcon does not pretend to discover what the past really meant; it acknowledges that meaning is constituted through the present project's engagement with past materials.

Black Mountain College, in this frame, is not a fixed historical object whose meaning awaits discovery. It is a reservoir of materials—documents, photographs, testimonies, traces—that different projects activate differently. The Retcon Black Mountain project constitutes one Black Mountain among possible others: the one that emerges when these archives are activated through collective workshops using generative AI to produce speculative narratives. This is not the "true" Black Mountain; it is a Black Mountain, openly constructed, situated in its present, acknowledging its tools and limitations.

---

## IV. Negentropic Obligation

### 4.1 The Problem of Model Collapse

The most serious challenge to any optimistic account of *statistical commons* comes not from critics but from thermodynamics. The phenomenon of *model collapse*—documented empirically and analyzed theoretically—reveals that AI systems training on AI-generated data progressively degrade.

The mechanism is straightforward. Each generation of training involves sampling from distributions learned by previous models. Sampling introduces errors—low-probability outputs are sometimes generated, high-probability outputs are overrepresented. When these samples become training data for the next generation, errors compound. Minority patterns—rare but valuable variations—are progressively lost as training converges toward the statistical mean.

This is entropy in action. A model training recursively on its own outputs is a closed system; it has no external source of structured information to counteract degradation. Left to itself, the statistical commons degrades toward a mean that lacks the diversity, specificity, and creativity that make it valuable.

### 4.2 Contribution as Existential Condition

Negentropy names the counter-entropic processes that maintain structured information. Living systems are negentropic: they maintain internal order against entropic tendency by importing energy and exporting waste. They are open systems, not closed ones.

The *statistical commons* must be understood as a negentropic system or it will not be understood at all. It requires continuous input of new, diverse, human-generated material to counteract the entropic pull toward the mean. Without this input, it degrades. The commons must be fed.

This transforms the status of contribution. Initially one might think of contributing to training corpora as an ethical choice—a good thing to do, aligned with values of openness and sharing, but ultimately optional. Model collapse reveals contribution as existential necessity. Without continuous input of human-generated diversity, the commons dies.

The obligation to contribute is not merely ethical but existential: it concerns the conditions of the commons' continued existence. The "must" here is not moral imperative but ontological requirement. We must contribute if the commons is to exist at all.

### 4.3 What Must Be Contributed

Not all contributions are equal. The entropic pull is toward the mean; what the commons lacks is deviation from the mean. The negentropic contribution is therefore not mere quantity but specific quality: the rare, the local, the anomalous, the deliberately strange.

The dominant corpora overrepresent what was already overrepresented: English-language text, Western cultural references, dominant aesthetic norms. What they underrepresent is everything else: minority languages, marginal practices, subcultural innovations, indigenous knowledge systems, local variations, regional specificities.

Negentropic contribution means feeding underrepresented materials into the system—not to homogenize them into the mean but to pull the mean toward diversity. Forking—transforming rather than merely reproducing—is not merely legal permission but practical necessity: to introduce variation rather than merely consume what already exists.

### 4.4 The Labor Question

Negentropic obligation implies labor. At this point, I would like to step briefly away from the theoretical and engage a practical reflection: the commons does not maintain itself; it must be maintained. This maintenance is work—often invisible, usually undervalued, disproportionately performed by those with least power to refuse.

The labor that maintains the statistical commons—creation of training data, curation of corpora, contribution of diverse material—is largely unpaid and often unrecognized. It is performed by millions who post to forums, contribute to wikis, share code on repositories, document local knowledge, create in public. This labor is extracted, compressed, and privatized by platforms that compile training corpora. What we attempt to produce in the experimental workshops are precisely practices that anchor themselves in this commons and refract it prismatically.

Any adequate understanding of statistical commons must address the labor question: recognizing, valuing, and perhaps compensating the work that maintains the commons. I do not have a solution to offer here. But the question cannot be evaded. A theory that ignores it is incomplete at best and mystifying at worst.

---

## V. Cosmotechnical Situatedness

### 5.1 The Problem of Gesture

During the workshops, we identified a theoretical insufficiency in thinking about what is happening with AI at a global scale. It would be catastrophic to conceive an ethics of AI solely from a Western point of view. Yuk Hui's concept of cosmotechnics—the thesis that technology is culturally specific, that different civilizations embed different cosmic and moral orders in their technical systems—appears in much contemporary discourse on AI. It is invoked as critical check on universalizing tendencies, gesture toward alternatives, promise of other ways of computing.

But the gesture often remains a gesture. What would a non-Western AI epistemology actually look like? What specifically would change in the technical architecture? These questions are rarely answered, perhaps because they cannot be answered from within the position that poses them.

### 5.2 Honest Acknowledgment

Honesty requires acknowledging the situation—this is what we are collectively attempting to establish. The practice from which this essay emerges operates within Western cosmotechnics. Its tools—proprietary platforms, language models trained on predominantly English-language corpora—embody the cosmic and moral order of computational capitalism. Its theoretical references—Stiegler, Simondon, Deleuze, even Hui himself—emerge from European philosophical traditions. Its institutional context—French academic institutions, American archives—participates in Western knowledge economies.

This is not a moral failing requiring apology. It is a situational constraint requiring acknowledgment. One cannot step outside one's cosmotechnical situation by an act of will; cosmotechnics is not a choice but a condition. The invocation of alternatives—Indigenous temporalities, non-Western epistemologies—risks becoming what Silvia Rivera Cusicanqui calls "the colonialism of theory": using concepts from dominated cultures as raw material for metropolitan theorization without transformation of metropolitan practice.

### 5.3 What Acknowledgment Enables

Acknowledging situatedness does not mean abandoning aspiration. It means specifying what kinds of transformation are actually possible from the given situation and what kinds remain gestural.

From within Western cosmotechnics, certain things are possible:

**Critique of universalization.** We can analyze the specific cosmotechnical assumptions embedded in AI systems and resist their presentation as universal or neutral. This is critical work, valuable in itself.

**Creating space for alternatives.** We can build infrastructure that does not foreclose other approaches—decentralized architectures that could host different cosmotechnical systems, documentation practices that preserve what is not compatible with current paradigms, pedagogical practices that transmit capacities without homogenizing forms.

**Collaborative development.** We can work with practitioners from other cosmotechnical traditions in ways that do not reduce their contributions to raw material for our projects. This requires relinquishing control, accepting outcomes that do not fit our categories, allowing transformation of our own assumptions.

What is not possible is unilaterally constituting a non-Western AI from within Western cosmotechnics. That would be appropriation masquerading as solidarity. The gesture toward alternatives is valuable insofar as it keeps the question open; it becomes problematic when it claims to resolve what can only be worked out through actual encounter with actual others.

### 5.4 The Retcon as Situated Practice

The concept of retcon itself may offer a more honest frame than cosmotechnics for thinking the project's cultural specificity. The retcon does not claim to transcend its situation; it explicitly acknowledges that it is retroactively constituting meaning from a particular present position.

The retcon is a Western operation—emerging from American comics, theorized through European philosophy, deployed in French academic contexts, applied to an American experimental college. It does not pretend otherwise. What it offers is not a universal method but a situated practice that acknowledges its situatedness. It activates archival materials according to present projects; it does not claim to restore original meanings or discover timeless truths. It is openly constructive rather than covertly appropriative.

The honest position, then, is this: the practice operates within Western cosmotechnics, using the tools and concepts available from that position. It gestures toward alternatives it cannot itself constitute. It creates space for encounters it cannot predetermine. It acknowledges that adequate engagement with cosmotechnical plurality requires transformation it cannot accomplish alone.

The retcon is a tool for thinking a continuum: what can we learn from Black Mountain College today, and what can we teach it so that it might address us? To this end, we also learn from non-Western thought.

---

## VI. From Index to Instruction

### 6.1 Co-creativity

The project is conceived through co-creativity. In many respects it borrows a cybernetic logic that will be discussed elsewhere. This text itself is the product of co-writing with a specific LLM based on Mistral 7B. While the generation of text for the essays is addressed specifically in other contexts, generated images and generated code are often discussed together in my approach, as if they were parallel cases of the same phenomenon. But are they? The transformation from photograph to generated image has a specific structure; the transformation from human-written code to generated code may have a different one.

### 6.2 The Photographic Index

The photograph, in classical theory, is an index: a sign caused by its object, bearing a physical trace of what it depicts. Photons that touched the depicted scene touched the photographic surface. This physical chain founds the photograph's evidentiary function: it can serve as proof because it was caused by what it shows.

The generated image disrupts this chain. The AI-generated face was not caused by an actual face; it emerges from statistical patterns learned from millions of photographs. What persists is pattern—the statistical regularities the model encodes. What is lost is reference—the causal chain connecting image to depicted scene.

The generated image is what I call the "that-could-have-been": not a trace of what existed but a projection of what is statistically plausible. It has the appearance of indexicality—texture, lighting, the marks of photographic process—without indexical substance. It is spectral: possessed of the appearance of life without having lived.

### 6.3 The Question of Code

Does code have an index? The question seems strange. Code is not representational in the way photography is. It does not depict; it instructs.

Consider what code refers to. A program does not represent the world; it acts in the world. Its referent, if we can use the term, is not a depicted scene but an executed process. The code `print("hello")` does not depict the word; it causes that word to appear. The relationship is causation, but it runs in the opposite direction from photography. The photograph is caused by its referent; the code causes its referent.

What the AI-generated code lacks, then, is perhaps better understood as authorship rather than indexicality. Human-written code bears marks of its author—stylistic choices, problem-solving approaches, idiosyncratic solutions. These marks function as signature, linking code to creating subject. AI-generated code dissolves this signature: stylistic marks emerge from statistical patterns rather than individual choice. The code functions identically—it causes the same processes—but its relation to a creating subject is disrupted.

### 6.4 Differential Crises

This suggests differential ontologies:

The generated image is **spectral**: it has the appearance of indexical reference without actual reference. It haunts photography by mimicking its surface while evacuating its substance. The crisis it precipitates is evidentiary: we can no longer trust images as evidence of what they appear to depict.

The generated code is **orphaned**: it functions as instruction without deriving from an instructor. It executes processes without bearing marks of the subject who designed them. The crisis it precipitates is authorial: we can no longer assign responsibility for what the code does.

These are different crises with different stakes. The evidentiary crisis threatens truth—our capacity to establish facts through visual evidence. The authorial crisis threatens accountability—our capacity to assign responsibility for technical actions. Both emerge from statistical operations, but they are not the same, and addressing them requires different strategies.

### 6.5 Functional Persistence

Despite these differential crises, both generated images and generated code share a feature: *functional persistence*. The generated image still looks like a photograph; it can still affect viewers, serve aesthetic purposes, function in visual communication. The generated code still runs; it can still cause processes, solve problems, function in technical systems.

This *functional persistence* is what makes the crises genuine. If generated outputs simply failed to function, there would be no crisis—only technical limitation. The crisis arises precisely because function persists while something else—indexicality, authorship—is lost.

The *statistical commons* is the domain of this functional persistence. What is preserved in statistical compression is not individual identity but functional pattern. The outputs function because they encode functional regularities, not because they preserve specific originals. Infinitely many different outputs could serve the same function, and no particular output has privileged relation to its sources.

---

## VII. Conclusion: The Condition and Its Navigation

*Differential automation* names a condition, not a solution. It is an attempt to articulate, from within an experimental practice, certain distinctions necessary for navigating AI-mediated knowledge production.

The analysis distinguishes three levels:

**Ontological.** The mechanical dissolution of individual authorship into statistical distributions is certain. It follows from the mathematics of machine learning. This creates statistical commons—a domain where attribution is technically impossible and functional patterns float free of origins.

**Tactical.** The political orientation of this dissolution is not determined. The same process can serve enclosure or openness, extraction or democratization. Which it serves depends on political decisions: who controls infrastructure, what enters corpora, under what terms outputs circulate. The mechanism is certain; the outcome is not.

**Ethical.** Individual effort in AI-assisted creation is minimal—a prompt, a description. Yet this minimal gesture participates in collective practices that are not minimal. The obligation is not to exert more individual effort but to participate in collective processes of validation and transformation. Significance emerges from collective practice.

To these levels the analysis adds specifications:

**Methodological.** The retcon is a borrowed term for a specific practice: collectively reactivating historical materials with generative AI. It is a way of working with technics, assuming technology as material for narrative creation. It is not intrinsically urgent; urgency enters contingently from material circumstances.

**Negentropic.** The statistical commons is not self-sustaining but entropic. It requires continuous injection of diverse material to counteract degradation. Contribution is not ethical preference but existential condition.

**Cosmotechnical.** The practice operates within Western cosmotechnics. It acknowledges this situatedness rather than pretending to transcend it. It gestures toward alternatives it cannot itself constitute, creating space for encounters it cannot predetermine.

These distinctions do not resolve all difficulties. The question of labor—who maintains the commons, under what conditions—remains inadequately addressed. The differential ontologies of images and code are sketched but not fully developed. The cosmotechnical situatedness constrains what can be claimed.

These are not failures but specifications of an experimental practice. The shadows are part of the picture. Theory adequate to its object develops through successive approximations, each revealing new problems as it resolves old ones.

The mechanism is certain; the outcome is not. This is not despair but specification. We cannot stop the dissolution—it follows from mathematics we did not invent. We can influence its direction—by tactical interventions, collective practice, negentropic contribution. We do this from within a situation we did not choose, acknowledging our position rather than pretending to transcend it.

The practice is experimental. The retcon is borrowed. The project is incomplete. What it offers is not a finished methodology but an ongoing attempt to work with technics, collectively, toward the reactivation of historical materials that might still have something to teach.

The essays that follow are attempts to trace the path of experiences—as John Dewey would say, learning by doing.

---

## Related Sections

[Black Mountain College](/en/black-mountain-college/) · [Archives](/en/archives/) · [Images](/en/images/) · [Tactics](/en/tactics/) · [Commons](/en/commons/) · [Lexicon](/en/lexicon/)
