---
title: "Model Collapse"
type: glossary
aliases: []
tags:
  - glossary
  - _larchive-liquide*-*the-recursive-archive
---

Shumailov et al.'s term (Nature, 2024) for degenerative process when generative models train recursively on synthetic data; causes irreversible loss of distributional tails and minority information. Also called "Habsburg AI" or "AI inbreeding." Shumailov et al. speak of "model autophagy disorder"â€”by analogy with prion diseases where misfolded proteins cause other proteins to misfold. After five to seven generations of recursive training, the model produces "degenerate" results: total loss of semantic nuance, convergence toward average, disappearance of the tails of distribution. Not only a technical risk but the symptom of a system that, lacking new human inputs to extract, begins to devour itself. (*L'Archive Liquide*, *The Recursive Archive*)

**References:**
- SHUMAILOV, Ilia et al. The Curse of Recursion: Training on Generated Data Makes Models Forget. *arXiv preprint arXiv:2305.17493*. 2023.