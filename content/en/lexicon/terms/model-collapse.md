---
title: "Model Collapse"
type: glossary
aliases: []
tags:
  - glossary
  - _larchive-liquide*-*the-recursive-archive
---

What happens when models are trained on synthetic data generated by previous models. Shumailov et al. speak of "model autophagy disorder"â€”by analogy with prion diseases where misfolded proteins cause other proteins to misfold. After five to seven generations of recursive training, the model produces "degenerate" results: total loss of semantic nuance, convergence toward average, disappearance of the tails of distribution. Not only a technical risk but the symptom of a system that, lacking new human inputs to extract, begins to devour itself. (*L'Archive Liquide*, *The Recursive Archive*)

**References:**
- SHUMAILOV, Ilia et al. The Curse of Recursion: Training on Generated Data Makes Models Forget. *arXiv preprint arXiv:2305.17493*. 2023.