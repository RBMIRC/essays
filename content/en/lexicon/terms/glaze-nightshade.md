---
title: "Glaze / Nightshade"
type: glossary
aliases: []
tags:
  - glossary
  - _larchive-liquide
---

Technical tools for resistance against AI appropriation: systems that apply invisible noise to images, imperceptible to the human eye but disruptive to AI learning. Artists can "poison" their own data, preventing models from copying their style without blocking human viewing. Concrete tools for claiming what Édouard Glissant called the right to opacity—the right not to be fully legible to systems of extraction. (*L'Archive Liquide*)