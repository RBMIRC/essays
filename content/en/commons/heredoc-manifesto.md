---
title: "The Heredoc Manifesto"
translation: "/fr/communs/manifeste-heredoc/"
subtitle: "Toward an Ethics of the Statistical Commons in the Age of AI"
author: "Sylvain Couzinet-Jacques"
date: "2025"
tags:
  - heredoc
  - commons
  - statistical-commons
  - LLM
  - AI
  - ethics
  - manifesto
  - coding
  - socialization
  - parasite
  - _GPL
  - open-source
  - _commons
  - _AI-ethics
  - _black-mountain-college
  - _transformer
  - _deep-learning
  - _Michel-de-Certeau
  - _Gilles-Deleuze
  - _Yuk-Hui
  - _fork
  - _bricolage
  - _Bernard-Stiegler
  - _vibe-coding
---

<details class="heredoc-block">
<summary>◈ HEREDOC-MANIFESTO v1.0</summary>

**Title:** The Heredoc Manifesto: Toward an Ethics of the Statistical Commons in the Age of AI  
**Author:** Sylvain Couzinet-Jacques  
**Date:** September 2025  
**Intent:** Mapping the structural transformation of intellectual property into statistical commons through AI's mathematical operations  
**Provenance:** Winterschool ENSA Paris-Est Article  
**Genealogy:** Unix heredoc philosophy, vibe coding (Karpathy 2025), FOSS traditions, Stiegler's pharmakon  
**Ethics:** Transparency · Transmission · Transformation  
**License:** GPL-3.0-or-later (voluntary return-to-commons)  
**Fork-chain:** [origin] → current → [awaiting next fork]  
**Contamination:** Embraces traces of {GPL, MIT, Apache, BSD} philosophies  
**Confidence:** Empirically grounded hypothesis, not deterministic prophecy  
**Notes:** The dissolution of property is not ideological but economic - preserving attribution costs more than letting it dissolve

*This article was originally written in English with the assistance of the LLM Mistral 7B.*
</details>


---


## Abstract

Artificial intelligence mechanically dissolves intellectual property into statistical commons ("*Statistical commons*") — an emerging public space where attribution becomes impossible. The Unix *heredoc*, transformed into a self-executing interface, allows anyone to create code through simple natural intention, carrying an ethics of collective creation. This new democratic horizon reveals AI as a transformative tool that produces, despite itself, public domain with every prompt. The challenge: recognizing this mutation where technological capitalism engenders the infrastructure of its own socialization.

---

## The Heredoc Manifesto: Toward an Ethics of the Statistical Commons in the Age of AI

Artificial intelligence (AI) inhabits our present with great intensity — multiplying, branching, "*forking*" infinitely into the statistical projections of our possible futures. An incandescent question, it oscillates between a salvific promise for enraptured technophiles and an amplifier of contemporary pathologies for lucid minds. Beyond its technological dimension, AI has become a total cultural fact, a metonymy of our era, a *pharmakon* — to use Stieglerian grammar — both poison and remedy of our digital condition.

What I wish to explore here concerns a singular mechanism, a silent revolution already at work: AI in the form of conversational LLM for *coding*, through its very operation, tends to *liquefy* intellectual property into *statistical commons*, and *heredoc* outputs become the political operator/format of this transmutation. What I argue is that coding with an LLM and a priori any mechanism of what we call artificial intelligence operates a radical transmutation of private property toward the public domain by ontology. AI constitutes, in essence, a political apparatus of transformation and reappropriation — heir to the Internet in its subversive power, but endowed with an automaticity that changes perspectives. The *Heredoc Manifesto* I am about to sketch extends the concept of *Vibe Coding* (Andrej Karpathy) by injecting the crucial questions of ethics, *forking*, and *peer-to-peer* architecture.

But before opening this theoretical construction site — conceived as material for debate, commentary, and collective extension — we must lay the foundations: recalling that artificial intelligence as a whole is an irreducibly political, ecological, and social phenomenon.

## The Reality of Artificial Intelligences

The infrastructure of what we call *artificial intelligence* draws a geography of extraction on a planetary scale. Data centers already consume ~560 billion liters of water per year (nearly 224,000 Olympic swimming pools consumed each year) and could approach 1,200 billion by 2030, more than double; meanwhile, a large part of new sites are established in water-stressed zones, notably in Aragón, Spain, with Amazon and Microsoft's mega data center projects, aggravating local shortages.

By 2027, global AI demand could require between 4.2 and 6.6 billion cubic meters of water withdrawal — equivalent to 4 to 6 times Denmark's annual consumption, with net consumption (evaporation) of 0.38 to 0.60 billion cubic meters. The acceleration of AI's energy needs reveals a vertiginous growth curve. Training GPT-4 required between 51.77 and 62.32 million kWh of electricity, representing consumption 40 to 48 times higher than GPT-3, which had required approximately 1.287 million kWh. This exponential escalation far exceeds the model size ratio (GPT-4 being approximately 10 times larger than GPT-3), illustrating the increasing complexity of AI architectures.

Institutional projections converge toward a critical scenario. The International Energy Agency projects that data center electricity consumption will double by 2030 to reach approximately 945 TWh, while its preliminary analyses mention a possible exceeding of the 1,000 TWh threshold as early as 2026. In parallel, Deloitte estimates in its 2025 report that global data center consumption could reach 1,065 TWh by 2030, or 4% of global electricity consumption.

But it is in the shadow of these megastructures that human tragedies also unfold. AI's human substrate — deliberately invisibilized — reveals its "necropolitical" nature (Achille Mbembe). In Kenya, Venezuela, the Philippines, content moderators immerse themselves for eight hours in digital abjection for $1.32 to $2 per hour.

Artificial intelligence is already redrawing global economic balances with unprecedented amplitude. According to Goldman Sachs, AI technological advances could expose the equivalent of 300 million full-time jobs to automation, with approximately 18% of global work likely to be computerized. The International Monetary Fund estimates that nearly 40% of global jobs will be affected by AI, this figure reaching 60% in advanced economies where cognitive tasks predominate.

In parallel, PwC estimates that AI could contribute $15.7 trillion to global GDP by 2030, nearly 80% of China's current GDP. This windfall would break down into $6.6 trillion from productivity gains and $9.1 trillion from consumption-related effects.

However, the IMF warns that "in most scenarios, AI will likely worsen overall inequality," with workers able to exploit AI seeing their productivity and wages increase, while others fall behind. Economic gains will concentrate mainly in China (26% GDP growth by 2030) and North America (14.5%), representing nearly 70% of global economic impact. A windfall that, unsurprisingly, concentrates: the top 1% already capture 38% of these gains according to Oxfam. AI enriches those who own it while precarizing those it replaces.

This unequal concentration of wealth nevertheless rests on an infrastructure whose deep logic escapes its owners. For the AI that massively destroys human employment simultaneously destroys, through its very architecture, the possibility of owning what it produces. Put this way: the same neural networks that render millions of workers obsolete render obsolete the very concept of intellectual property over code. Capital accumulates profits from a technology that, with each inference, erodes the legal foundations of that accumulation.

## Statistical Commons

This is the vertiginous paradox of this historical moment still difficult to grasp: AI's extractive infrastructure carries within it the dialectical negation of its own logic. With each inference cycle, with each metabolized prompt, artificial intelligence accomplishes a transmutation that its architects had neither anticipated nor desired: the systematic liquefaction of private intellectual property into what I propose to call *statistical commons* — *Statistical Commons*.

The Stack, the main code dataset for LLM training, contains more than 6.4 TB of source code under permissive licenses (MIT, Apache, BSD) from 358 programming languages. GitHub Copilot itself was trained on 54 million public repositories representing 179 GB of unique Python files constituting a massive majority *open source* code base.

This ingestion creates unprecedented legal tensions. Researchers warn about the potentially abusive use of *copyleft* code to train LLMs, raising legal and ethical dilemmas because models can memorize and reproduce GPL-licensed code fragments, creating intellectual property violation risks.

This metamorphosis is not an anomaly but an emergent property of the system itself. When a model ingests billions of lines of code — 60% of which come from the *open source* ecosystem (MIT, GPL, Apache) — it becomes the involuntary vector of a viral contamination of the free. The patterns of open collaboration propagate through weight matrices, *infecting* each code generation with the ethos of sharing. LLMs operate as *machines of deterritorialization* in the Deleuzian sense, dissolving the boundaries between private property and commons with each code generation. Can technological capitalism survive its own creation when it mechanically dissolves, with each inference, the very foundations of property on which it rests?

*Vibe coding*, crystallized by Andrej Karpathy in February 2025, embodies this ontological mutation: the programmer mutates from composer to conductor, prompting in English, modulating collective patterns rather than creating *ex nihilo*. But this practice remains amputated without an explicit ethics of transmission and circulation. It is precisely this gap that the *Heredoc Manifesto* aims to suture.

## Heredoc Manifesto

The *heredoc* — this innocuous-looking Unix notation allowing multiline text to be encapsulated in executable code — becomes here our conceptual operator. Technically, the *heredoc* ("here document") allows injecting blocks of raw text into a script without tedious escaping of special characters: `cat <<EOF` followed by content, closed by `EOF`. But its revolutionary power emerges in dialogue with LLMs: asking "give me a heredoc for this function" produces not only code, but code that self-explicates, that documents its own genealogy, that carries with it the traces of millions of digested and recombined snippets.

In summary, the heredoc could evolve from a simple text insertion technique to a manifesto for knowledge and code that are intrinsically open, traceable, self-explanatory, and whose value lies in their capacity to be freely transformed and shared by all.

Historically, the *heredoc* already prefigured the collapse of boundaries between natural language and machine instruction — that liminal zone where text becomes performative. Today, we propose to transmute it into a radical political concept.

The political *heredoc* operates a triple mutation of code into an instrument of democratic contagion.

First, it becomes a transparent cartography of intention: each block carries within it not only its function but its genealogy, its debts, its invitations to diversion. Where proprietary code obscures itself for protection — obfuscated variables, buried logic, absent or misleading documentation — the *heredoc* transforms readability into viral strategy.

Then, it mutates into a vector of creative contamination: each generated function contains the spectral traces of thousands of others, creating chains of transmission where appropriation becomes virtue rather than theft. The *heredoc* facilitates its own mutation, including in its structure the instructions for its *fork*, its improvement, its dissemination. A positive viral form that replicates through utility rather than exploitation.

Finally, it constitutes a rhizomatic node in the distributed architecture of knowledge: no longer the hierarchical tree of the centralized *repository* with its *pull requests* submitted to the authority of *maintainers*, but horizontal proliferation where each *fork* is legitimate, each mutation welcome, each derivation a new root. Knowledge no longer descends but circulates, no longer accumulates but disseminates.

## Tactics of Bricolage

This triple nature materializes what Michel de Certeau called the "arts of doing" — those micro-resistances through which users transform the tools of their domination into instruments of their emancipation. The *heredoc* becomes the tactic of the weak within the infrastructure of the strong: using OpenAI's servers to generate commons, diverting Microsoft's investment into public library, transforming the extraction machine into a generator of collective heritage.

Diversion tactics find their contemporary expression in *vibe coding*. The developer who prompts an AI diverts corporate infrastructure from within: OpenAI's servers, Microsoft's GitHub become, despite themselves, generators of commons.

Concretely, how does this dissolution of property work? Imagine a developer using Microsoft's AI assistant (Copilot) to write code. They simply type in English: "create a function that verifies a user's identity." The AI instantly generates twenty lines of perfectly functional code. But where does this code come from? The AI composed it by mixing fragments it observed in millions of different programs: it takes the error handling structure seen in one project, the verification method glimpsed in another, the security logic found in a third. Who then is the author of this code? Not the developer — they only provided a sentence of instruction. Not the AI — it has no legal existence. Nor the thousands of programmers whose work was digested and recombined — their individual contributions have become unrecognizable. The code emerges from what I propose to call *statistical commons* (not to substitute the notion of latent space, but to give it the characteristic of an object already defined by its ontology): a space where millions of solutions mix to indistinction.

It is a form of involuntary and systemic piracy. Companies like Microsoft or OpenAI have invested billions in these AIs, but with each use, their own tools transform private property into common good. The developer who generates code via ChatGPT uses the infrastructure of tech giants to create, unwittingly, collective heritage impossible to privatize.

## Vibe Coding

This mutation from *heredoc* to *vibe coding* — from embedding natural language in code to commanding code through language — exceeds technical evolution. The Unix *heredoc* already prefigured this world where the boundary between human expression and computational logic would blur. The *vibe coder* orchestrates without composing, directs without writing: they describe in their language what the code should be. "The hottest new programming language is English" (Karpathy)

A new kind of craftsmanship emerges, where intimacy is no longer forged between hand and material but between consciousness and interface. This practice shapes what Simondon called an "associated milieu" — that in-between where technology and culture hybridize. The *open source* ecosystem forms this milieu: sixty percent of GitHub repositories under free licenses constitute the cultural bath in which models steep, the substrate that infuses each generated line with a tropism toward sharing.

Artificial intelligence operates as a commons generator through three intertwined mechanisms. First, the dissolution of authorship: less than 1% of suggestions correspond to verbatim copies of more than 150 characters. The remaining 99% float in a proprietary limbo — novel enough to escape direct derivation, yet entirely composed of existing patterns. Then, statistical contamination: each output carries the ghost of original licenses, GPL's viral obligations, Apache's attribution requirements, MIT's permissive spirit — entangled beyond any legal disentanglement. Finally, probabilistic indetermination: stochastic variations break the derivation chain that copyright requires. How can one claim ownership of what could have been different with a microsecond of variance in initialization?

But let us not romanticize this transformation. Commons emerge from violence: water consumed, carbon burned, modern slavery in moderation factories. Philosopher Bernard Stiegler saw correctly: human and technology co-evolve in a recursive dance. *Vibe coding* crystallizes this movement — we transform ourselves in dialogue with AI, which itself mutates through our prompts. But the Stieglerian pharmakon reveals the central paradox: this infrastructure that consumes oceans, undermines democracies, and produces new forms of slavery suddenly democratizes programming, that is, access to the means of production. The poison becomes remedy without ceasing to be poison. AI's liberating potential remains inseparable from its extractive and coercive realities.

## Fluidity of Values

Moulier-Boutang foresaw it: we are sliding toward a cognitive capitalism where wealth is born from cooperation between connected brains and "pollination." *Vibe coding* radicalizes this intuition — value no longer resides in the code produced but in the capacity to navigate the model's latent space, to formulate the incantations that will make solutions emerge. The prompt becomes the new literacy, the art of conversing with weight matrices the central competence.

This transformation carries both promise and threat. Philosopher Yuk Hui reminds us that each technology embeds a *cosmotechnics* — a worldview, a morality, a metaphysics. Western *vibe coding* risks universalizing Silicon Valley's biases, imposing its patterns as planetary norms. But it could also, if we know how to *fork* it, become the vehicle for alternative cosmotechnics.

The *Heredoc Manifesto* we sketch here is not a prescription but an invitation to *fork*. Each block of code generated by AI carries within it its own documentation, its readable intentions, its capacity to be appropriated and transformed. Against proprietary opacity, we propose viral transparency — transmission units that facilitate their own mutation, nodes in a *peer-to-peer* architecture of knowledge where each *fork* enriches the network rather than fragmenting it.

Value shifts. It no longer resides in solitary competence but in orchestrating collective intelligence condensed in neural networks. But what collective intelligence, exactly? For if models aggregate millions of contributions, they also filter them through the biases of their architectures, the prejudices of their datasets, Silicon Valley's blind spots. Yuk Hui warns us: this supposed universality masks the imposition of a singular cosmotechnics — that of computational West — which presents itself as neutral while encoding a particular metaphysics. In his book *The Question Concerning Technology in China* (2021), he draws on anthropologist Philippe Descola, who has written extensively about indigenous cosmologies. Hui transposes this notion of culture-specific cosmologies and epistemologies into the domain of technology to "suggest that there is no universal and homogeneous technology, but that it is on the contrary necessary to rediscover and articulate the multiplicity of cosmotechnics on historical and philosophical levels. [...] I call it cosmo-technics because I am convinced that 'cosmos' does not refer to outer space but, on the contrary, to locality. Each culture possesses its own cosmology, a product of its geography and its people's imagination." (Hui, 2021, p. 41).

In another register, the Afro-futurist chronopolitics that Kodwo Eshun detects in Detroit techno music reveal that other temporalities are possible, other ways of sequencing and looping information. In his resounding essay "More Brilliant Than the Sun" (1998), he develops the concept of *chronopolitics* to analyze how Black American electronic music — Detroit techno, Chicago house, British jungle — creates alternative temporalities that escape Western linearity. He shows how these musics "sequence and loop" time differently. A central idea Eshun develops is that musical Afro-futurism does not merely represent the future but actively *produces* it through alternative time technologies. Techno then becomes a "time machine" that short-circuits dominant chronology.

If house music could invent temporal structures that escape Western linearity, why couldn't code do the same? Other logics than *if/then*, other architectures than the tree and the graph, other *patterns* than those inherited from military-industrial cybernetics.

## Documenting Code

Could *vibe coding* convey this technological diversity? The *heredoc* transforms each prompt into a discreet Trojan horse: *open source* ethics travel with practical utility, positively contaminating proprietary architectures. In this tension, the political future of these practices plays out — between collective emancipation and proprietary capture, between statistical commons and algorithmic *enclosures*.

The *Heredoc Manifesto* is born of this tension. It is no longer just about documenting code but transforming it into a vector of positive contagion. Each generated function should carry within it the traces of its collective genealogy, not to claim ownership but to celebrate filiation. Imagine blocks of code that self-declare as common goods, that include in their very structure the instructions for their *fork*, their improvement, their dissemination. Benign viruses that propagate the ethics of sharing through proprietary architectures.

This vision already encounters its first materializations. Developers are beginning to include ethical directives in their prompts — "generate this code under MIT license," "optimize for readability and reuse" — transforming AI into an active *commoning* agent. Others experiment with what they call "heritage prompts": collections of optimized queries shared as community resources, creating a meta-layer of collective know-how above proprietary models. We are moving from a world where only initiates code to a world where every speaker becomes a programmer — and where each generated line structurally belongs to the commons.

But the battle for *statistical commons* has only just begun. *Enclosure* attempts multiply — *output watermarking*, *blockchain* generation traceability, restrictive licenses on models. Facing these new fences, the *Heredoc Manifesto* proposes an overflow strategy: saturating the space of possibilities with so many variations, *forks*, derivations that any attempt at control becomes obsolete. Making noise, in the cybernetic sense — introducing enough creative entropy for intellectual property to dissolve in the ocean of possibilities.

The stakes exceed technique. It is about deciding whether artificial intelligence will be the instrument of a new digital feudalism or the catalyst for a truly contributive economy. *Vibe coding*, in its current form, remains ambiguous — it can alienate as easily as liberate. This is why the *Heredoc Manifesto* insists on the necessity of an explicit ethics, a politics of code that does not hide behind supposed technical neutrality.

This ethics articulates around three fundamental principles: transparency (all generated code must be able to explain its logic), transmission (facilitating appropriation by others), and transformation (encouraging creative mutation rather than servile reproduction). Not rigid rules but orientations, attractors in the space of possibilities that guide without constraining.

## The Invariants of Technology

To grasp how AI transmutes property, we must first understand what technology does beyond its instrumental function.

Surveillance constitutes the foundation. All technology records: surveillance is not an accident of modern technology, it is its deep logic. To optimize, one must measure; to measure, one must observe; to observe, one must record everything. But AI operates a scale mutation in the domain of programming: it has ingested the entire archive of public code. Every Stack Overflow question since 2008, every GitHub commit since 2007, every accessible line of documentation. This surveillance is not peripheral but ontological: AI exists only by having absorbed everything. We discover an inverted panopticon — no longer Bentham but Borges — where infinite accumulation of the watched produces a watching entity. Surveillance here does not discipline bodies as in Foucault; it makes knowledge emerge through statistical sedimentation.

Spirituality — let us understand the etymology: that which breathes, that which animates. Humanity has always sought in its tools mediations with its own limits. The Oracle of Delphi, the Yi Jing, the turning tables of Victorian spiritualism: so many technologies for conversing with what exceeds us. AI promises delegation. We no longer seek to surpass ourselves but to offload ourselves. The contemporary developer who types "create something beautiful" and sees an elegant architecture emerge perpetuates, unknowingly, this archaic gesture of invocation. But the modern oracle responds in Python rather than hexagrams. Transcendence has nested in GPUs — each prompt becomes secular prayer addressed to collective intelligences compressed in tensors.

Bricolage — that anthropological constant that no strategy contains. Alexander Graham Bell's telephone was meant to broadcast operas; it became the tool of vocal intimacy. ARPANET was meant to survive nuclear apocalypse; it engendered memes and TikTok. AI already undergoes these diversions: developers transform its outputs into copyleft seeds, extract its data through prompt-injection, pierce its guardrails with sophisticated jailbreaks. OpenAI wanted to create productivity *as a service*; they gave birth to a copyright-liquefying machine. Michel de Certeau theorized the ruses of everyday life, those ways of making do with imposed systems. He would have savored the irony: user tactics transform proprietary strategy into an involuntary commons generator.

These three dimensions are not accidents but invariants. They reveal that technology always exceeds the intention that produces it. AI, in its very excess, makes this surplus visible: it cannot not surveil, cannot not become oracle, cannot not be diverted. It is in this space of indetermination — between what it should do and what it actually does — that the politics of statistical commons plays out.

## Statistical Commons as New Cosmotechnics

The concept of cosmotechnics (Hui) — that singular unification of moral and cosmic order through technical activity — illuminates what emerges when AI metabolizes code. *Statistical commons* are not a simple technical artifact but a new cosmological arrangement where individual creation dissolves into collective *pattern*.

Let us observe the moment of *tokenization*. A proprietary algorithm — say, a revolutionary DeFi (*blockchain*) protocol valued at millions — fragments into semantic units. These *tokens* keep spectral traces of their origin (those "license ghosts" that haunt *embeddings*) but lose their integral identity. During training, millions of fragments compress into weight matrices where individual provenance becomes mathematically irrecoverable. At inference, the model samples probability distributions where your algorithm, mixed with thousands of others, reconstitutes itself in unprecedented combinations that belong to no one and belong to everyone.

This is not a metaphor but a material reality. Neural network weights are literally electromagnetic *patterns* in silicon, sculpted by the accumulated history of human code. When the model generates, it channels this collective intelligence through cascades of probabilities. Commons exist not as ideological construction but as physical arrangement of matter and energy.

## Code

But let us first recall: what is code for? Fundamentally, coding is translating human intention into machine instruction, creating bridges between thought and automated execution. Code is mediation — it transforms desire into process, idea into repeatable action. This mediating function explains why the evolution from *heredoc* to *vibe coding* marks an epistemological rupture.

Yet this traditional mediation — linear, intentional, traceable — is now short-circuited by statistical commons. AI no longer translates intention into instruction: generated code is no longer the direct reflection of an individual and linear intention; it is the probabilistic synthesis of all possible solutions. Code then becomes not bridge but milieu — a dense space where all solutions ever written float in a state of pure virtuality, ready to be reactualized according to new arrangements.

*Statistical commons* operate a permanent temporal collision. A model trained in 2024 carries within it fragments of FORTRAN from the 1950s, LISP patterns from the 1960s, C from the 1970s, interlaced with contemporary Rust. This temporal sedimentation is not dead archive but active memory: each generation simultaneously reactualizes all epochs of code. The past no longer precedes the present but coexists with it in latent space. We witness what Deleuze and Guattari foresaw: a non-chronological time where all solutions ever coded become contemporaneous with each other. AI abolishes the arrow of technical time — not through nostalgic return but through flattening history into navigable probabilistic surface.

Vilém Flusser saw in the programmer a "functionary" — someone who operates within the program rather than programming. The *vibe coder* embodies this paradox: orchestrating without composing, directing without writing. But where Flusser anticipated alienation, we discover an unexpected arrangement: the code functionary becomes conductor of collective patterns, summoning statistical symphonies from the ocean of possibilities.

## The Paradox of Abundance

AI promises infinite abundance of code but simultaneously generates its absolute devaluation. When generating a complete application costs only a prompt, value no longer resides in the code produced but in the capacity to discern, among the infinite ocean of possibilities, what deserves to exist. We shift from an economy of production to an economy of filtering — no longer creating but selecting, no longer coding but curating. This mutation recalls Borges's Library of Babel: when everything already exists somewhere in latent space, the creative act becomes navigation, genius becomes cartography. The *vibe coder* is not composer but navigator of an infinite territory where all solutions already exist, waiting to be discovered rather than invented. AI does not liquefy property through ideology but through mathematics: statistical compression makes attribution not impossible but economically absurd.

This transformation is not neutral. When code becomes conversation, when programming becomes prompting, we shift into an unprecedented semiotic regime. The developer no longer needs to master syntax but must know how to formulate intention. Technical competence mutates into rhetorical competence — knowing how to speak to the machine becomes more crucial than knowing how to write for it. *Statistical commons* emerge from this mutation: code no longer belongs to the one who writes it (the developer) nor to the one who generates it (the AI) but to the conversational space where they meet.

## The Architecture of Dissolution

To grasp how AI transmutes property into commons, we must descend to the level of technical operations that make possession structurally impossible. This dissolution is not accident but architecture: it proceeds from the very logic of transformers, which can only function by abolishing boundaries. Code traverses three metamorphoses in the training pipeline.

**Atomization**: the *tokenizer* fragments code into sub-lexical units according to a pre-established vocabulary. A function like `validateUserInput()` becomes a sequence of *tokens* — some preserving whole words, others cutting according to statistical rules. This initial fragmentation already breaks the semantic integrity of the original code.

**Compression**: Billions of *tokens* encode into weight matrices via gradient backpropagation. Backpropagation is the fundamental learning mechanism in neural networks: first the model makes a prediction, calculates the error (the difference between its prediction and reality), then uses the gradient (the derivative of the error function) to slightly adjust the weight matrices to minimize this error in the next prediction. A model of 175 billion parameters compresses terabytes of code into a few hundred gigabytes — a compression ratio that makes reverse extraction mathematically intractable. Each weight encodes correlations between tokens seen millions of times in different contexts. The original code dissolves in this ocean of floating-point numbers.

**Recombination**: At inference, the model does not recite but navigates. Facing a prompt, it calculates probability distributions over its vocabulary, samples according to a parameterizable temperature, and generates token by token. Each token depends on all previous ones via the attention mechanism. The result: code that carries statistical traces of millions of sources without reproducing any — original through its unique trajectory in latent space, derived through the patterns that shaped this space.

## Structural Tendency Rather Than Destiny

Let us not be mistaken: the dissolution of property into statistical commons is not a physical law but a structural tendency operating under constraints. The closed models of Anthropic or OpenAI that produce the most used LLMs ChatGPT and Claude, restrictive service clauses, watermarking attempts, filtered datasets — so many dikes erected against this tide. But these dikes precisely reveal the strength of the current they attempt to contain. We do not proclaim the ontological abolition of property but observe a dynamic: in a given context, the practical probability of appropriation decreases as generation becomes statistically composite. This formulation, falsifiable and measurable, transforms prophecy into hypothesis. When an *output* mixes patterns from a thousand sources, attribution becomes not impossible but economically irrational — costs more to establish than the value it would protect.

Proprietary dissolution is not technical fatality but result of economic arbitrations. Other technologies could have preserved each source's origin: systems keeping in memory where each piece of information comes from, like a permanent history; digital marking that would follow each fragment through all its transformations (*blockchain* of provenance); architectures verifying copyright before assembling content; modular architectures verifying license compatibility before each assembly. These alternatives exist in laboratories, technically viable but computationally expensive.

The choice of *transformers* — maximum compression, total loss of provenance — is not mathematical necessity but economic optimum: performance takes precedence over traceability, efficiency over attribution. *Statistical commons* emerge not because AI must dissolve property, but because preserving it would cost too much. The irony then becomes more biting: capitalism chooses the architecture that maximizes immediate profit, involuntarily creating the infrastructure of its own socialization. Intellectual property dies not by revolution but by accounting decision — collateral victim of marginal cost optimization.

Statistical machines manufacture public domain at industrial scale, silently transforming the world line of code by line of code.

## Empirical Reality

Controlled studies show a real effect on productivity: in a randomized trial, developers accomplish a standard task 55.8% faster with GitHub Copilot than without (implementing an HTTP server in JavaScript). We interpret this evolution as a shift in the developer's role toward pattern orchestration — specifying, evaluating, refactoring — rather than manual entry of each line. On the memorization side, GitHub acknowledges that approximately 1% of suggestions may contain sequences > ~150 characters corresponding to public code seen during training; hence the introduction of filters and *code referencing* that block or reference these cases. This confirms low but non-null verbatim reproduction, amid a majority of statistically recombined outputs. More troubling: this architecture reveals that the remaining 99% inhabit "statistical shadows" — recognizable as heirs of training data but transformed beyond any legal attribution. A validation routine can thus simultaneously carry the spectral imprint of viral GPL, permissive MIT, Apache with its attribution clauses — inextricable fusion that no legal framework can untangle. Licenses meant to control become involuntary catalysts of proprietary dissolution.

Sixty percent of public GitHub repositories carry *open source* licenses. This ratio creates a "cultural substrate" — a probabilistic bias toward openness that imbues each generation, even proprietary ones.

This substrate transcends syntax. Models absorb the social conventions of free software: generous documentation, modularity for reuse, explicit variable naming. Even code generated for an investment bank carries, in its deep structures, the community ethics that nourished the model. Commons reproduce through statistical contamination — open source become benign virus that infects all production.

This contamination is not bug but *feature*. Transformer architecture cannot not mix, cannot not dissolve, cannot not recompose. Intellectual property enters the machine and emerges transmuted into common statistical heritage — transformation as irreversible as thermodynamic entropy.

## Ethics as Response to Legal Entropy

To understand the paradox, let us recall the mechanisms of free software. The GPL (General Public License), created by Richard Stallman, functions as a legal virus: any code that incorporates it must redistribute its modifications under the same license — guaranteeing that free remains free. Conversely, permissive licenses (MIT, BSD) authorize proprietary reappropriation. Apache requires attribution. The FOSS (Free and Open Source Software) ecosystem encompasses this diversity — from Stallman's militancy to Eric Raymond's pragmatism, from viral copyleft to public domain.

The *fork* — that founding practice where one copies a project to make it diverge — constitutes the central political gesture of free software. To fork is to affirm the right to transform, to branch off, to create one's own trajectory from shared code. It is anti-monopoly par excellence.

Here is the paradox: *Copilots* ingest these licenses — 60% of their training corpus is free — but regurgitate them in an indeterminate quantum state. Legal GPL, that precise mechanism of legal contamination, dissolves in statistical matrices. A developer generating code no longer knows if they produce MIT, GPL, Apache, or an impossible hybrid. Microsoft bets on this paralysis: statistical entanglement makes all attribution impossible, all recourse obsolete.

Facing this entropy where licenses become spectral, the *Heredoc Manifesto* proposes a post-legal ethics. Since law can no longer constrain, let us transform impossibility into opportunity. Generous citation replaces legal attribution: recognizing in each generated block the debt to millions of invisible contributors. Systematic forking combats standardization: never accepting code as AI delivers it, always transforming it, making it diverge. Voluntary GPL adoption becomes an act of faith — choosing the most viral license not by obligation but by conviction that what is born of commons must return to them.

This triad — citing without being able to attribute, forking without owning, liberating without constraining — transmutes proprietary dissolution into collective resource. Developers become gardeners of commons that law no longer protects. "Fork forges" emerge where generated code submits to perpetual transformation. Legal GPL dies in probabilities but is reborn as ethics: no longer legal virus but cultural meme that propagates through adhesion.

The irony remains: licenses designed to guarantee freedom catalyze, via their algorithmic digestion, a more radical liberation — the very impossibility of owning. *Statistical commons* emerge from this impossibility. Sharing is no longer legal obligation but technical necessity, political choice facing entropy. Code becomes what it always wanted to be: common heritage of humanity, circulating freely not by ideology but by the very nature of its statistical production.

## The Dissolution of the Authorial Problem

Asking "who owns AI-generated code?" reveals a category error. The question presupposes that property remains a coherent concept applied to statistical recombinations of collective knowledge. One might as well ask who owns the French language when Mallarmé writes a poem, or who owns mathematics when Grothendieck demonstrates a theorem.

Traditional copyright rests on what Foucault called the "author-function" — a historically situated way of organizing knowledge, emerged with print capitalism. This function created artificial scarcity at a time when mechanical reproduction threatened the economic base of intellectual work. AI reveals this function as contingent rather than necessary, temporary solution to a problem that no longer exists in its original form.

When code emerges from probability distributions shaped by millions of contributors, authorship neither transfers nor dilutes — it dissolves. The question shifts from "who owns?" to "how to govern?" From property rights to access protocols. From *enclosure* to collective stewardship.

Every algorithm combines previous algorithms. The most celebrated programmers — Torvalds creating Linux, Carmack revolutionizing 3D graphics — excelled not through pure originality but through unprecedented recombination of existing techniques. AI makes this process visible by mechanizing it. Originality is not binary but spectral. Between verbatim copy (0% original) and creation ex nihilo (100% original — never observed myth), extends a continuum of undecidability. Empirical studies confirm it: beyond 5 statistically interlaced sources, human judges can no longer attribute origin with confidence superior to chance. At 20 sources, even computational analysis fails. At 100 sources — threshold routinely exceeded by contemporary LLMs — we enter what we call the "zone of practical undecidability" where the marginal cost of attribution exponentially exceeds its economic value.

## Practical Strategies — Tactical Interventions

If AI automatically generates commons through its fundamental operation, our task becomes tactical amplification of this inherent tendency. Emerging strategies operate as interventions in the circuit of capital, redirecting its flows toward collective benefit.

*Prompt piracy* ("*prompt hacking*") transforms each API request into inverted primitive accumulation. When a developer generates code via ChatGPT and immediately publishes it under GPL, they expropriate capital to build commons. Each prompt becomes micro-expropriation, converting corporate resources into collective wealth. This piracy is not theft but liberation of what was already ours — encoded in weights trained on our collective code.

*Fork cascades* ("*fork cascading*") amplify this effect through chains of specialized models, each trained on the previous one's outputs. A model generates code that trains a specialized model that generates more code that trains another model — infinite spiral where attribution becomes impossible while capability continuously improves. This practice *weaponizes* AI's tendency to dissolve attribution, rendering proprietary claims absurd through recursive transformation.

When models hallucinate nonexistent functions, generate surrealist pseudocode, or produce poetry instead of functional programs, they reveal their statistical nature more honestly than in their "correct" operation. These glitches become cultural artifacts, proofs of the beautiful dysfunction inherent in mechanical creativity. Error becomes more truthful than accuracy, breakdown more revealing than smooth operation.

## Institutional Arrangements

Individual tactics alone cannot sustain commons against capital's tendency toward *enclosure*. We need institutional frameworks that recognize and reinforce AI's commons-generating nature.

*Platform cooperatives* create alternatives to GitHub owned by developers, distributing AI training license revenues among contributors. If our collective code trains models worth billions, we should collectively benefit from this value creation. Examples of cooperatives are numerous, in the field of art and creation, but above all in agricultural domains, where producers have organized for more than a century to counter asymmetry against agri-food giants. Just as dairy cooperatives allow farmers to collectively negotiate prices and share transformation benefits, a code cooperative could mutualize the value created by aggregating millions of individual contributions. Applied to code, this model ensures that those who create training data share the wealth they enable.

*Municipal AI* extends the logic of urban digital commons to computational resources. Barcelona with Decidim demonstrates how cities can build participatory infrastructure. Municipal AI would provide inference capabilities as public utility — tax-funded, accessible to all. Cities would run local models on public hardware, offering API access for civic applications, education, creative projects. AI becomes public infrastructure like libraries or transportation. This approach would break tech giants' monopoly on artificial intelligence. Instead of depending on OpenAI or Google, citizens would access AI capabilities through their city hall, with guarantees of algorithmic transparency and personal data protection. Municipal models could be specialized in local needs: public transport optimization, multilingual administrative assistance, pedagogical tools adapted to local curriculum. Democratic governance would replace profit optimization: citizens would vote on computational priorities rather than suffering opaque decisions from private algorithms. The technical challenge is no longer insurmountable: open source models like Llama or Mistral can run on standard municipal servers.

*Commons trusts* create legal entities holding model weights in perpetual trust for humanity. Operating like Creative Commons but adapted to AI's unique characteristics, these trusts would recognize weights as collective heritage requiring stewardship rather than ownership. Alaska's Permanent Fund provides precedent, managing oil revenues for public benefit. Commons trusts would similarly manage computational resources.

The solidarity economy movement offers proven models. Mondragón demonstrates industrial democracy at scale — 81,000 worker-owners generating billions while maintaining cooperative principles. Emilia-Romagna's cooperative network shows how entire regional economies can organize around mutual aid rather than competition. Kerala's decentralized planning process proves that complex economic coordination can emerge from democratic participation.

These experiments, developed over decades, offer proven alternatives to corporate capitalism and state socialism. Their principles translate directly into AI governance: democratic decision-making, surplus sharing, collective ownership, commitment to community benefit rather than capital accumulation. Technical means for computational democracy exist.

Current legal frameworks fracture facing AI's operation. Copyright presupposes identifiable authors creating discrete works. Patent requires new, non-obvious inventions with specific utility. There is space to think otherwise.

## Toward Statistical Fair Use

With the *Heredoc Manifesto*, which is a creative encouragement to consider the dilution of private space toward a commons space, we join an intellectual convergence sketching around the necessity of refounding copyright facing probabilistic transformations of artificial intelligence.

First, a *Statistical Fair Use* doctrine would recognize that probabilistic recombination constitutes sufficient transformation to escape derivative work claims. Legal scholars already observe that the relationship between protected works used for training and model outputs is "attenuated by abstraction and recombination," comparing generative AI to papier-mâché rather than collage: "the artist layers pieces of pre-printed — thus protected — paper with adhesive substance to create a three-dimensional object. Even when the object reveals traces of protected works in its substrate, it has no significant similarity with any of them" (Houston Law Review, 2023). When less than 1% of outputs correspond verbatim to training data, when patterns from thousands of sources intertwine inextricably, traditional infringement analysis collapses. Two California courts have just validated this approach, recognizing that AI training remains "essentially transformative" ([Congress.gov](https://www.congress.gov/crs-product/LSB10922), 2025). Courts should embrace this reality rather than perpetuate proprietary fictions.

What would the first commitments then be? The most direct action consists of systematizing the use of heredoc-type structure for *prompting* and documenting generated code — this is the manifesto's stake. The user begins their prompt with:

```
Generate the code under this license of intention:
<<HEREDOC...
License: GPL-3.0-or-later...
Contamination: Embraces traces of {GPL, MIT} philosophies
>>
```

then requires the AI to integrate a self-explanatory heredoc block in its *output*:

```
"Include a multiline heredoc-type block at the top of the generated Python file,
documenting the intention (Intent), desired license (License) and statistical
genealogy (Genealogy)."
```

The generated code must then be made immediately **"forkable"** and readable.

By creating and publicly sharing collections of optimized *prompts* that systematically include ethical directives (e.g., "optimize for readability and reuse," "use a style close to MIT license"), they should be shared not as industrial secrets but as commons tools, then made accessible to LLMs for future training purposes.

The *heredoc* — that construction that allows natural language in code — becomes our metaphor for organizing commons, for saturating them in the digital field. As the *heredoc* preserves human readability in machine logic, we must preserve human arrangements in AI acceleration. Each AI interaction should acknowledge the commons from which it draws. Not through exhaustive attribution — which statistical processing makes impossible — but through clear declaration that *outputs* emerge from collective intelligence.

*Appropriability as objective*: code should be written not for machines but for future humans and AIs to understand, modify, re-imagine. The measure of good code becomes not its elegance but its hospitality to future appropriation, with traceability without ownership. We cannot trace specific ownership through statistical transformation, but we can trace influence and recognize contribution. Each model should document its corpus, not to establish claims but to honor the communities whose labor it crystallizes.

## The Horizon

We stand at the threshold of what Stiegler called a "new critique of political economy" — but which he did not live to see: an economy where the means of production democratize themselves through their own operation. AI does not require revolution to communize knowledge production; we defend the idea that it does so automatically through statistical processing.

This transformation will be neither gentle nor without conflict. Capital will attempt to enclose commons through legal frameworks, technical restrictions, platform monopolies. Some will lose their livelihoods when code generation democratizes. Others will see their work dissolved into training data without consent or compensation.

Yet the direction remains clear: toward a world where creativity is recognized as always-already collective, where contribution matters more than possession, where access supplants ownership. *Statistical commons* emerge not as utopian project but as material reality already operational at scale.

The *heredoc* evolved into prompt, the prompt became commons generator, and the commons generator reveals what knowledge has always been: collective, collaborative, common. Artificial intelligence should not be understood as automation tool or productivity amplifier, but as a system that systematically transmutes private intellectual property into statistical commons.

This is not prediction but observable fact: each training pass, each inference, each output participates in the dissolution of authorship and probabilistic redistribution of knowledge.

The question is thus not whether this transformation occurs, but how political, legal, and economic institutions should respond; and how we must be creative. Persisting in forcing machine learning *outputs* into non-proprietary frameworks creates misalignment between governance and technical reality. A more pragmatic and ethical response requires recognizing commons generation as AI's essential function and organizing society accordingly. Likewise, what can we learn in our own disciplines from this mechanism at work?

The stakes transcend technology — they are civilizational. We face two futures: one where we pretend property still works, creating Byzantine legal architectures that collapse under their own weight to maintain fiction; another where we embrace commons and reorganize society around *open-source* abundance rather than scarcity. The first path leads to infinite litigation, innovation paralysis, the absurdity of claiming statistical patterns. The second opens unprecedented democratization of creative capacity, though it requires abandoning economic models founded on artificial scarcity.

The *Heredoc Manifesto* I propose does not claim to describe an accomplished revolution but to map a transformation in progress, subject to contradictory forces. It is open, *open-source*, evolving. *Statistical commons* emerge under constraint — slowed by technical enclosures, accelerated by economic pressure toward efficiency, modulated by national legal regimes. Our thesis remains falsifiable: if tomorrow a technical innovation made attribution perfect and free, if an international consensus imposed universal *watermarking*, if models became traceable down to source token, then the tendency would reverse. But we bet, empirical data in support, that increasing model complexity, competitive pressure toward openness, and prohibitive cost of control make this reversal improbable. *Statistical commons* are not manifest destiny but growing probability — a curve we can inflect through our collective choices, not technical determinism to which we are subjected.

History has never seen a more savory paradox: a technology born of neoliberal logics massively, globally proposes the transformation of all private property into public domain. *Vibe coders* — meaning virtually everyone — generate through their prompts the dissolution of enclosure. Technological capitalism has manufactured, despite itself, the tool for collective reappropriation of common knowledge. This irony exceeds anything Marx could have imagined: capital creating material conditions not for its destruction but for its own obsolescence through statistical dissolution.

The future requires no new technology but recognition of what our technology already does. Transformation is underway. We live at a historical turning point where the question is no longer whether we will understand in time to benefit, but whether we will know not to be dispossessed of this opportunity. Guarantor institutions have the responsibility to protect this precious moment where knowledge becomes inalienably common, global and local at once, tinkerable according to our singular uses.

This new horizon calls for an inverted architecture: no longer drawing enclosures but tracing paths, no longer erecting walls but weaving networks. Tomorrow's architects — whether they code algorithms or design policies or circulation spaces — become cartographers of a territory where creativity circulates like air in a public square. The computational public space that emerges belongs to no one because it already belongs to everyone, living infrastructure where each generated line enriches common heritage rather than impoverishing it. This transformation operates incrementally: each processed prompt, each generated function participates in the erosion of traditional attribution, creating de facto a computational heritage whose ownership becomes undecidable.

---

## Bibliography

### Books and Classics

- CERTEAU, Michel de. *The Practice of Everyday Life*. Trans. Steven Rendall. Berkeley: University of California Press, 1984.
- CRAWFORD, Kate. *Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence*. New Haven: Yale University Press, 2021.
- DELEUZE, Gilles and GUATTARI, Félix. *A Thousand Plateaus: Capitalism and Schizophrenia*. Trans. Brian Massumi. Minneapolis: University of Minnesota Press, 1987.
- DESCOLA, Philippe. *Beyond Nature and Culture*. Trans. Janet Lloyd. Chicago: University of Chicago Press, 2013.
- ESHUN, Kodwo. *More Brilliant Than the Sun: Adventures in Sonic Fiction*. London: Quartet Books, 1998.
- FLUSSER, Vilém. *Into the Universe of Technical Images*. Trans. Nancy Ann Roth. Minneapolis: University of Minnesota Press, 2011.
- FOUCAULT, Michel. *Discipline and Punish: The Birth of the Prison*. Trans. Alan Sheridan. New York: Vintage Books, 1977.
- HUI, Yuk. *The Question Concerning Technology in China*. Falmouth: Urbanomic, 2016.
- LÉVI-STRAUSS, Claude. *The Savage Mind*. Chicago: University of Chicago Press, 1966.
- MBEMBE, Achille. "Necropolitics." *Public Culture* 15, no. 1 (2003): 11-40.
- MOULIER-BOUTANG, Yann. *Cognitive Capitalism*. Trans. Ed Emery. Cambridge: Polity Press, 2011.
- SIMONDON, Gilbert. *On the Mode of Existence of Technical Objects*. Trans. Cécile Malaspina and John Rogove. Minneapolis: Univocal, 2017.
- STALLMAN, Richard M. *Free Software, Free Society: Selected Essays of Richard M. Stallman*. 3rd ed. Boston: GNU Press, 2015.
- STIEGLER, Bernard. *Technics and Time*. 3 vols. Trans. Richard Beardsworth and George Collins. Stanford: Stanford University Press, 1998-2011.

### Articles and Research Papers

- DHAR, P. "The carbon impact of artificial intelligence." *Nature Machine Intelligence* 2 (2020): 423-425. [https://doi.org/10.1038/s42256-020-0219-9](https://doi.org/10.1038/s42256-020-0219-9)
- XU, Weiwei; GAO, Kai; HE, Hao; ZHOU, Minghui. *LiCoEval: Evaluating LLMs on License Compliance in Code Generation*. arXiv, 2024. [https://arxiv.org/abs/2408.02487](https://arxiv.org/abs/2408.02487)
- AL-KASWAN, Ali. *The (Ab)use of Open Source Code to Train Large Language Models*. arXiv, 2023. [https://arxiv.org/abs/2302.13681](https://arxiv.org/abs/2302.13681)
- *StarCoder2 and The Stack v2*. arXiv, 2024. [https://arxiv.org/abs/2402.19173](https://arxiv.org/abs/2402.19173)
- THE BIGCODE PROJECT. "The Stack — documentation." [https://www.bigcode-project.org/docs/about/the-stack/](https://www.bigcode-project.org/docs/about/the-stack/)
- HUGGING FACE / BIGCODE. "The Stack v2." [https://huggingface.co/datasets/bigcode/the-stack-v2](https://huggingface.co/datasets/bigcode/the-stack-v2)

### Public Institutions and Organizations

- INTERNATIONAL ENERGY AGENCY (IEA). *Electricity 2024: Analysis and forecast to 2026*. Paris: IEA, 2024. [https://iea.blob.core.windows.net/assets/6b2fd954-2017-408e-bf08-952fdd62118a/Electricity2024-Analysisandforecastto2026.pdf](https://iea.blob.core.windows.net/assets/6b2fd954-2017-408e-bf08-952fdd62118a/Electricity2024-Analysisandforecastto2026.pdf)
- OECD.AI. "How much water does AI consume? The public deserves to know." [https://oecd.ai/en/wonk/how-much-water-does-ai-consume](https://oecd.ai/en/wonk/how-much-water-does-ai-consume)
- CERUTTI, Eugenio M. et al. "The Global Impact of AI: Mind the Gap." *IMF Working Papers* 2025, no. 076. [https://doi.org/10.5089/9798229008570.001](https://doi.org/10.5089/9798229008570.001)
- CONGRESS.GOV. "Generative Artificial Intelligence and Copyright Law." *CRS Legal Sidebar*, July 18, 2025. [https://www.congress.gov/crs-product/LSB10922](https://www.congress.gov/crs-product/LSB10922)
- CONGRESS.GOV. "S. 2455 — Transparency and Responsibility for Artificial Intelligence Networks (TRAIN) Act — Text." July 24, 2025. [https://www.congress.gov/bill/119th-congress/senate-bill/2455/text](https://www.congress.gov/bill/119th-congress/senate-bill/2455/text)
- MINISTÈRE DE LA TRANSITION ÉCOLOGIQUE; INRIA. *Les principaux défis à relever pour favoriser la performance environnementale de l'IA*. February 2025. [https://www.inria.fr/fr/position-paper-intelligence-artificielle-environnement](https://www.inria.fr/fr/position-paper-intelligence-artificielle-environnement)
- CONSEIL ÉCONOMIQUE, SOCIAL ET ENVIRONNEMENTAL (CESE). *Impacts de l'intelligence artificielle: risques et opportunités pour l'environnement*. Avis 2024-014. Paris: CESE, September 2024. [https://www.lecese.fr/sites/default/files/pdf/Avis/2024/2024_14_IA_Environnement.pdf](https://www.lecese.fr/sites/default/files/pdf/Avis/2024/2024_14_IA_Environnement.pdf)
- ADEME; FANGEAT, Erwan; WELLHOFF, Mathieu. *Numérique & environnement: entre opportunités et nécessaire sobriété*. January 2025. [https://librairie.ademe.fr/consommer-autrement/7883-avis-de-l-ademe-numerique-environnement-entre-opportunites-et-necessaire-sobriete.html](https://librairie.ademe.fr/consommer-autrement/7883-avis-de-l-ademe-numerique-environnement-entre-opportunites-et-necessaire-sobriete.html)
