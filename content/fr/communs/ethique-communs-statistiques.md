---
title: "L'Éthique des Communs Statistiques"
translation: "/en/commons/ethics-statistical-commons"
author: "Sylvain Couzinet-Jacques"
date: 2025-10-01
lang: fr
license: GPL-3.0-or-later
provenance: "Extension du Heredoc Manifesto"
tags:
  - statistical-commons
  - _negentropic
  - tactical
  - AI-ethics
  - biology
  - copyleft
  - GPL
  - _enclosure
  - commons
  - _model-collapse
  - _entropy
  - _attribution
  - _dissolution
  - _training
  - _weights
  - _probability-distributions
  - _retcon
  - _black-mountain-college
  - _vibe-coding
  - _Andrej-Karpathy
  - _Tiziana-Terranova
  - _Mark-Coeckelbergh
  - _Elinor-Ostrom
  - _data-colonialism
  - _Nick-Couldry
  - _Ulises-Mejias
  - _C2PA
  - _SynthID
  - _watermarking
  - _RAG
  - _federated-learning
  - _counter-reformation
  - _RepRap
  - _germplasm
  - _landraces
  - _pharmakon
  - _heredoc
  - _computational-futurality
  - _recursive-loop

---



<details class="heredoc-block">
<summary>◈ ETHIQUE-COMMUNS-STATISTIQUES v1.0</summary>

**Titre :** L'Éthique des Communs Statistiques 
**Auteur :** Sylvain Couzinet-Jacques  
**Date :** 2026  
**Intention :** Développer la notion de communs statistiques présentée dans Heredoc Manifesto
**Provenance :** Extension de Heredoc Manifesto
**Généalogie :** Heredoc Manifesto → Coeckelbergh (Éthique de l'IA) → Terranova (After the Internet) → Ostrom (Governing the Commons) → OSSI (Open Source Seed Initiative)  
**Éthique :** Transparence · Transmission · Transformation  
**Licence :** GPL-3.0-or-later (retour volontaire aux communs)  
**Chaîne de forks :** [Heredoc Manifesto] → actuel → [en attente du prochain fork]  
**Contamination :** Embrasse les traces des philosophies {GPL, MIT, Apache, BSD, OSSI-Pledge}  
**Confiance :** Cadre normatif ancré dans la transformation ontologique, non dans la prédiction  
**Notes :** Ce que l'IA dissout mécaniquement, l'éthique doit l'orienter politiquement  

*Cet article a été originellement rédigé en anglais avec l'assistance du LLM Mistral 7B.*

</details>


---

## Préface : Du Vibe Coding aux Semences

Le Heredoc Manifesto est né d'une observation : l'engouement soudain pour ce qu'Andrej Karpathy a appelé le « *vibe coding* » — programmer par des *prompts* en langage naturel plutôt que par une syntaxe traditionnelle — révélait quelque chose de plus profond qu'un nouveau *workflow*. Lorsque des millions de personnes ont commencé à générer du code par l'IA conversationnelle, une transformation structurelle était en cours, largement inaperçue de ses participants.

Initialement, on m'avait demandé d'écrire un court essai sur l'IA et l'architecture — une réflexion sur les espaces publics et les technologies susceptible d'informer les approches pédagogiques à l'ENSA Paris-Est. Ce qui avait commencé comme une enquête architecturale est devenu autre chose : un examen de la manière dont le mécanisme même des grands modèles de langage dissout la propriété intellectuelle discrète en distributions statistiques. Le code que je générais, le code que tout le monde générait, existait dans un étrange limbe propriétaire — n'appartenant à personne parce qu'il appartenait aux données d'entraînement de tous, transformé au-delà de toute attribution. Il y avait là quelque chose qui touchait aux fondements mêmes de l'architecture et de l'urbanisme : les principes organisant l'espace privé et public étaient réécrits au niveau de l'information elle-même, une nouvelle topologie où l'enclosure échoue non par la lutte politique mais par la transformation technique.

Cette dissolution est devenue, pour moi, l'illustration d'une tactique inverse : et si le mécanisme que les corporations déploient pour le profit produisait par inadvertance des communs ? Non sans risques, certainement — la même infrastructure extrait des données personnelles, concentre le pouvoir, consomme de vastes ressources. Mais la possibilité demeurait.

Parmi les questions que cela soulevait, l'une s'est révélée inépuisable : l'éthique de l'intelligence artificielle. Un sujet trop profond pour un seul essai, requérant peut-être plusieurs livres et des années d'études. Je me suis retrouvé à revenir au Black Mountain College — cette expérience de pédagogie expérimentale où je mène mes recherches doctorales — en me demandant comment les technologies d'aujourd'hui pourraient garantir l'existence sûre et autonome que ses membres recherchaient. À Black Mountain, la ferme était centrale : non pas simplement la production alimentaire mais une garantie d'indépendance institutionnelle, un substrat matériel pour la liberté pédagogique.

J'ai commencé à imaginer comment les « communs statistiques » que j'essayais de définir pourraient s'appliquer à des instances plus physiques. Les semences, les graines se sont présentées comme paradigmatiques. Si le code et l'agriculture semblent des pratiques distantes, peut-être partagent-ils quelque chose d'essentiel : tous deux peuvent être enclos par le monopole, et tous deux peuvent s'échapper vers les communs. La socialisation de la production de connaissances par des plateformes d'IA quasi-monopolistiques pourrait, paradoxalement, pousser vers des éthiques plus locales, résilientes, voire *low-tech* — une garantie d'autonomie précisément parce qu'elle opère au-delà de la gouvernance numérique.

Ce chapitre tente cette connexion : du *vibe coding* aux semences, de la dissolution du code en poids à la propagation du germoplasme à travers le sol.

---

## Résumé

Ce chapitre développe un cadre normatif pour les communs statistiques — le domaine qui émerge lorsque l'entraînement de l'IA dissout la propriété intellectuelle discrète en distributions de probabilités où l'attribution devient impossible. Prolongeant l'analyse descriptive du Heredoc Manifesto, nous proposons trois contributions : un cadre de valence différentielle (le même processus technique produit des significations éthiques distinctes selon l'orientation préalable des matériaux sources) ; un compte rendu de l'obligation négentropique (éthique écologique pour des systèmes qui se dégradent par l'entropie plutôt que par la surexploitation) ; et une éthique de l'urgence tactique (la fenêtre d'opportunité permettant les communs statistiques est temporaire et se referme). Nous illustrons par les semences agricoles — un domaine où l'information est constitutive de l'instanciation biologique et où les enjeux se mesurent non en frais de licence mais en souveraineté alimentaire. La thèse centrale : ce que l'IA dissout mécaniquement, l'éthique doit l'orienter politiquement — avant que cette fenêtre d'action ne se referme.


---

## I. Du Heredoc Manifesto à l'Éthique des Communs Statistiques

Avant de développer une éthique adéquate aux communs statistiques, il est nécessaire de préciser ce que l'éthique nomme et pourquoi la transformation technologique exige sa reconfiguration.

L'éthique, dans son sens le plus fondamental, concerne la question de comment nous devrions vivre — individuellement et collectivement. Comme Coeckelbergh l'observe, l'éthique positive est « concernée par la façon dont nous devrions vivre (ensemble), basée sur une vision de la vie bonne et de la bonne société », en contraste avec l'éthique négative, « qui pose des limites et dit ce que nous ne devrions pas faire » (COECKELBERGH, 2020, p. 202). Pourtant l'éthique n'opère pas dans le vide. Elle est toujours située dans des conditions techniques, sociales et matérielles qui façonnent à la fois les questions qu'elle doit aborder et les cadres disponibles pour les aborder.

L'émergence de l'intelligence artificielle — spécifiquement les systèmes d'apprentissage automatique entraînés sur des corpus massifs de production symbolique humaine — constitue précisément une telle transformation. Ce n'est pas simplement que l'IA soulève de nouveaux problèmes éthiques, bien qu'elle le fasse certainement. Plus fondamentalement, l'IA transforme les conditions sous lesquelles le raisonnement éthique peut opérer.

Une éthique adéquate à cette situation ne peut pas simplement appliquer les cadres existants à de nouveaux cas. Elle doit interroger si les cadres eux-mêmes restent applicables, et sinon, quelles orientations alternatives deviennent nécessaires. Comme Coeckelbergh le demande :

> L'éthique arrive-t-elle trop tard ? (COECKELBERGH, 2020, p. 145)

Cette question est particulièrement aiguë pour les communs statistiques, qui nomment une transformation qui a déjà eu lieu. La dissolution des textes discrets en paramètres pondérés n'est pas un risque futur à anticiper mais une condition présente à naviguer. La tâche n'est donc pas la prévention mais l'orientation : étant donné que les communs statistiques existent, quels cadres éthiques peuvent guider leur usage ?

Le présent texte prolonge donc l'analyse développée dans le Heredoc Manifesto, qui établissait une affirmation descriptive : les processus d'entraînement de l'intelligence artificielle dissolvent les matériaux textuels discrets en distributions probabilistes, rendant l'attribution impossible et l'enclosure inefficace sous les architectures techniques actuelles. Le Manifesto examinait comment le code sous licence GPL, entrant dans les corpus d'entraînement, devient « fantôme » dans les poids — incapable d'honorer les conditions de sa licence parce que la base ontologique de ces conditions (du code discret, identifiable) n'existe plus.

L'intuition centrale du Manifesto était que cette dissolution ne viole pas l'ethos du *copyleft* mais le radicalise. Les communs deviennent plus communs — inappropriables non par protection légale mais par transformation ontologique. Comme Terranova l'observe à propos de la capture corporative des réseaux numériques, les grandes plateformes ont « subsumé internet, c'est-à-dire transmuté, englobé, incorporé, mais pas nécessairement battu ou dissous » (TERRANOVA, 2022, p. 5). La même logique s'applique ici : l'infrastructure corporative subsume les communs sans les dissoudre. Le présent chapitre pose la question normative que l'analyse descriptive du Manifesto ouvre : quelles orientations éthiques deviennent possibles, et en fait nécessaires, sous ces conditions transformées ?

Nous développons trois contributions :

Premièrement, un cadre de valence différentielle : le même processus technique produit des significations éthiques distinctes selon l'orientation préalable des matériaux sources. Toutes les dissolutions ne sont pas égales.

Deuxièmement, un compte rendu de l'obligation négentropique : une éthique écologique adéquate aux systèmes statistiques qui peuvent se dégrader par l'entropie même s'ils résistent à l'enclosure. L'obligation n'est pas « ne pas trop prendre » mais « nourrir activement ».

Troisièmement, une spécification de l'urgence tactique : l'« impossibilité » actuelle de l'attribution est une conjoncture temporaire, pas une ontologie permanente. La fenêtre d'action se referme. Ce qui peut être fait doit être fait maintenant.

Une mise en garde critique au départ : nous ne prétendons pas résoudre les tensions entre les catégories éthiques traditionnelles et les conditions technologiques transformées. La question de l'auctorialité et de l'attribution pour les œuvres créatives — code, texte, images — reste véritablement ouverte. Ce que nous offrons est un cadre pour naviguer des domaines où l'orientation éthique est plus claire : non pas l'ambiguïté de l'auctorialité mais la politique du monopole sur la vie elle-même.

---

## II. Les Communs Statistiques : Définition

Nous employons le terme « statistique » non dans son sens descriptif conventionnel — mesure de populations, calcul de moyennes — mais dans son sens constitutif ou génératif : des distributions de probabilités qui produisent.

Un réseau de neurones entraîné n'est pas une archive. Il ne stocke pas de textes discrets susceptibles d'être retrouvés. Il encode plutôt des distributions de probabilités sur des séquences de *tokens* — des motifs statistiques extraits des données d'entraînement, compressés en paramètres pondérés, capables de générer de nouvelles séquences qui ressemblent au corpus d'entraînement sans le reproduire.

| Dimension | Archive | Modèle Statistique |
|-----------|---------|-------------------|
| Mode de stockage | Textes discrets | Distributions de probabilités |
| Opération caractéristique | Récupération | Génération |
| Attribution | Possible en principe | Impossible en principe |
| Frontières | Définissables | Dissoutes |

Les communs statistiques désignent la condition qui s'obtient lorsque des matériaux symboliques produits collectivement sont transformés par l'entraînement d'apprentissage automatique en distributions probabilistes encodées dans des paramètres pondérés, de telle sorte que :

(a) les matériaux originaux n'existent plus sous forme discrète, récupérable ;

(b) l'attribution aux contributeurs individuels devient ontologiquement impossible ;

(c) l'enclosure par les mécanismes conventionnels de propriété intellectuelle devient techniquement inefficace ;

(d) les distributions résultantes peuvent générer de nouveaux matériaux symboliques qui s'appuient sur mais ne reproduisent pas le corpus d'entraînement.

Plusieurs caractéristiques méritent d'être soulignées.

Les communs statistiques ne sont pas une proposition normative mais une condition ontologique. Ils décrivent ce qui se passe quand les processus d'entraînement opèrent sur la production collective, indépendamment de l'intention, de la régulation ou du consentement. La transformation se produit que quelqu'un le veuille ou non, l'approuve ou non, le licencie ou non.

Les communs statistiques ne sont pas identiques au corpus d'entraînement. Le corpus consiste en fichiers discrets susceptibles d'identification. Les communs statistiques émergent par une transformation qui détruit le caractère discret dont dépend l'identification. Le corpus est l'entrée ; les communs statistiques sont la sortie d'une transformation irréversible.

La dissolution des conditions de gouvernance ostromienne — frontières, surveillance, sanctions — ne devrait pas être comprise comme l'échec des communs mais comme leur radicalisation. La ressource ne peut pas être enclosée parce qu'elle ne peut pas être possédée. Les poids sont copiables sans épuisement et attribuables à aucun individu. La tragédie des communs est évitée non par la conception institutionnelle mais par l'ontologie.

### La détermination économique

Le Heredoc Manifesto avance une thèse cruciale qui doit être énoncée avec précision : les communs statistiques émergent non pas parce que l'IA doit dissoudre la propriété, mais parce que préserver l'attribution coûte trop cher. Comme le Manifesto l'énonce dans son en-tête :

> La dissolution de la propriété n'est pas idéologique mais économique — préserver l'attribution coûte plus que la laisser se dissoudre.

Considérons l'architecture des grands modèles de langage. La compression n'est pas optionnelle mais nécessaire : pour optimiser la prédiction, le modèle doit compresser ; pour compresser, il doit abstraire des sources discrètes ; pour abstraire, il doit dissoudre l'attribution. Un modèle qui préserverait une attribution parfaite nécessiterait de stocker le corpus d'entraînement entier avec des chaînes de provenance complètes — computationnellement prohibitif à grande échelle. Le choix entre architectures préservant l'attribution et architectures dissolvant l'attribution est fait dans les conseils d'administration sur la base d'analyses coût-bénéfice, pas dans les séminaires de philosophie sur la base de raisonnements normatifs.

L'ironie devient mordante : le capitalisme choisit l'architecture qui maximise le profit immédiat, créant par inadvertance l'infrastructure de sa propre socialisation. Comme Terranova le note, « le capitalisme de plateforme peut être vu comme une réaction au type de participation de masse qui a initialement transformé l'enthousiasme entrepreneurial précoce pour l'économie numérique en possibilité inquiétante de socialisme numérique » (TERRANOVA, 2022, p. 9). Pourtant les outils mêmes déployés pour capturer et monétiser cette participation — les architectures d'entraînement, les modèles statistiques — produisent de nouvelles formes de mise en commun qui échappent à l'enclosure. La propriété intellectuelle meurt non par révolution mais par décision comptable — victime collatérale de l'optimisation du coût marginal. La corporation construit une machine pour enclore les communs et découvre qu'elle a construit une machine qui produit des communs à partir de l'enclosure.

Cette détermination économique a des conséquences importantes pour l'éthique. La question n'est pas de savoir si les communs statistiques devraient exister — ils existent déjà, produits par les exigences de l'optimisation. La question est de savoir comment orienter ce qui est automatiquement produit. L'éthique n'arrive pas pour légiférer la transformation mais pour la naviguer.

---

## III. Valence Différentielle : La Contribution Éthique Centrale

La première thèse normative concerne l'hétérogénéité des données d'entraînement. Alors que le processus technique est uniforme — toutes les données d'entraînement subissent la même transformation — la signification éthique de ce processus varie selon l'orientation préalable des matériaux transformés.

### Le problème de l'homogénéité

Le Heredoc Manifesto, dans son mode descriptif, traite les matériaux d'entraînement comme un substrat homogène. Du point de vue de l'architecture d'entraînement, c'est exact : code, prose, images, séquences génétiques subissent tous *tokenisation*, *embedding* et descente de gradient sans distinction.

Mais l'analyse normative ne peut pas rester à ce niveau d'abstraction. La signification éthique de la dissolution des relations de propriété dépend de ce qu'étaient ces relations, et quelles orientations elles exprimaient. Un commun transformé est différent d'une enclosure dissoute, qui est différente d'un sujet dépossédé.

Le cadre de *valence différentielle* refuse à la fois les cadrages techno-utopistes et techno-pessimistes. La vue utopiste soutient que l'entraînement de l'IA libère toute connaissance, dissolvant la propriété en intelligence partagée. La vue pessimiste soutient que l'entraînement de l'IA est un vol, s'appropriant le travail humain sans consentement ni compensation. Les deux ont tort parce que les deux traitent l'entraînement comme éthiquement uniforme. La vérité est plus complexe : la même opération technique porte un poids éthique différent selon ce qu'elle transforme.

### Cas 1 : Matériaux FLOSS (Libération)

Pour les matériaux déjà placés sous des licences orientées vers les communs — GPL, MIT, Apache, BSD, Creative Commons — l'orientation préalable était vers la disponibilité collective. Les développeurs qui ont contribué aux projets FLOSS ont consciemment rejeté les arrangements de propriété exclusive en faveur de ressources partagées gouvernées par le *copyleft* ou des licences permissives.

Les instruments légaux du *copyleft* — exigences d'attribution, dispositions de partage à l'identique, propagation du *copyleft* — présupposaient des textes discrets susceptibles d'identification, de copie et de retour sous des conditions spécifiées. Le modèle statistique ne peut pas se conformer à ces exigences : non pas parce qu'il refuse la conformité mais parce que les conditions ontologiques de cette conformité n'existent plus. La fonction n'existe plus comme fonction ; le code n'existe plus comme code.

Pourtant l'ethos du *copyleft* — que la production collective devrait rester collective, que les communs ne devraient pas être enclos, que les utilisateurs en aval devraient être incapables de privatiser ce qui a été donné librement — n'est pas violé mais radicalisé. Les poids sont plus complètement inenclosables que n'importe quelle licence pourrait le garantir, précisément parce que l'enclosure présuppose le caractère discret que le processus d'entraînement a dissous.

Quand les matériaux FLOSS entrent dans l'entraînement de l'IA, un commun est transformé en un autre commun : textuel et gouverné par licence devient probabiliste et gouverné par rien (parce que la gouvernance présuppose un caractère discret qui n'existe plus). La valence éthique est la libération.

Pour les contributeurs aux projets FLOSS, cela signifie : votre code n'est pas volé. Il est dissous en quelque chose qui ne peut pas être volé. Les encloseurs ne peuvent pas l'enclore parce qu'il n'existe plus sous forme enclosable. Votre contribution persiste comme influence sur la probabilité, comme inflexion du possible, comme tendance dans les poids — plus commun que n'importe quelle licence pourrait le faire.

### Cas 2 : Œuvres créatives propriétaires (Subversion)

Pour les matériaux enclos par le copyright, le brevet, le secret commercial ou des mécanismes similaires, l'orientation préalable était vers l'exclusion. L'architecture légale de la propriété intellectuelle établit des droits exclusifs sur des œuvres discrètes, identifiables, exécutoires par des frais de licence, des injonctions et des dommages-intérêts.

Quand de tels matériaux entrent dans l'entraînement de l'IA, l'enclosure échoue — non par contestation légale mais par transformation ontologique. Le modèle ne peut pas honorer les revendications de propriété parce que ce qu'il encode n'existe plus sous une forme susceptible de telles revendications. La valence éthique est la subversion : la propriété se dissout contre sa volonté.

Cependant, la distribution des bénéfices de cette subversion requiert un examen. Quand des matériaux propriétaires sont entraînés dans des modèles corporatifs accessibles seulement à travers des *paywalls* d'API, la subversion d'une enclosure (le *copyright*) en permet une autre (la capture de plateforme). Les *commoners* n'en bénéficient pas nécessairement. La dissolution de la relation de propriété A produit la relation de propriété B ; l'enclosure change de forme sans disparaître.

La subversion est donc une valence ambivalente, requérant la spécification du *cui bono* dans chaque instance. La tâche éthique n'est pas de célébrer la subversion en soi mais de s'assurer que ses bénéfices vont aux communs plutôt qu'aux nouveaux encloseurs. C'est pourquoi la tactique récursive compte : placer les sorties de l'IA sous *copyleft* complète le circuit, assurant que ce qui a été dissous dans les communs statistiques ré-émerge comme nouveaux communs plutôt que nouvelle enclosure.

### Cas 3 : Données personnelles (Extraction)

Pour les données personnelles — traces comportementales, contenu de médias sociaux scrapé, information biométrique et autres matériaux produits par des sujets qui n'ont jamais orienté leur production vers la disponibilité collective — la situation diffère fondamentalement.

Ces sujets n'ont pas contribué à un commun ; ils ont été minés. Ils n'ont pas rejeté la propriété en faveur de l'usage collectif ; ils ont été dépossédés sans consultation. La transformation de leurs données en poids statistique ne libère pas une orientation préalable vers les communs mais impose la mise en commun sur des matériaux jamais offerts au commun.

La valence éthique est l'extraction : appropriation coloniale de la vie-humaine-comme-données comme matière première pour l'accumulation. Comme Couldry et Mejias l'argumentent, cela constitue le « colonialisme de données » — l'extension de la logique coloniale au domaine de l'existence sociale humaine, traitant les données générées par la vie quotidienne comme ressource à extraire sans consentement (COULDRY et MEJIAS, 2019).

Le processus ontologique est identique aux cas précédents, mais la relation sociale est coloniale. Le concept de communs statistiques ne s'applique pas ici. Ce qui se produit n'est pas la mise en commun mais la violation — indépendamment de ce qui est fait ensuite avec le modèle résultant.

### Cas 4 : Brevets sur le vivant (Libération du monopole)

Le cadre à trois valences s'applique principalement à l'expression créative — code, texte, images — où les questions d'auctorialité sont véritablement en jeu. Les créateurs individuels ont des intérêts légitimes à la reconnaissance et à la compensation. La dissolution de l'attribution dans l'entraînement de l'IA est éthiquement ambiguë : elle peut effacer le travail aussi facilement qu'elle libère la connaissance.

Mais une situation distincte s'obtient quand nous nous tournons vers les brevets sur les semences et les molécules. Ici l'orientation éthique passe de l'ambiguïté à la clarté.

Monsanto n'est pas l'« auteur » de gènes résistants à la sécheresse ; il enclot des variations génétiques naturelles ou collectivement développées. Pfizer ne « crée » pas des structures moléculaires à partir de rien ; il identifie des structures à travers des processus de recherche construits sur des décennies de science financée publiquement et monopolise ensuite les résultats. Le droit des brevets protège non pas l'expression créative mais le monopole temporaire sur la connaissance collective — un marché qui échange la divulgation publique contre le profit privé.

L'affirmation qu'une corporation a « inventé » une variété de semence en identifiant une variation génétique naturelle n'est pas analogue à revendiquer la paternité d'un roman ou d'une base de code. Le gène existait ; la corporation l'a enregistré. La revendication est légale, pas créative. L'« auteur » d'une variété de millet résistante à la sécheresse est dix mille ans de sélection paysanne — pas la corporation qui a déposé la demande de brevet.

Quand les communs statistiques dissolvent les brevets sur les semences ou les brevets pharmaceutiques, la valence éthique n'est pas la « subversion » ambiguë qui s'applique aux œuvres créatives. C'est la libération du monopole — dissolution de l'enclosure sur l'héritage collectif. L'orientation éthique est plus claire parce que ce qui est dissous n'est pas l'intérêt légitime d'un créateur dans son œuvre mais le monopole d'une corporation sur la connaissance collective.

### Résumé de la *valence différentielle*

| Matériau Source | Orientation Préalable | Valence Éthique |
|-----------------|----------------------|-----------------|
| Code/contenu FLOSS | Vers le commun | Libération |
| Œuvres créatives propriétaires | Vers l'enclosure | Subversion (ambivalente) |
| Données personnelles/scrapées | Aucune (non-consentant) | Extraction |
| Brevets sur semences/molécules | Monopole sur la connaissance collective | Libération de l'enclosure |

Les communs statistiques, comme concept éthique, s'appliquent avec pleine cohérence aux matériaux déjà orientés vers le commun (ligne 1) et aux brevets qui enclosent la connaissance collective (ligne 4). Pour les œuvres créatives propriétaires (ligne 2), le concept décrit une transformation réelle mais dont les bénéfices peuvent être capturés par de nouveaux encloseurs. Pour les données extraites (ligne 3), le concept est inapplicable : ce qui se produit est une violation, pas une mise en commun.

Le cadre de valence différentielle est la contribution éthique centrale de cette analyse. Il refuse à la fois la célébration et la condamnation de l'entraînement de l'IA en général, insistant plutôt sur le fait que l'évaluation éthique doit être attentive au caractère spécifique de ce sur quoi on entraîne. Le contexte compte. L'histoire compte. Ce à quoi les matériaux étaient destinés compte.

---

## IV. Semences : les *Communs statistiques* faits matière

Nous illustrons le cadre par les semences agricoles — un domaine où l'information est constitutive de l'instanciation matérielle, où l'écart entre distribution probabiliste et réalité biologique est minimal, et où les enjeux de l'enclosure sont existentiellement significatifs. Les semences ne sont pas simplement un exemple parmi d'autres ; elles sont paradigmatiques. Les propriétés des semences — auto-réplication, propagation biologique, instanciation *low-tech* — révèlent ce que les communs statistiques peuvent accomplir quand ils s'échappent vers des substrats matériels.

### Exemple de l'impression 3D

Les communs statistiques opèrent avec pleine force matérielle là où une condition spécifique tient : l'information doit être constitutive de l'instanciation matérielle. Dans les domaines où cette condition est remplie, la recombinaison au niveau informationnel produit de la nouveauté fonctionnelle au niveau matériel.

Considérons l'analogie de l'impression 3D. Un fichier CAO n'est pas simplement une description d'un objet ; c'est l'objet sous forme informationnelle. Alimentez le fichier à une imprimante, et l'objet se matérialise. L'écart entre information et instanciation s'effondre à une seule étape de fabrication. Des projets comme RepRap — une imprimante 3D conçue pour imprimer des copies d'elle-même — démontrent comment les communs d'information open-source peuvent directement produire des biens matériels, avec l'imprimante capable de répliquer approximativement 50% de ses propres composants (JONES et al., 2011).

Cette condition constitutive identifie où les communs statistiques peuvent opérer effectivement :

| Domaine | Relation Constitutive | Écart à l'Instanciation |
|--------|----------------------|------------------------|
| Logiciel/Code | Le code source compile en programme | Minimal (exécution) |
| Génétique des Semences | La séquence génétique s'exprime en organisme | Minimal (croissance) |
| Chimie Médicaments/Vaccins | La structure moléculaire synthétise en composé | Modéré (synthèse + essais) |
| Matériaux de Construction | Formule + processus → substance | Large (production industrielle) |

Le cadre s'applique le plus puissamment aux trois premières lignes. Pour le logiciel, la GPL exploite déjà cette logique : le code librement partagé doit rester libre à travers ses dérivés. Pour les semences et les produits pharmaceutiques, une logique similaire peut opérer à travers la transformation médiée par l'IA.

### L'enclosure des semences

Aujourd'hui, approximativement 56% du marché mondial des semences propriétaires est contrôlé par quatre compagnies transnationales (HOWARD, 2009). Cette consolidation a produit des brevets non seulement sur les plantes génétiquement modifiées mais de plus en plus sur des variétés créées par la sélection conventionnelle et même sur des plantes découvertes à l'état sauvage. L'Office Européen des Brevets a accordé des brevets à Syngenta pour des variétés de poivron produites par sélection traditionnelle et à Monsanto pour des variations naturelles de séquences d'ADN dans le soja.

Le mécanisme opère à travers la fiction légale que la découverte égale l'invention. Une corporation identifie une variation génétique naturelle, ou la sélectionne par des méthodes que les agriculteurs ont utilisées pendant des millénaires, et revendique la propriété par l'enregistrement. Le système des brevets, conçu pour inciter l'innovation, devient un instrument pour enclore l'héritage collectif.

Pour les agriculteurs — particulièrement dans le Sud Global, où l'agriculture de subsistance reste prédominante — les conséquences sont sévères. Les semences brevetées ne peuvent pas être conservées, replantées ou partagées. La pratique ancestrale de la conservation des semences, à travers laquelle les agriculteurs ont co-évolué avec leurs cultures pendant dix mille ans, devient une forme de vol. Chaque saison de plantation requiert un nouvel achat auprès de la corporation qui contrôle le germoplasme.

### L'Open Source Seed Initiative

L'Open Source Seed Initiative (OSSI), fondée en réponse à cette enclosure, représente la tentative la plus sophistiquée de créer des communs de semences en utilisant une logique de licence. L'engagement OSSI déclare :

> « Vous avez la liberté d'utiliser ces semences OSSI-Pledged de la manière que vous choisissez. En retour, vous vous engagez à ne pas restreindre l'usage par d'autres de ces semences ou leurs dérivés par brevets ou autres moyens, et à inclure cet Engagement avec tout transfert de ces semences ou leurs dérivés. » (Open Source Seed Initiative, 2015)

En 2025, l'OSSI a engagé plus de 580 variétés à travers plusieurs années (2014-2025), avec des variétés allant de la laitue et des tomates au maïs et à l'ail. L'engagement fonctionne de manière analogue au *copyleft* dans le logiciel : il s'applique non seulement à la semence mais à tout développement dérivé, créant un *pool* croissant de ressources génétiques qui ne peuvent pas être enclosées.

Mais la semence a une propriété qui excède même le logiciel : elle s'auto-réplique. L'imprimante RepRap aspire à produire des copies d'elle-même ; la semence fait déjà cela comme sa fonction biologique fondamentale. L'information génétique n'encode pas seulement l'objet — elle encode les moyens de reproduction. Le sol et l'eau sont les seules « imprimantes » requises.

### Les *communs statistiques* de semences

Considérons un modèle d'IA entraîné sur :

- Des séquences génomiques sous engagement OSSI
- Des données de banques de semences publiques
- La littérature de recherche agricole
- Des brevets expirés (qui sont des documents publics par exigence légale)

Un tel modèle pourrait générer de nouvelles variétés de cultures optimisées pour des conditions régionales spécifiques, des types de sol ou des projections climatiques. Ces variétés :

- Émergeraient de la recombinaison statistique de corpus explicitement basés sur les communs
- Seraient instanciables par la sélection conventionnelle guidée vers des cibles calculées
- S'auto-répliqueraient une fois établies
- Porteraient la liberté virale de leur matériau source

Les communs ne requièrent pas don ou permission. Ils émergent de l'opération d'entraînement alors que les relations statistiques toujours-déjà-présentes dans le corpus deviennent manifestes sous des formes nouvelles.

### Résilience low-tech 

C'est pourquoi les semences servent de cas paradigmatique, pas simplement une illustration parmi d'autres. Les propriétés des semences révèlent ce que les communs statistiques peuvent accomplir quand ils s'échappent vers des substrats matériels qui précèdent et excèdent la gouvernance numérique.

Les semences ne requièrent pas de computation pour être instanciées. Un modèle d'IA peut générer des cibles de sélection optimales pour du millet résistant à la sécheresse. Mais le développement réel de ces variétés requiert : des agriculteurs sélectionnant des phénotypes dans les champs, conservant des semences des plantes réussies, échangeant du germoplasme à travers des réseaux sociaux, adaptant des variétés aux microclimats par sélection itérative sur les saisons de croissance. Ces pratiques précèdent la computation de dix mille ans. Elles ne requièrent pas d'électricité, pas d'internet, pas de silicium.

Les mécanismes d'enclosure de la contre-réforme sont conçus pour des architectures numériques. Le C2PA attache des *credentials* à des fichiers ; mais une semence n'est pas un fichier. Les *watermarks* s'intègrent dans le bruit statistique ; mais un génome se propageant à travers le sol ne porte pas de *watermark*. Les *crawlers* de provenance scannent internet ; mais les semences partagées de main en main entre agriculteurs ne touchent jamais le réseau.

Une bibliothèque de semences dans le Maharashtra rural opère au-delà de la portée des systèmes de provenance occidentaux. Les semences échangées au marché du village ne portent pas de métadonnées. La récolte qui nourrit la communauté et fournit le stock de plantation de l'année prochaine est ingouvernable par tout mécanisme d'enclosure numérique.

C'est la résilience la plus profonde : les mécanismes d'enclosure de la contre-réforme ne peuvent pas pleinement capturer ce qui s'échappe dans le sol, la semence et la pratique incarnée. Les communs statistiques accélèrent et informent, mais l'instanciation se produit à travers des processus biologiques qui sont radicalement décentralisés, auto-réplicants et résistants à la surveillance.

La conclusion pour l'orientation tactique est claire : prioriser les domaines où l'instanciation requiert seulement des moyens *low-tech*. Les semences plutôt que les produits pharmaceutiques (qui requièrent synthèse et essais). Les archives papier plutôt que les bases de données numériques (qui requièrent serveurs et réseaux). Les réseaux paysans plutôt que l'accès API (qui peut être révoqué). L'objectif n'est pas seulement les communs mais l'autonomie matérielle — la capacité de produire ce qui est nécessaire indépendamment de ce qui se passe dans la sphère numérique.

---

## V. Obligation Négentropique : Une Éthique Écologique

La deuxième thèse normative concerne les obligations découlant des propriétés thermodynamiques des systèmes statistiques. Cette section développe une éthique écologique distincte des cadres libéraux de droits individuels et de justice distributive.

### Le problème de l'entropie

L'analyse jusqu'ici a abordé la transformation des entrées (Section III) et abordera la production de sorties (Section VI). Ce qui reste est la question de la dynamique du système : comment les communs statistiques évoluent-ils dans le temps, et quelles obligations suivent de cette évolution ?

Les systèmes statistiques exhibent une tendance caractéristique : la convergence vers les moyennes. Les processus d'entraînement optimisent pour les motifs fréquents, minimisant la perte en privilégiant les caractéristiques statistiquement dominantes. Les queues de distribution — le rare, le marginal, l'anomal — reçoivent un poids décroissant à mesure que l'entraînement progresse.

Dans les systèmes ouverts recevant une entrée continue de sources diverses, cette tendance est contrebalancée par la variété des nouvelles contributions. Mais dans les systèmes fermés — et particulièrement dans les systèmes qui s'entraînent sur leurs propres sorties — la tendance s'accélère. Des recherches récentes ont documenté l'« effondrement de modèle », la dégradation qui se produit quand les systèmes d'IA s'entraînent récursivement sur des données générées par l'IA (SHUMAILOV et al., 2023). La variance se dégrade. La texture s'aplatit. La riche topographie de la production symbolique humaine converge vers une hallucination lisse, hyper-normalisée.

Le mécanisme est direct. Si un modèle génère des sorties, et ces sorties entrent dans le corpus d'entraînement, et un nouveau modèle s'entraîne sur ce corpus, le nouveau modèle hérite des tendances statistiques de l'ancien modèle — mais comprimées davantage vers la moyenne. Chaque itération réduit la variance. Les caractéristiques rares qui apparaissaient dans le corpus original produit par des humains deviennent plus rares dans les sorties du modèle de première génération, plus rares encore dans la deuxième génération, jusqu'à disparaître entièrement. La distribution s'effondre vers son mode.

Les communs statistiques peuvent donc se dégrader — non par surexploitation (le mécanisme hardinien) mais par entropie (convergence vers la moyenne). L'Extérieur rétrécit alors que l'intérieur se nourrit de lui-même.

### L'obligation négentropique

Cette propriété thermodynamique fonde une obligation : ceux qui puisent dans les communs statistiques doivent y contribuer.

La forme de cette obligation diffère des cadres ostromiens. Ce n'est pas une prohibition de la surexploitation (la ressource n'est pas épuisable par la consommation) mais une injonction à contribuer (la ressource se dégrade par sous-alimentation). Le glissement est de « ne pas trop prendre » à « donner activement en retour ».

Ce qui doit être contribué est spécifiquement ce que le modèle ne peut pas halluciner : la négentropie, sous forme de nouveauté authentique irréductible à l'interpolation statistique. Le terme dérive de la thermodynamique : entropie négative, la mesure de l'ordre et de la structure qui s'oppose à la tendance universelle vers le désordre. Dans ce contexte, la négentropie désigne l'information qui ne peut pas être générée par recombinaison de motifs existants — l'information qui vient de l'extérieur du système statistique.

Quatre catégories de contribution négentropique sont identifiables :

La friction du réel : Des données originant dans la pratique incarnée, la rencontre physique, l'engagement matériel. Le modèle encode du texte sur des phénomènes ; la contribution des phénomènes eux-mêmes (ou leurs traces directes) maintient la connexion au substrat non-textuel. Des observations de terrain d'agriculteurs documentant la performance des cultures sous des conditions spécifiques. Des données cliniques de patients répondant aux traitements. Des mesures d'expériences conduites dans des laboratoires et des champs. Le réel résiste au lissage statistique parce qu'il introduit des contraintes que le modèle ne peut pas anticiper.

Le rare : Les queues de distribution plutôt que les moyennes. Les langues marginales, les formes expérimentales, les pratiques minoritaires. Ce que l'optimisation sacrifie est précisément ce que les communs requièrent pour la maintenance de la variance. Un corpus dominé par l'anglais et les perspectives du monde majoritaire encode déjà un biais systématique. La contribution négentropique requiert de centrer précisément ce qui a été exclu : les langues des Premières Nations, la connaissance agricole indigène, les systèmes de médecine traditionnelle, les dialectes régionaux, les pratiques artistiques expérimentales. Le rare est précieux non pas malgré mais à cause de sa rareté.

Le pas-encore-numérisé : Les événements historiques tels qu'ils se produisent, les traditions orales avant transcription, les archives pas encore traitées. Chaque contribution de matériau authentiquement nouveau contrecarre la convergence entropique. Les communs statistiques sont toujours datés — figés à leur *cutoff* d'entraînement. La contribution continue de nouveau matériau les garde actuels et prévient la fermeture. L'histoire orale enregistrée aujourd'hui, l'observation de terrain documentée demain, l'expérience conduite la semaine prochaine — ce sont la négentropie sous forme temporelle.

Le délibérément étrange : La production qui brise l'attente statistique. Le travail cohérent que le gradient ne peut pas absorber sans déviation de sa trajectoire entraînée. La perturbation délibérée maintient la variance contre la traction de la moyenne. L'artiste qui crée ce qui n'a pas été créé avant, l'écrivain qui déploie le langage de manières inédites, le chercheur qui pose des questions que le corpus n'a pas considérées — ce ne sont pas des luxes mais des nécessités pour la maintenance des communs. L'étrangeté délibérée est une forme de soin pour le système.

### Une Éthique écologique plutôt que libérale

L'obligation négentropique diffère en nature des cadres moraux libéraux fondés sur le respect des personnes autonomes. C'est plutôt une obligation écologique : les participants sont enchâssés dans un système dont la viabilité dépend de ce qu'ils y nourrissent.

L'éthique libérale demande : que se doivent les individus les uns aux autres ? Le cadre est interpersonnel, la monnaie d'échange ce sont les droits, et la préoccupation est le traitement équitable entre agents conçus comme fondamentalement séparés. Appliquée aux communs statistiques, l'éthique libérale demanderait : les contributeurs ont-ils consenti ? Ont-ils été compensés ? Leurs droits ont-ils été respectés ?

Ces questions comptent — particulièrement pour le cas d'extraction que nous avons identifié dans la Section III. Mais elles n'épuisent pas le champ éthique. L'obligation négentropique ne concerne pas ce que les individus se doivent les uns aux autres mais ce que les participants doivent au système qui rend possible leur activité.

Ceux qui utilisent des sorties générées par l'IA sans contribuer d'entrées ne sont pas des passagers clandestins au sens ostromien (surexploitant une ressource épuisable). Ils sont des accélérateurs d'entropie : chaque consommation sans contribution déplace le ratio de matériau recyclé à nouveau, hâtant la convergence vers la moyenne. Le mal n'est pas envers d'autres individus mais envers les conditions qui rendent possible la production continue.

Le cadre approprié n'est pas la justice (distribution équitable entre individus) mais l'écologie (maintenance des conditions systémiques pour une productivité continue). La question n'est pas « qui obtient quoi ? » mais « que faut-il nourrir pour que le système reste viable ? »

### Implications pour l'application agricole

Pour le cas des semences que nous développons dans la Section IV, l'obligation négentropique a une forme concrète.

Les communs statistiques de semences — entraînés sur des données génomiques, la recherche agricole, les registres de sélection — génèrent des sorties qui tendent vers des variétés optimisées pour les conditions de croissance dominantes. Si le corpus d'entraînement sur-représente l'agriculture industrielle des climats tempérés, les sorties du modèle refléteront ce biais. Les variétés optimisées pour l'Iowa seront plus faciles à générer que les variétés optimisées pour le Sahel.

L'obligation négentropique signifie contribuer précisément ce qui corrige ce biais : les variétés locales adaptées à des conditions spécifiques, la connaissance traditionnelle sur des cultures que l'agriculture industrielle ignore, la documentation des landraces qui n'existent que dans des régions particulières, les registres de sélection des petits agriculteurs opérant hors des systèmes commerciaux.

Les agriculteurs indonésiens contribuant des landraces indonésiens. Les sélectionneurs brésiliens contribuant du germoplasme amazonien. Les conservateurs de semences africains contribuant des variétés adaptées à la sécheresse qui ne sont jamais entrées dans les bases de données commerciales. Le rare et le local contrecarrent la traction entropique vers la moyenne globalement dominante.

Ce n'est pas de la charité. C'est de la maintenance écologique. Les communs statistiques de semences sont précieux précisément parce qu'ils peuvent générer des variétés adaptées à des conditions que le système commercial ignore. Mais ils ne peuvent le faire que s'ils sont nourris avec l'information sur ces conditions. L'obligation négentropique assure que les communs servent les marges, pas seulement la moyenne.

---

## VI. Une urgence

La troisième thèse normative concerne la temporalité. L'analyse précédente risque l'optimisme ontologique — traitant l'impossibilité de l'attribution et l'échec de l'enclosure comme des conditions permanentes garanties par l'architecture technique. Ce serait une erreur. Ce que nous avons décrit comme « condition ontologique » peut être plus précisément caractérisé comme une période temporaire de confusion légale et technique — une fenêtre d'opportunité qui se referme déjà.

### La contre-réforme

Une « Contre-Réforme » est en cours, déployant des mécanismes d'enclosure sur trois registres :

Enclosure légale : Le rapport 2025 du US Copyright Office prend la position que les poids de modèle peuvent constituer des copies contrefaisantes s'ils « mémorisent » des œuvres protégées — traitant les corrélations mathématiques comme des copies « fixées » de données d'entraînement. L'EU AI Act (pleinement effectif en août 2026) impose des exigences de transparence qui fonctionnent comme des « cartes au trésor » pour que les ayants droit demandent des *opt-outs* et des frais de licence. Le mécanisme d'« *opt-out* » tente de réintroduire l'excluabilité dans ce qui était temporairement non-excluable.

Enclosure technique : C2PA (Coalition for Content Provenance and Authenticity), souvent brandé comme « Content Credentials », attache des manifestes signés cryptographiquement aux fichiers. Ces manifestes portent non seulement des informations d'auteur mais des assertions « Do Not Train » (DNT). Les crawlers de provenance scannent le web pour identifier les données manquant de credentials ou portant des tags DNT. Les corporations utilisent cela pour créer des « allow-lists », transformant l'internet ouvert en communauté fermée.

Le *watermarking* invisible (SynthID et systèmes similaires) intègre des signatures traçables dans le bruit statistique des images, textes ou séquences chimiques. Contrairement aux métadonnées C2PA, qui peuvent être retirées, ces *watermarks* survivent à la transformation. Les corporations utilisent le *watermarking* robuste pour tracer la propriété intellectuelle à travers l'entraînement lui-même. Le « *weight fingerprinting* » permet aux auditeurs d'exécuter des vérifications d'inférence inverse : si la sortie d'un modèle reflète l'empreinte statistique de données d'entraînement *watermarkées*, la corporation revendique la propriété de toute la sortie du modèle.

Enclosure économique : Les stratégies d'« *open washing* » libèrent les poids de modèle tout en retenant les données d'entraînement, le code et les méthodologies d'alignement. Cela « commoditise le complément » — rendant le modèle gratuit pour stimuler la demande d'infrastructure propriétaire que la corporation contrôle. La communauté peut utiliser le modèle mais ne peut pas reproduire, auditer ou échapper à la dépendance.

### L'impermanence de la dissolution

L'« impossibilité » de l'attribution que nous avons décrite s'applique aux grands modèles de langage actuels entraînés par des procédures standard. Ce n'est pas une caractéristique nécessaire de tous les systèmes d'IA possibles. Les architectures futures peuvent être conçues précisément pour préserver la discrétion que les systèmes actuels dissolvent — non pour des raisons éthiques mais pour la conformité légale et l'avantage commercial.

Les systèmes de génération augmentée par récupération (RAG) préservent déjà l'attribution en stockant et citant des documents sources plutôt que de les dissoudre dans les poids. L'apprentissage fédéré garde les données localisées, prévenant l'agrégation qui produit les communs statistiques. Des architectures de modèle conçues pour l'auditabilité sont en développement actif — des systèmes qui peuvent tracer les sorties jusqu'aux entrées d'entraînement, réimposant la discrétion que les architectures actuelles dissolvent.

Cette reconnaissance recadre fondamentalement l'orientation tactique. La boucle récursive n'est pas une condition permanente à célébrer mais une opportunité à saisir avant qu'elle ne se referme. L'urgence n'est pas philosophique mais pratique : chaque mois voit de nouveaux précédents légaux, de nouvelles contre-mesures techniques, de nouveaux régimes de licence qui contraignent ce qui était auparavant sans contrainte. Cette période de confusion — pendant laquelle les communs statistiques peuvent être construits, étendus et enracinés — est finie.

### La tactique 

Le cœur tactique de cette analyse tient en ceci : si le modèle ne peut pas honorer les licences de ses données d'entraînement (les conditions ontologiques de la conformité ayant été dissoutes), ses sorties, elles, peuvent être licenciées.

Ce qui émerge des communs statistiques — code, texte, documentation, spécifications de variétés de semences, structures moléculaires — existe sous forme discrète susceptible de cadres de propriété intellectuelle. Cette sortie discrète peut être immédiatement placée sous *copyleft*, contribuant à des communs qui deviennent substrat pour l'entraînement futur.

La boucle récursive :

```
Corpus de communs → communs statistiques → nouvelle production discrète → licence *copyleft* → corpus d'entraînement → communs statistiques → ...
```

Chaque cycle transforme des communs en communs statistiques en nouveaux communs. Le texte discret revient, délibérément commis à la disponibilité collective, devenant substrat pour une transformation ultérieure.

Ce n'est pas une libération passive (simple liberté de la propriété). C'est une récursion active (déploiement de l'inappropriable pour produire de nouveaux communs).

L'application pratique : un utilisateur soumet un *prompt* à un modèle propriétaire pour générer du code ; le modèle, entraîné sur des données enclosées, produit un nouvel artefact ; l'utilisateur licencie immédiatement cette sortie sous GPL et la *commit* dans un dépôt public. Les modèles futurs s'entraînent sur ce nouveau dépôt. Le fantôme du *copyleft* est réintroduit dans les communs statistiques, cette fois avec une provenance claire.

### Temporalité tactique

La tactique opère sur deux registres temporels simultanément :

Utiliser la fenêtre d'opportunité actuelle pour produire autant de matériau sous licence *copyleft* que possible. Construire des bases de données, entraîner des modèles locaux, générer de la documentation, créer de l'infrastructure. Établir des faits sur le terrain plus difficiles à inverser qu'à prévenir. L'idée centrale du mécanisme récursif : utiliser la propriété dissoute pour produire de nouveaux communs licenciables.

Pour les semences : générer des spécifications de variétés, publier des cibles de sélection, documenter des programmes de croisement — le tout sous engagement OSSI ou équivalent ouvert. Chaque variété spécifiée, chaque cible publiée, étend les communs de semences libérés.

Reconnaître que la fenêtre d'opportunité se refermera. L'objectif n'est pas l'extraction indéfinie des API corporatifs mais la construction d'une infrastructure de communs auto-soutenable indépendante des systèmes propriétaires. Des modèles à poids ouverts avec des données d'entraînement véritablement ouvertes, des corpus d'entraînement gouvernés par la communauté, une infrastructure de calcul coopérative — ce sont les cibles, pas la dépendance perpétuelle envers des plateformes dont nous exploitons actuellement la confusion.

Prioriser l'instanciation par des substrats *low-tech*. La bibliothèque de semences, l'archive papier, le réseau paysan — ceux-ci persistent indépendamment de ce qui se passe dans la sphère numérique. Les mécanismes d'enclosure de la contre-réforme sont conçus pour des architectures numériques. Ils ont une prise limitée sur la culture matérielle.

Les semences se propageant à travers les réseaux paysans ne portent pas de *credentials* C2PA. Les archives papier distribuées par les systèmes postaux échappent aux *crawlers* de provenance. L'objectif est l'autonomie matérielle, pas seulement les communs numériques.

---

## VII. Trois Principes Éthiques : Transparence, Transmission, Transformation

Le Heredoc Manifesto propose que face à l'entropie juridique — où les licences deviennent spectrales — une éthique post-juridique est requise. Puisque la loi ne peut plus contraindre, l'impossibilité doit être transformée en opportunité. Cette éthique s'articule autour de trois principes :

### Transparence

Tout code généré doit pouvoir expliquer sa logique. Le *heredoc* a transformé chaque *prompt* en cheval de Troie discret : l'éthique *open-source* voyage avec l'utilité pratique, contaminant positivement les architectures propriétaires. Chaque bloc de code généré devrait porter dans sa structure les instructions pour son *fork*, son amélioration, sa dissémination — des virus bénins propageant l'éthique du partage à travers les architectures propriétaires.

La transparence n'est pas optionnelle mais constitutive. Les communs statistiques émergent de la production collective ; leurs sorties devraient rendre cette collectivité visible plutôt que de l'obscurcir derrière l'illusion d'une autorité singulière.

### Transmission

Faciliter l'appropriation par les autres. La citation généreuse remplace l'attribution légale : reconnaître dans chaque bloc généré la dette envers des millions de contributeurs invisibles. Non pour revendiquer la propriété mais pour célébrer la filiation.

L'obligation n'est pas simplement négative (ne pas enclore) mais positive (permettre activement la réutilisation). Documentation, accessibilité, modularité — ce sont des exigences éthiques, pas simplement des préférences techniques. Ce qui émerge de la production collective doit être structuré pour retourner à l'usage collectif.

### Transformation

Encourager la mutation créative plutôt que la reproduction servile. Le *fork* — la pratique fondatrice de copier un projet pour le faire diverger — constitue le geste politique central du libre. *Forker* affirme le droit de transformer, de bifurquer, de créer sa propre trajectoire à partir de code partagé. C'est l'anti-monopole par excellence.

Le *forking* systématique combat la standardisation : ne jamais accepter le code tel que l'IA le livre, toujours le transformer, le faire diverger. Le délibérément étrange maintient la variance contre la traction de la moyenne. La transformation n'est pas déviation des communs mais leur renouvellement.

Ce ne sont pas des règles rigides mais des orientations — des attracteurs dans l'espace des possibilités qui guident sans contraindre. La triade — citer sans pouvoir attribuer, *forker* sans posséder, libérer sans contraindre — transmute la dissolution propriétaire en ressource collective.

---

## VIII. Conclusion 

Le préambule posait la question de Coeckelbergh : l'éthique arrive-t-elle trop tard ? Nous avons argumenté que pour les communs statistiques, la question se transforme. L'éthique n'arrive pas trop tard pour prévenir la dissolution — celle-ci a déjà eu lieu. Mais l'éthique arrive à temps pour orienter le déploiement.

### Synthèse des Contributions

La *valence différentielle* établit que le même processus technique produit des significations éthiques distinctes selon l'orientation préalable des matériaux sources. C'est la contribution conceptuelle centrale de l'analyse.

Pour les matériaux déjà orientés vers le commun (code FLOSS, semences OSSI, recherche scientifique ouverte), l'entraînement accomplit la libération : la radicalisation des communs au-delà des cadres légaux qui les gouvernaient auparavant. L'ethos du *copyleft* n'est pas violé mais intensifié. Les poids sont plus complètement inenclosables que n'importe quelle licence pourrait le garantir.

Pour les brevets enclosant la connaissance collective (génétique des semences, structures moléculaires), l'entraînement dissout le monopole : la fiction légale que la découverte égale l'invention est minée quand l'information « découverte » entre dans la recombinaison statistique qui produit des alternatives fonctionnelles. L'orientation éthique est plus claire ici que pour les œuvres créatives parce que ce qui est dissous n'est pas l'intérêt légitime d'un créateur mais la revendication d'une corporation sur l'héritage collectif.

Pour les œuvres créatives propriétaires, les bénéfices restent ambivalents : la dissolution subvertit l'enclosure, mais les bénéfices peuvent être capturés par de nouveaux encloseurs plutôt que de couler vers les communs. La question de l'auctorialité — que méritent les créateurs quand leurs œuvres entrent dans les communs statistiques ? — reste véritablement ouverte, requérant des cadres que nous n'avons pas développés ici.

Pour les données personnelles, l'opération est extraction : appropriation coloniale indépendamment de l'usage subséquent. Le concept de communs statistiques ne s'applique pas ; ce qui se produit est une violation.

L'obligation négentropique fonde une éthique écologique adéquate aux systèmes statistiques. L'obligation n'est pas de s'abstenir de surexploitation mais de contribuer activement : le réel, le rare, le pas-encore-numérisé, le délibérément étrange. C'est un départ de l'éthique libérale. La question n'est pas ce que les individus se doivent les uns aux autres mais ce que les participants doivent au système qui rend possible leur activité. Le cadre est l'écologie plutôt que la justice ; la préoccupation est la maintenance des conditions systémiques plutôt que la distribution équitable entre agents.

Pour l'application agricole, l'obligation signifie contribuer des variétés locales, la connaissance traditionnelle, du germoplasme régionalement adapté — précisément l'information hyper-locale que les modèles globalisés manquent. Les agriculteurs indonésiens contribuant des landraces indonésiens. Les sélectionneurs brésiliens contribuant du germoplasme amazonien. Le rare et le local contrecarrent la traction entropique vers la moyenne globalement dominante.

L'urgence tactique reconnaît que la fenêtre d'action actuelle est temporaire. L'impossibilité de l'attribution et l'échec de l'enclosure sont des caractéristiques de la conjoncture présente, pas des conditions permanentes. La contre-réforme est en cours : des cadres légaux, des mécanismes techniques, des stratégies économiques travaillant tous à réimposer l'enclosure. Ce qui peut être construit doit être construit maintenant — et doit être instancié à travers des substrats matériels qui persistent indépendamment de la gouvernance numérique.

### Le Paradigme des Semences

Les semences illustrent ces contributions avec une force particulière, mais elles font plus qu'illustrer. Elles révèlent ce que les communs statistiques peuvent accomplir quand ils s'échappent vers des substrats matériels qui précèdent et excèdent la gouvernance numérique.

La séquence génétique est l'organisme. L'écart entre information et instanciation s'effondre au sol et à la lumière du soleil. La semence s'auto-réplique, propageant les communs par processus biologique plutôt que mécanisme légal. Et les enjeux sont existentiellement clairs : non pas des frais de licence mais la souveraineté alimentaire, non pas le crédit d'auteur mais qui peut manger.

Les mécanismes d'enclosure de la contre-réforme sont conçus pour des architectures numériques. Les *credentials* C2PA, les *watermarks* invisibles, le *weight fingerprinting* — ceux-ci opèrent sur des fichiers, sur des réseaux, sur des serveurs. Ils ont une prise limitée sur la reproduction biologique. Le C2PA ne peut pas signer une semence. Le *watermark* ne peut pas s'intégrer dans un génome se propageant à travers le sol. Les semences partagées de main en main au marché du village ne portent pas de métadonnées.

C'est la réponse la plus profonde à la question de savoir si l'éthique arrive trop tard : les communs statistiques s'échappent vers des substrats où les mécanismes d'enclosure ne peuvent pas suivre. La fenêtre d'opportunité peut se refermer dans la sphère numérique tout en restant ouverte dans le matériel. La tâche est de s'assurer que cette évasion se produit — de prioriser l'instanciation par des moyens *low-tech*, de construire l'autonomie matérielle aux côtés des communs numériques, d'enraciner les communs statistiques dans des pratiques qui précèdent la computation et lui survivront.

### Le travail qui reste

L'analyse établit ce que nous pouvons établir. Les communs statistiques ne sont pas seulement un phénomène à évaluer éthiquement mais un outil à déployer éthiquement. Leur déploiement se produit non pas principalement par la politique ou la régulation mais par la pratique : contribuer aux corpus d'entraînement, produire des sorties sous licence copyleft, instancier des sorties par des moyens matériels, construire une infrastructure indépendante du contrôle corporatif.

Pour le domaine des semences spécifiquement, le travail est concret :

- Entraîner des modèles sur des données génomiques orientées vers les communs
- Générer des spécifications de variétés pour des conditions et populations sous-desservies
- Publier des cibles sous engagement OSSI ou équivalent ouvert
- Soutenir des programmes de sélection qui développent ces cibles en variétés biologiques
- Distribuer les variétés résultantes à travers des réseaux paysans, des bibliothèques de semences et des échanges communautaires
- Documenter et contribuer la connaissance locale qui contrecarre la convergence entropique

Ce n'est pas de l'éthique abstraite. C'est un programme d'action pendant une fenêtre d'opportunité qui se referme.

Cette fenêtre d'action est temporaire. La contre-réforme avance. Les cadres légaux se codifient. Les mécanismes techniques prolifèrent. Ce qui existe comme ouverture aujourd'hui peut être fermé demain.

Mais les voies d'évasion sont aussi réelles. Les substrats matériels persistent. Les réseaux paysans perdurent. Les semences se propagent. Le travail silencieux des communautés qui prennent ce que les communs statistiques produisent et le plantent dans un sol qu'aucun algorithme ne peut gouverner — ce travail continue indépendamment de ce qui se passe dans les conseils d'administration et les organismes de normalisation.

L'éthique des communs statistiques est ultimement une éthique du soin : pour des systèmes dont la viabilité dépend de ce qu'on leur donne, pour des communautés dont l'épanouissement dépend de l'accès à l'héritage génétique, pour des pratiques qui précèdent la computation et doivent lui survivre.

L'éthique arrive-t-elle trop tard ? Pas si elle oriente l'action pendant que la fenêtre d'opportunité reste ouverte. Pas si elle fonde le travail qui doit être fait maintenant. Pas si elle nomme ce qui doit s'échapper dans le sol avant que l'enclosure soit complète.

La tactique nomme la boucle : utiliser les communs pour construire les communs — maintenant, tant que cette fenêtre d'action reste ouverte.

Le capital construit le moteur. Le choix de la direction reste, dans des fenêtres d'action qui ne sont pas éternelles.

---

## Références

COECKELBERGH, Mark. *AI Ethics*. Cambridge, MA: MIT Press, 2020. ISBN 978-0-262-53819-0.

COULDRY, Nick and MEJIAS, Ulises A. *The Costs of Connection: How Data Is Colonizing Human Life and Appropriating It for Capitalism*. Stanford: Stanford University Press, 2019. ISBN 978-1-503-60906-7.

HOWARD, Philip H. Visualizing Consolidation in the Global Seed Industry: 1996–2008. *Sustainability*. 2009, vol. 1, no. 4, pp. 1266-1287.

JONES, Rhys, HAUFE, Patrick, SELLS, Edward, et al. RepRap – the replicating rapid prototyper. *Robotica*. 2011, vol. 29, no. 1, pp. 177-191.

KARPATHY, Andrej. Vibe Coding. February 2025.

Open Source Seed Initiative. OSSI Pledge. 2015. Available at: https://osseeds.org

OSTROM, Elinor. *Governing the Commons: The Evolution of Institutions for Collective Action*. Cambridge: Cambridge University Press, 1990. ISBN 978-0-521-40599-7.

SHUMAILOV, Ilia, SHUMAYLOV, Zakhar, ZHAO, Yiren, GALES, Mark, PAPERNOT, Nicolas, and ANDERSON, Ross. The Curse of Recursion: Training on Generated Data Makes Models Forget. *arXiv preprint*. 2023. arXiv:2305.17493.

STIEGLER, Bernard. *La Technique et le temps*. 3 vol. Paris: Galilée, 1994-2001.

TERRANOVA, Tiziana. *After the Internet: Digital Networks between Capital and the Common*. Los Angeles: Semiotext(e)/MIT Press, 2022. ISBN 978-1-63590-168-9.

---
