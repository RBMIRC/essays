---
title: "L'Archive Liquide"
translation: "/en/archives/liquid-archive-prismatic-default"
subtitle: "Workshop Retcon Black Mountain, Ecole Nationale Supérieure de la Photographie, Arles"
author: "Sylvain Couzinet-Jacques"
date: "2025"
lang: fr
license: GPL-3.0-or-later
provenance: "Workshop ENSP Arles 2024, avec Mabe Bethonico"
tags:
  - liquid-archive
  - prismatic-default
  - statistical-commons
  - generative-AI
  - photography
  - pedagogy
  - latent-space
  - model-collapse
  - _Benjamin
  - _Barthes
  - _Sontag
  - _Flusser
  - _Bauman
  - _Parikka
  - _Pasquinelli
  - _Crawford
  - _Stiegler
  - _Simondon
  - _Glissant
  - _Dewey
  - _Freire
  - _Ranciere
  - _Yuk-Hui
  - _Haraway
  - _Barad
  - _diffraction
  - _friction
  - _entropy
  - _liquidity
  - _prism
  - _statistical-unconscious
  - _proletarianization
  - _cosmotechnics
  - _technodiversity
  - _Black-Mountain-College
    
---

<details class="heredoc-block">
<summary>◈ ARCHIVE-LIQUIDE v1.0</summary>

**Titre :** L'Archive Liquide  
**Sous-titre :** Workshop Retcon Black Mountain, École Nationale Supérieure de la Photographie, Arles  
**Auteur :** Sylvain Couzinet-Jacques  
**Date :** 2025  
**Intention :** Analyser la transformation de l'image quand elle perd sa fonction documentaire face à l'IA générative  
**Provenance :** Workshop ENSP Arles 2024, avec Mabe Bethonico  
**Généalogie :** Benjamin (inconscient optique) → Barthes (punctum) → Flusser (appareil) → Bauman (modernité liquide) → Stiegler (prolétarisation)  
**Éthique :** Diffraction · Friction · Opacité  
**Licence :** GPL-3.0-or-later  
**Chaîne de forks :** [Philosophie de la photographie] → actuel → [en attente du prochain fork]  
**Contamination :** Infusé de {New Aesthetic, archéologie des médias, études des plateformes, cosmotechnique}  
**Confiance :** Observations d'atelier ancrées dans un cadre théorique  
**Notes :** L'image ne témoigne plus de la distance ; elle rend « proximal » ce qui est statistiquement probable  

</details>

## Introduction : La crise de l'image comme crise politique

### Le point de départ : une expérience pédagogique

Ce texte procède d'une expérience pédagogique — un atelier mené avec des étudiant.e.s en photographie confrontés pour la première fois dans le cadre de leur cursus aux outils d'intelligence artificielle générative. L'intention initiale était modeste : observer comment de jeunes praticien.ne.s — dont la formation traverse aussi bien les héritages documentaires que les pratiques plasticienne, performative ou post-internet — réagiraient face à des machines capables de produire des images sans référent. Des documents de Black Mountain College ont servi de trame à des conversations collectives, mais très peu de documents visuels ont servi de support pour le workshop.

Ce qui s'est joué dans cet atelier dépasse largement le cadre d'une initiation technique. Il a fonctionné comme un révélateur, au sens photographique du terme : il a fait apparaître, dans l'espace clos d'une salle de classe, les mêmes symptômes que l'on observe à l'échelle de la culture visuelle contemporaine. Une perte de repères politiques et intentionnels. Une liquéfaction des enjeux du document et de sa valeur sociale. Un repli sur les formes connues — esthétiques, communicationnelles, engagées — non pas comme affirmation mais comme refuge.

### La question qui organise ce texte

La question qui organise ce texte n'est pas : « L'IA va-t-elle remplacer les photographes ? » — question économique légitime mais insuffisante. Elle n'est pas non plus : « Les images générées sont-elles de l'art ? » — question esthétique qui présuppose des catégories peut-être déjà obsolètes. La question est plus fondamentale : que devient l'image quand elle perd sa fonction de document ?

---

## De l'ontologie de la trace à la phénoménologie du flux

Cette question — à quoi sert l'image ? — n'appelle pas une réponse fonctionnelle, mais une enquête sur la nature du lien entre le sensible et le réel. Si l'on suit la généalogie de la pensée visuelle du XXe siècle, on observe un glissement sémantique majeur : l'image passe du *statut de vestige à celui de vecteur*.

### L'aura et l'inconscient optique (Benjamin)

Chez Walter Benjamin, la question de l'utilité de l'image est indissociable de sa valeur d'usage politique. La perte de l'aura — « l'unique apparition d'un lointain, si proche soit-il » (BENJAMIN, 1935/2000, p. 75) — est le prix de la reproductibilité technique. Mais cette perte ouvre la voie à ce que Benjamin nomme *l'inconscient optique* : la photographie « fait apparaître cet inconscient optique, comme la psychanalyse l'inconscient pulsionnel » (BENJAMIN, 1931/2000, p. 301). L'image photographique révèle des structures de la réalité que l'œil nu ne peut saisir — le mouvement décomposé, le détail agrandi, la configuration spatiale invisible à la perception ordinaire. L'inconscient optique révélait une matérialité du monde qui échappait au regard.

Dans le contexte de l'IA générative, l'espace latent apparaît comme la forme terminale, mathématisée, de cet inconscient. Mais le basculement est radical : il ne s'agit plus d'explorer les détails du monde physique, mais les corrélations invisibles au sein de la masse des données. L'inconscient optique devient inconscient statistique. Ce que révèle l'IA, ce n'est plus une matérialité du monde, mais une logique du langage et du style qui échappe à la conscience individuelle.

Ce retournement est réflexif : chez Benjamin, la machine aidait à voir le réel ; chez l'IA, la machine aide à voir le *pattern*. L'image ne sert plus à « dévoiler » la nature, mais à « exposer » la structure de nos propres représentations collectives. L'œil ne regarde plus l'objet — il regarde la manière dont la culture a regardé l'objet. L'image ne témoigne plus du lointain ; elle rend « proximal » ce qui est statistiquement probable.

### Le référent adhérent et la spectralité sans corps (Barthes)

Pour Roland Barthes dans *La Chambre claire*, l'image photographique est un « médium bizarre, une nouvelle forme d'hallucination » (BARTHES, 1980, p. 177) car elle contraint l'esprit à admettre l'existence passée de l'objet. Le noème de la photographie est le « Ça-a-été » : « cela que je vois s'est trouvé là » (BARTHES, 1980, p. 120). L'image sert de certificat de présence, une preuve ontologique où le référent « adhère » à la surface sensible. L'image barthésienne est une émanation du référent — les photons qui ont touché le sujet ont touché la pellicule. C'est cette chaîne physique qui fonde la « mort douce » de la photographie : elle conserve la trace d'un corps qui a existé.

Face à *l'archive liquide*, cette adhérence se dissout. L'image générée par IA est un « Ça-aurait-pu-être ». Elle ne certifie plus une présence, mais une vraisemblance. Plus radicalement : l'image IA est une émanation du *dataset*, pas du référent. Elle est spectrale — elle possède l'apparence de la vie (la texture, le grain, la lumière) sans avoir jamais eu de corps. Ce que nous perdons, ce n'est pas seulement la « vérité » ; c'est la chair du temps.

On passe de l'image-souvenir à l'image-prédiction — une image qui ne regarde plus vers le passé mais vers la distribution de probabilités du futur. L'image-prédiction évacue la finitude humaine au profit d'une éternité statistique. Elle n'est plus indexée sur un moment qui a eu lieu, mais sur un espace de possibles qui n'a pas de date.

### L'image comme prédation et extractivisme cognitif (Sontag)

Susan Sontag radicalise l'approche en faisant de l'image un instrument d'accumulation. « Photographier, c'est s'approprier la chose photographiée » (SONTAG, 1977/1979, p. 14) ; c'est transformer le monde en une « anthologie d'images » qui finit par remplacer l'expérience directe. L'image sert à gérer le réel par le biais du cadre — elle découpe, sélectionne, possède. C'est ce qu'on pourrait appeler une éthique du cadre : le photographe exerce un pouvoir sur ce qu'il choisit de montrer.

Dans l'ère de ce que je nomme les *communs statistiques*, nous passons de cette éthique du cadre à une économie de l'extraction. Ce n'est plus le photographe qui s'approprie un sujet particulier ; c'est le modèle — via le *scraper* qui collecte les données d'entraînement — qui s'approprie l'ensemble des gestes de vision pour les transformer en capital algorithmique. Le photographe n'est plus celui qui prend une photo ; il est celui qui génère des données. La prédation ne s'exerce plus sur le sujet photographié, mais sur le geste créatif lui-même, qui est « aspiré » pour entraîner son propre remplaçant algorithmique.

L'image ne sert plus à connaître le monde, mais à nourrir la machine qui le simulera. La prédation devient extraction ; le photographe devient ressource. C'est la logique du capitalisme cognitif appliquée au visuel : chaque image produite alimente un espace latent dont les bénéfices sont privatisés par les propriétaires des modèles.

### Le pivot : l'image-programme (Flusser)

Le philosophe Vilém Flusser est le chaînon manquant entre la photographie argentique et *l'archive liquide*. Dans *Pour une philosophie de la photographie*, il soutient que les images techniques sont « une nouvelle sorte d'abstraction », produites par des appareils, et que leur prétendue objectivité « dissimule leur nature de symboles qui encodent des concepts » (FLUSSER, 1983/1996, p. 17). Pour Flusser, l'image technique n'est pas le reflet du monde, mais le produit d'un appareil — un dispositif dont le photographe explore les possibilités programmées. « Les photographes ne travaillent pas, ils jouent » avec les combinaisons offertes par le programme de leur appareil (FLUSSER, 1983/1996, p. 28).

Cette intuition trouve son aboutissement dans l'IA générative. *L'image liquide* n'a plus besoin de référent extérieur ; elle n'est que la manifestation d'une boîte noire explorant ses propres limites internes. L'image ne sert plus à représenter — elle sert à itérer. Elle est un jeton dans un jeu probabiliste, une actualisation parmi des milliards d'actualisations possibles dans l'espace latent. Le photographe flusserien, qui jouait contre l'appareil pour en révéler les potentialités cachées, devient le prompteur — celui qui formule des requêtes à un programme dont il ne maîtrise pas les règles et dont il alimente, à chaque usage, la puissance.

---

## Ce que nous perdons : la désubjectivation du regard

Si l'on croise ces quatre perspectives, on peut cartographier ce que l'image perd dans sa transition vers l'espace latent. Ce qui se joue est une désubjectivation progressive : le sujet qui regarde, qui cadre, qui décide, qui témoigne, se trouve dépossédé de ses prérogatives.

De Benjamin, nous perdons l'exploration du réel pour une exploration du langage. L'inconscient optique révélait les structures cachées du monde physique ; l'inconscient statistique ne révèle que les corrélations du dataset — c'est-à-dire la manière dont nous avons collectivement représenté le monde, pas le monde lui-même.

De Barthes, nous perdons l'attestation du passé pour la suggestion du probable. Le « Ça-a-été » s'efface au profit du « Ça-pourrait-être » — l'indice cède la place au simulacre. Plus profondément : nous perdons la chair du temps, cette émanation physique d'un corps qui a existé, au profit d'une spectralité sans référent.

De Sontag, nous perdons la capture du sujet pour l'extraction de la donnée. Le pouvoir du photographe sur son sujet devient le pouvoir du modèle sur l'ensemble des photographes. L'éthique du cadre — qui supposait une responsabilité face au visible — cède la place à une économie de l'extraction où le geste créatif est lui-même la ressource exploitée.

De Flusser, nous perdons le jeu contre l'appareil pour la soumission au programme. Le photographe qui détournait son Kodak pour produire de l'inattendu devient le prompteur qui alimente le modèle sans en comprendre les règles — et qui, ce faisant, contribue à l'entraînement de sa propre obsolescence.

La fonction testimoniale s'effondre. L'image photographique a servi, depuis le XIXe siècle, de preuve dans les procès, de document dans les archives, de témoignage dans le journalisme. Cette fonction reposait sur une confiance sociale dans l'indexicalité de la trace. L'IA générative rend cette confiance impossible — non pas parce que toutes les images deviennent fausses, mais parce que toute image devient suspecte. Le régime de croyance s'effondre.

La fonction mémorielle se dissout. Flusser définissait l'image technique comme un outil de lutte contre l'entropie — une manière de fixer le flux du temps. L'album de famille, l'archive photographique, le fonds documentaire : autant de dispositifs qui permettaient de constituer une mémoire collective transmissible. L'image générique, produite à la demande et jetable, ne constitue pas de mémoire. Elle participe de ce que Bernard Stiegler appelait la prolétarisation des savoirs : ces technologies « fonctionnent pour le moment comme des instruments qui privent les cerveaux de leur conscience, c'est-à-dire de leur rapport au savoir » (STIEGLER, cité par CASSOU-NOGUÈS, 2024). Mais ici, ce n'est pas seulement le savoir-faire technique qui se perd — c'est le savoir-voir lui-même. Si l'appareil voit pour nous et décide de la probabilité d'une forme, c'est notre capacité à exercer un jugement esthétique qui s'atrophie.

La fonction critique se neutralise. Jacques Rancière a montré que l'image était un outil du partage du sensible — « ce système d'évidences sensibles qui donne à voir en même temps l'existence d'un commun et les découpages qui y définissent les places et les parts respectives » (RANCIÈRE, 2000, p. 12). La photographie documentaire a joué ce rôle politique : elle faisait dissensus, elle perturbait l'ordre du visible.

L'IA générative, par définition, est une machine à consensus. Elle calcule la « moyenne » de ce qu'est une belle image, une image révoltante, une image triste. Le partage du sensible devient un lissage du sensible. L'image ne sert plus à faire dissensus, mais à produire de l'adhésion par le biais du « vibe » — cette cohérence esthétique immédiate qui frappe sans argumenter. Elle montre ce qui est déjà attendu, ce qui correspond à la distribution majoritaire. Elle ne dérange pas, elle confirme.

---

## La dialectique : ce que nous gagnons peut-être

Il serait trop simple de s'en tenir à ce constat de perte. L'IA générative ouvre aussi des possibilités que la photographie traditionnelle n'offrait pas.

La libération de l'imaginaire : Joan Fontcuberta, théoricien de la « post-photographie », argue que la fin de l'indexicalité libère l'image de son asservissement au réel. Dans *La fureur des images*, il soutient que nous sommes entrés dans un régime où « les images ne témoignent plus, elles construisent » (FONTCUBERTA, 2017, p. 25). L'image n'a plus à prouver, elle peut inventer. Elle devient un espace de fiction assumée, de spéculation visuelle, d'exploration de mondes possibles. Pour Fontcuberta, ce n'est pas une perte mais un gain : la photographie était prisonnière de sa fonction documentaire, l'image générative s'en émancipe.

La démocratisation de la production : N'importe qui peut désormais produire des images de haute qualité technique sans maîtriser les compétences traditionnelles. On peut y voir une prolétarisation au sens de Stiegler, ou une démocratisation au sens d'une extension de l'accès aux moyens de production visuelle. La question reste ouverte : qui bénéficie réellement de cette démocratisation, et à quel prix pour le commun ?

L'exploration de l'espace latent : Les artistes qui travaillent avec l'IA découvrent un nouveau territoire, l'espace latent, cet espace mathématique multidimensionnel où les concepts sont encodés sous forme de vecteurs. Naviguer dans cet espace, c'est explorer les corrélations implicites du dataset, révéler les biais, produire des formes inattendues. C'est une nouvelle forme de sérendipité visuelle — même si elle reste contrainte par les limites du modèle.

---

## La thèse de ce texte

La thèse de ce texte est que ces gains apparents sont compromis par un défaut d'ajustement entre le plan technique et le plan politique. L'IA générative produit des images, mais elle ne produit pas les conditions de leur circulation, de leur interprétation, de leur contestation. Elle génère du contenu, mais pas de commun.

Nous proposons de nommer ce défaut : le *défaut prismatique*. Le prisme est un appareil optique qui décompose la lumière blanche en spectre de couleurs — il révèle la pluralité contenue dans l'apparent uniforme. Mais le prisme est aussi, dans notre perspective, l'outil de la re-politisation. Si *l'archive liquide* est une « bouillie » où tout se mélange, le prisme est ce qui réintroduit de la finitude et de la responsabilité.

*L'archive prismatique* ne se contente pas de stocker des flux ; elle permet de remonter la chaîne des causalités. Qui a produit cette donnée ? Quel biais a été appliqué ? Quelle perspective a été écrasée ? Elle transforme le « slop » — le contenu générique, le spam visuel de l'ère algorithmique — en un objet d'étude diffracté, dont on peut interroger les couches et les origines. L'image n'y est plus un point final (un document), mais une interface — un lieu de tension politique et esthétique.

Mais il faut aller plus loin. *L'archive prismatique* n'est pas seulement un concept critique — elle est elle-même une technique, avec ce que toute technique comporte d'ambivalence constitutive. Simondon nous a appris qu'un objet technique n'existe que dans son milieu associé — l'ensemble des conditions, des usages, des détournements qui lui donnent sens. Dans cette perspective, je propose de distinguer trois régimes dans lesquels toute archive technique opère simultanément :

Le régime de la traçabilité : toute archive implique une forme de veille, de documentation, de regard sur le monde. *L'archive prismatique* n'échappe pas à cette dimension — elle rend visible, elle expose, elle conserve la possibilité d'une enquête.

Le régime de la transmission : toute archive engage un rapport au sens qui dépasse l'utilitaire. Elle commémore, elle institue une mémoire collective, elle lie les vivants aux morts et aux générations futures. Il y a dans l'archive une dimension rituelle — non pas religieuse, mais instituante.

Le régime du bricolage : toute archive est appropriable, détournable, reconfigurable. *L'archive prismatique* n'est pas un protocole figé mais un ensemble de gestes possibles, de pratiques situées, de recombinaisons imprévues.

Ces trois régimes ne s'excluent pas ; ils coexistent dans toute technique vivante. Refuser l'un — par exemple, rejeter toute traçabilité au nom de la liberté, ou tout rituel au nom de l'efficacité —, c'est mutiler les deux autres. L'archive prismatique assume cette triple condition.

Elle assume donc un régime éthique qui lui est propre — situé (elle ne prétend pas à l'universalité algorithmique), individué (elle se constitue dans des contextes singuliers, avec des acteurs identifiables), responsable (elle peut rendre des comptes sur ses choix). 

C'est en cela qu'elle s'oppose à *l'archive liquide*, dont le régime éthique est précisément l'absence de régime — la dissolution de toute responsabilité dans le flux statistique. *L'archive liquide* est celle où tout se mélange sans se distinguer — une bouillie statistique où les perspectives se dissolvent. La liquéfaction n'est pas la condition postmoderne normale de l'archive. Elle est le moment exact où l'archive perd sa dimension prismatique — c'est-à-dire politique, collective et reconfigurable. Elle cesse de traverser la profondeur des perspectives humaines pour ne plus circuler qu'à la surface de ses propres distributions.

Si la photographie a été l'invention d'une machine à arrêter le temps (la trace), l'IA générative est l'invention d'une machine à abolir l'événement (le flux). Le passage de l'un à l'autre ne marque pas seulement une évolution technique, mais l'entrée dans un régime visuel où l'image, vidée de sa fonction documentaire, devient le lieu d'une lutte pour le maintien d'une dimension prismatique — seule capable de sauver la singularité du regard face à l'hégémonie du probable.


---

## Méthode et structure

Pour analyser ce défaut, nous proposons une méthode empruntée à Donna Haraway et Karen Barad : la diffraction. La critique traditionnelle de l'IA opère souvent sur le mode de la réflexion — on tient un miroir face à la machine pour dénoncer ses biais, ses erreurs, ses hallucinations. La diffraction, en revanche, s'intéresse aux motifs d'interférence qui surgissent lorsque des ondes — ici, le savoir computationnel et la réalité matérielle — se croisent et se perturbent mutuellement. Pour Barad, la diffraction est un dispositif qui « met en lumière, expose et rend évidente la structure enchevêtrée de l'ontologie changeante et contingente du monde » (BARAD, 2007, p. 73, ma traduction).

La réflexion demande : « Cette image est-elle vraie ? » La diffraction demande : « Quels enchevêtrements politiques et matériels produisent cette esthétique ? » Ce déplacement a des conséquences pour l'analyse. On ne se contente pas de dire que l'archive liquide est « fausse » ou « biaisée ». On observe comment elle interagit avec le monde pour produire de nouvelles réalités — comment l'esthétique ambrée de l'IA commence à influencer les photographes humains qui tentent d'imiter l'algorithme pour être visibles sur les plateformes. C'est ce que Barad appelle les intra-actions : l'IA ne représente pas le monde, elle le reconfigure. Haraway, de son côté, critique le god trick — la prétention à voir de nulle part — et lui oppose des « savoirs situés » qui assument leur positionnalité et leur responsabilité (HARAWAY, 1988, p. 581).

Ce texte procède en sept temps. Il commence par une généalogie de la vision machinique, de la "New Aesthetic" de James Bridle aux "images opérationnelles" de Harun Farocki (I). Il analyse ensuite l'espace latent comme un commun non gouverné, en mobilisant le concept de *communs statistiques* et la sociologie de Zygmunt Bauman (II). Il décrit la physique des plateformes et les mécanismes d'extraction cognitive théorisés par Matteo Pasquinelli (III). Il examine la thermodynamique de la culture — le phénomène de *model collapse* et ses manifestations esthétiques (IV). Il revient alors sur l'expérience de l'atelier comme révélateur de ces dynamiques (V). Il propose des pistes pour une écologie de la friction, en mobilisant le "Droit à l'Opacité" d'Édouard Glissant (VI). Il conclut par une réflexion sur l'éthique de la pédagogie de l'image générative, en s'appuyant sur Dewey, Freire, Rancière, Simondon et Stiegler (VII).

Quatre motifs traversent ces sept sections et reviennent à différentes échelles : la liquidité, l'entropie, la friction, le prisme. Leur récurrence n'est pas redondance — elle tente de performer, dans l'écriture même, ce que serait une *archive prismatique* : chaque passage par le même concept l'éclaire autrement, l'enrichit d'une couche supplémentaire.

---

## I. Généalogies de la vision machinique

### 1. *L'archive liquide* avant l'IA : Carlos Amorales

Avant de devenir un concept théorique appliqué aux modèles génératifs, le terme *Liquid Archive* désignait une pratique artistique. L'artiste mexicain Carlos Amorales a développé à la fin des années 90 une banque d'images vectorielles — des silhouettes numériques détachées de leur contexte d'origine, recombinables à l'infini. Chez Amorales, l'archive liquide est un réservoir de formes qui peuvent être assemblées, superposées, déformées, sans référence à un original stable.

Ce précédent artistique éclaire le fonctionnement des modèles génératifs actuels. Midjourney ou Stable Diffusion opèrent une « vectorisation » du monde analogue à celle d'Amorales — mais à une échelle industrielle et automatisée. Ils réduisent des œuvres complexes, chargées d'histoire et d'émotion, à des motifs statistiques recombinables. Le défaut n'est pas technique, il est ontologique : en devenant liquide, l'archive détruit la singularité de l'œuvre pour la fondre dans un flux indifférencié.

La différence cruciale : chez Amorales, la liquidité était un geste d'artiste, conscient et délibéré. Dans l'espace latent des modèles génératifs, elle est une propriété structurelle du système — personne ne l'a décidée, personne ne la gouverne.

### 2. La New Aesthetic comme préhistoire du latent

Au début des années 2010, James Bridle a cristallisé sous le terme de *New Aesthetic* une observation empirique : l'irruption du langage numérique dans le monde physique. Des coussins aux motifs pixelisés, des bâtiments conçus pour être lus par des satellites, des camouflages militaires adoptant des patterns fractals. Bridle collectait ces artefacts sur un Tumblr, sans manifeste dogmatique — un geste rhizomatique de documentation (BRIDLE, 2011-2013).

La New Aesthetic cherchait à rendre visible l'infrastructure invisible. Elle donnait forme sensible aux flux de données, aux protocoles de surveillance, aux algorithmes de compression. Les carrés verts grossiers de Google Earth, censés représenter des champs agricoles mais trahissant la basse résolution du capteur, devenaient des objets esthétiques révélant la médiation technique de notre rapport au territoire.

Cette observation rejoignait les travaux de Harun Farocki sur les images opérationnelles (FAROCKI, 2004) et ceux de Trevor Paglen sur la "vision machine" : des images faites par des machines pour des machines, qui n'ont plus besoin de l'œil humain pour fonctionner (PAGLEN, 2016). Images de drones, de systèmes de reconnaissance faciale, de satellites — un régime visuel où l'humain devient spectateur accidentel d'un dialogue entre appareils.

Dans une perspective complémentaire, Gwenola Wagon et Stéphane Degoutin ont documenté dans *World Brain* (2015) et *Globodrome* (2013) la matérialité des infrastructures numériques : data centers, câbles sous-marins, zones logistiques. Leur archéologie visuelle du *cloud* fait le lien entre la New Aesthetic et la *Geology of Media* de Parikka — le numérique n'est pas immatériel, il a des adresses physiques et des coûts écologiques.

Mais cette esthétique restait ancrée dans un paradigme indexical. Les images, aussi glitchées soient-elles, référaient toujours à une réalité préexistante. L'image satellite, même pixelisée, était trace d'un territoire géographique réel. Le *glitch* était l'accident survenu à un fichier original lors de sa transmission. La machine voyait le monde — différemment, certes, mais elle regardait encore le monde.

### 3. De la vision à l'hallucination : le basculement post-digital

Une décennie plus tard, l'émergence de l'IA générative (Midjourney, Stable Diffusion, DALL-E) opère un basculement radical. Nous ne sommes plus dans le régime de la vision machine mais dans celui de *l'hallucination machine*. L'ordinateur ne traite plus des *inputs* visuels ; il synthétise de nouvelles réalités à partir de distributions statistiques.

Ce basculement inverse le schéma de Farocki et Paglen. Les images opérationnelles excluaient l'humain du circuit visuel — machines parlant à des machines. L'IA générative, au contraire, réintègre l'humain dans le dialogue, mais en l'extractant : ce qu'il pense, ce qu'il dit, ce qu'il a produit devient matière première du modèle. Le prompt est une forme d'aveu ; la génération, une restitution statistique de l'imaginaire collectif. L'humain n'est plus spectateur accidentel — il est ressource.

C'est le véritable sens du post-digital : non pas l'après du numérique, mais le moment où le numérique se retourne sur ses propres conditions de production et commence à se nourrir de lui-même. Le "Model Collapse" n'est pas un accident technique — c'est la logique terminale de ce retournement. L'artiste Grégory Chatonsky explore depuis deux décennies cette logique entropique à travers le concept de telofossiles — ces traces que notre civilisation numérique laissera pour des archéologues futurs. Dans *La Quatrième Mémoire* (2025), installation présentée dans l'exposition « Le monde selon l'IA » au Jeu de Paume (commissaire : Antonio Somaini), Chatonsky utilise les mêmes modèles de diffusion (Stable Diffusion XL, LAION-5B) que ceux analysés ici pour produire une archéologie spéculative de notre présent — retournant l'outil contre lui-même pour en révéler les sédiments. Ce geste ne garantit rien : il expose une condition, il ne la résout pas.

L'esthétique de l'IA actuelle ne se définit plus par le pixel visible ou l'artefact de compression JPEG — signes distinctifs de la New Aesthetic — mais au contraire par une hyper-résolution, un lissage surnaturel, une cohérence sémantique troublante. Là où la New Aesthetic montrait la couture entre le numérique et le physique, l'esthétique de l'IA cherche à effacer toute trace de médiation, produisant des simulacres parfaits sans référent dans le monde réel.

### 4. L'Aesthetics Wiki et la prolifération catégorielle

Un phénomène parallèle mérite d'être interrogé : l'émergence de l'*Aesthetics Wiki*, encyclopédie communautaire recensant plus de mille « esthétiques » identifiées et nommées — Cottagecore, Dark Academia, Weirdcore, Liminal Space, Frutiger Aero (AESTHETICS WIKI, 2024). Ce wiki peut être lu comme une subdivision tardive de la New Aesthetic, ou comme sa réaction compensatoire.

D'un côté, le wiki prolonge le geste de Bridle : collecter, nommer, rendre visible. Mais là où la New Aesthetic cherchait à identifier les traces de la machine dans le monde physique, l'Aesthetics Wiki cartographie les styles vernaculaires nés des plateformes — des esthétiques qui n'existent souvent que comme flux d'images tagguées, sans auteurs identifiables, sans œuvres canoniques.

De l'autre côté, le wiki représente une tentative de résistance taxinomique face à la fluidité post-catégorielle de l'espace latent. Il est discret là où le latent est continu, hyper-catégoriel là où le latent est mathématique, narratif là où le latent est vectoriel. Le wiki a d'ailleurs banni le contenu généré par IA dans ses règles communautaires, affirmant que l'IA ne possède pas la « compréhension culturelle » nécessaire (AESTHETICS WIKI, « AI Policy », 2024) — un geste politique de démarcation entre la création humaine intentionnelle et la synthèse probabiliste.

Mais il y a plus. Ces catégorisations — Cottagecore, Vaporwave, Liminal Space — sont des tentatives de nommer des brins idéologiques d'effets pré-IA. Elles fixent rétrospectivement des tendances visuelles qui ont émergé avant que l'IA générative ne les dissolve dans l'espace latent. Ce sont des *fossiles taxinomiques* : des traces de ce que l'imaginaire collectif produisait quand il n'était pas encore capturé par les modèles. En ce sens, l'Aesthetics Wiki est moins un outil de création qu'un monument funéraire — une archive de ce qui pouvait encore être nommé.

Cette tension entre prolifération catégorielle et dissolution latente traverse l'ensemble de la culture visuelle contemporaine. Elle pose une question que ce texte ne prétend pas résoudre : qui pense l'esthétique en 2025 ? Quels sont les lieux, les collectifs, les méthodes qui permettent encore de produire des concepts pour ce qui nous arrive visuellement ? La théorie critique classique (Adorno, Benjamin) a été conçue pour d'autres régimes d'images. Les *cultural studies* et les *visual studies* peinent à suivre la vélocité des mutations. Les plateformes elles-mêmes génèrent leur propre métalangage vernaculaire (*vibe, aesthetic, core*), mais sans appareil critique. La question reste ouverte — et son urgence croît avec chaque nouvelle version des modèles.

### 5. Le nouvel âge sombre

James Bridle lui-même a anticipé cette évolution dans New Dark Age. « Le volume même d'information disponible aujourd'hui révèle moins que nous ne l'espérons. Il annonce plutôt un nouvel Âge Sombre : un monde d'incompréhension toujours croissante » (BRIDLE, 2018, p. 3, ma traduction). Le fossé grandissant entre la complexité des systèmes que nous construisons et notre capacité cognitive à les comprendre définit notre condition contemporaine. L'opacité des réseaux de neurones profonds introduit une « nouvelle esthétique de la politique ». La question n'est plus de voir les pixels — de toute façon lissés par *l'upscaling neuronal* — mais de comprendre les vecteurs invisibles, les biais latents, les architectures de probabilité qui régissent la génération de notre réalité commune.

> **Premier retour du motif : la liquidité.** L'archive n'est plus une collection d'objets visibles sur un Tumblr. Elle est devenue un espace latent invisible et multidimensionnel — un flux sans points d'ancrage.

---

## II. L'espace latent comme commun non gouverné

### 1. La modernité liquide et ses sédiments

Zygmunt Bauman, dans son analyse de la *Modernité Liquide*, décrit le passage d'une phase « solide » de l'histoire à une phase « fluide ». Les formes sociales « ne peuvent plus […] garder leur forme longtemps » parce qu'elles se décomposent plus vite qu'on ne peut les adopter (BAUMAN, 2007, p. 1). Dans cet état, le pouvoir appartient non plus à ceux qui contrôlent le territoire, mais à ceux qui contrôlent les flux.

L'archive liquide des modèles génératifs est l'incarnation technologique de cette sociologie. Elle n'est pas constituée de documents fixes mais de vecteurs probabilistes. Le « savoir » n'y est pas stocké ; il est reconstitué dynamiquement à chaque requête. Cette liquidité a une conséquence politique : l'obsolescence programmée de la mémoire. L'archive liquide produit un *Forever Now* où l'oubli est la condition de l'adaptation continue.

Cependant, cette liquidité est trompeuse. Jussi Parikka, dans *A Geology of Media*, développe une « media history of matter » qui articule extraction minière, infrastructures numériques et déchets électroniques (PARIKKA, 2015, p. 5). Il fait des médias une médiation entre les sédimentations anciennes et la « geology of waste » de l'Anthropocène. Le « cloud » est une métaphore qui dissimule une réalité géologique lourde. L'archive liquide repose sur l'extraction massive de minerais rares, sur des centres de données qui consomment des quantités considérables d'eau et d'électricité, sur des réseaux de câbles sous-marins. L'archive est « liquide » non seulement parce qu'elle est fluide, mais parce qu'elle liquéfie les ressources planétaires. Elle transforme l'énergie fossile et l'eau potable en tokens statistiques. L'immatérialité apparente de l'IA est soutenue par une matérialité écrasante.

### 2. Les communs statistiques : du code à l'image

Le concept de *communs statistiques* que j'ai tenté de définir dans le "Heredoc Manifesto" a été développé pour décrire ce qui se produit dans le domaine du code et du texte lorsque des modèles de langage sont entraînés sur des corpus massifs. Le phénomène est d'abord textuel : chaque ligne de code publiée, chaque documentation technique, chaque texte mis en ligne contribue involontairement à l'entraînement des LLM. La propriété intellectuelle privée se transforme, par le processus d'entraînement, en distribution de probabilités partagée. Le code source, protégé par des licences, devient *pattern* statistique accessible à quiconque dispose du modèle.

Ce commun se constitue automatiquement, sans délibération — contrairement aux communs traditionnels (forêts, pâturages) soumis à des règles d'usage collectif négociées. Il n'existe pas d'assemblée des contributeurs, pas de protocole de réciprocité. La valeur circule sans politique. La recombinaison n'y est que probabiliste, jamais décisionnelle — elle reflète la corrélation, pas la négociation.

L'extension de ce concept au domaine de l'image demande une précaution. Les modèles de diffusion (Stable Diffusion, Midjourney) opèrent différemment des LLM : ils ne prédisent pas le token suivant mais dé-bruitent progressivement une image à partir de bruit gaussien. Pourtant, le mécanisme fondamental reste analogue : un corpus massif d'images — photographiques, picturales, graphiques — est compressé en distributions de probabilités dans l'espace latent. L'image privée devient texture statistique commune. La question de la gouvernance de ce commun se pose avec la même acuité.

### 3. L'archive liquide comme défaut prismatique

C'est ici que la notion d'*archive liquide* prend son sens véritable. Elle ne désigne pas simplement la fluidité de la circulation des données, caractéristique des réseaux distribués. Elle désigne la nature même du stockage ontologique dans l'espace latent : une représentation vectorielle continue où les concepts ne sont plus stockés comme entités distinctes mais comme probabilités en suspension.

Cependant — et c'est l'inflexion décisive — cette liquidité n'est pas une condition neutre ou naturelle. Elle est le symptôme d'un défaut d'ajustement entre le plan technique et le plan politique. L'archive se liquéfie quand elle n'a pas la bonne dimension politique — prismatique — qui permettrait sa recombinaison.

Le prisme, contrairement au miroir liquide, diffracte sans dissoudre. Il est un appareil d'ajustement, une interface entre dimensions. L'*archive prismatique* traiterait la donnée non comme flux turbulent mais comme spectre recombinatoire : chaque angle — social, esthétique, économique, affectif — renverrait une couleur distincte. Là où l'archive liquide se borne à la circulation instantanée, l'archive prismatique construirait une écologie de récursivité : un système où la répétition renvoie toujours à un nouvel angle d'interprétation, non à une redondance.

Sans gouvernance, sans ajustement prismatique, l'espace latent tend vers l'uniformisation. La variance diminue. La diversité disparaît. Le modèle converge vers une moyenne terne. Le *commun statistique* — ce mécanisme par lequel le traitement probabiliste transforme le privé en ressource partagée — existe bien, mais il reste non gouverné, livré aux forces entropiques.

---

## III. Physique des plateformes et anatomie du prisme

### 1. Le Nooscope : l'instrument de la réduction ontologique

Matteo Pasquinelli et Vladan Joler proposent le concept de Nooscope pour briser le mythe de l'IA comme entité autonome. Ils décrivent l'IA non comme une intelligence autonome, mais comme un « instrument d'amplification de la connaissance » qui transforme des masses de données en modèles statistiques de perception (PASQUINELLI et JOLER, 2021, p. 1264, ma traduction). Le Nooscope vise à « séculariser l'IA de son statut idéologique de "machine intelligente" vers celui d'instrument de connaissance » (PASQUINELLI et JOLER, 2021, p. 1265, ma traduction). Le Nooscope n'est pas un télescope qui étendrait la vision ; c'est un instrument de diffraction qui révèle que l'IA ne « pense » pas — elle automatise la perception.

Le mécanisme est celui d'une compression de la connaissance. L'algorithme ne « voit » pas une image ; il détecte des distributions statistiques de pixels — bords, textures, contrastes. Il codifie une tâche cognitive humaine (reconnaître une forme, interpréter un contexte) pour la transformer en opération statistique. Ce faisant, il opère ce qu'on pourrait appeler un épistémicide discret : en transformant la perception qualitative — le sens, l'histoire, l'ironie, l'ambiguïté sociale — en distributions quantitatives, le prisme algorithmique élimine tout ce qui résiste à la quantification.

Le défaut prismatique naît ici. Le prisme algorithmique n'est pas une vitre transparente ; c'est un dispositif qui n'autorise le passage que de ce qui est quantifiable. Ce que nous appelons « biais » n'est pas une erreur du système, mais sa logique fondamentale : l'imposition d'une vision normative dictée par la moyenne. L'IA est le « Maître » car elle détient le pouvoir de définir la « normalité » statistique du monde — ce qui est probable, ce qui est attendu, ce qui est générable.

### 2. Le coût matériel du commun statistique

Le Nooscope de Pasquinelli et Joler révèle la logique épistémique de l'IA ; il laisse dans l'ombre son infrastructure matérielle. Kate Crawford, dans *Atlas of AI*, propose une cartographie complémentaire — non plus des flux de données mais des chaînes d'extraction qui les rendent possibles (CRAWFORD, 2021).

L'atlas commence par la terre. Les GPU qui entraînent les modèles de diffusion requièrent du cobalt (République Démocratique du Congo), du lithium (Chili, Argentine, Australie), des terres rares (Chine). Ces extractions ont des coûts humains documentés : travail des enfants dans les mines artisanales, pollution des nappes phréatiques, déplacement de communautés. Le « cloud » — cette métaphore aérienne qui suggère l'immatérialité — repose sur une géologie lourde, extractive, inégalement répartie.

L'atlas se poursuit par l'énergie. Les data centers qui hébergent les modèles consomment des quantités massives d'électricité et d'eau de refroidissement. En 2022, les data centers de Google ont consommé 21,2 milliards de litres d'eau — l'équivalent de la consommation annuelle de 37 terrains de golf en Arizona. L'entraînement d'un seul grand modèle de langage émet autant de CO2 que cinq voitures pendant toute leur durée de vie. Chaque image générée par Midjourney ou Stable Diffusion consomme environ 2,9 Wh — une charge de smartphone. Multipliée par les milliards de générations quotidiennes, l'empreinte devient vertigineuse. L'image « légère » — ce JPEG de quelques mégaoctets — est énergétiquement massive.

L'atlas se termine par le travail. Crawford rejoint ici Gray et Suri, mais élargit le cadre. Le « travail fantôme » n'est pas seulement celui des annotateurs et des modérateurs ; c'est l'ensemble du travail humain qui entre dans les datasets sans consentement ni compensation. Chaque photographe dont les images ont été scrapées pour LAION-5B, chaque artiste dont le style a été vectorisé sans permission, chaque utilisateur dont les requêtes servent à l'entraînement par renforcement — tous participent à ce que Crawford nomme l'extractivisme épistémique : l'appropriation systématique du savoir-faire et du savoir-voir au profit d'infrastructures privées.

Hito Steyerl, artiste et théoricienne, prolonge cette analyse depuis la pratique. Dans Duty Free Art, elle observe que la valeur de l'image numérique ne réside plus dans son contenu mais dans sa circulation — ce qu'elle nomme le « circulationnisme » (STEYERL, 2017, p. 47). L'image n'a pas besoin d'être vraie, belle ou significative ; elle doit circuler, générer de l'engagement, alimenter les algorithmes de recommandation. Dans son dernier ouvrage, Medium Hot: Images in the Age of Heat, Steyerl radicalise ce diagnostic en introduisant le concept d'« image dérivée » (derivative image) : comme les produits financiers dérivés, les images générées par IA sont des moyennes statistiques extraites de vastes datasets, des « rêves sociaux sans sommeil » qui reflètent ce à quoi la société prête attention — et rien d'autre (STEYERL, 2025). Le Slop — ce spam visuel jauni et générique — est le produit logique de cette économie : une image optimisée pour la circulation, vidée de toute friction sémantique, parfaitement adaptée au flux.

Cette économie de l'image a une géographie. Safiya Umoja Noble, dans Algorithms of Oppression, montre que les biais des systèmes de recherche d'images ne sont pas des accidents techniques mais des structures de pouvoir (NOBLE, 2018). Les requêtes sur « beautiful woman » renvoient massivement des images de femmes blanches ; les requêtes sur « professional » excluent systématiquement certains corps. Ces biais sont encodés dans les datasets — qui surreprésentent les contenus occidentaux, anglophones, masculins — et amplifiés par les modèles qui apprennent à reproduire les distributions majoritaires. Le « jaunissement » que nous avons décrit n'est qu'un symptôme parmi d'autres d'un système qui converge vers des moyennes culturellement situées mais présentées comme universelles.
Le commun statistique existe — c'est un fait technique et juridique. Comme l'a montré le phénomène des licences GPL dans les LLM, le traitement statistique transforme effectivement la propriété privée en ressource collective : le code copyleft, une fois ingéré et redistribué par le modèle, « contamine » statistiquement l'ensemble des outputs. C'est l'effet viral des licences libres étendu à l'ère du machine learning. En ce sens, le commun statistique est potentiellement émancipateur — il défait les enclosures de la propriété intellectuelle par le fait même du calcul.

Mais ce que Crawford, Steyerl et Noble cartographient, ce sont les conditions de production de ce commun — et celles-ci relèvent bien d'une accumulation primitive. Kate Crawford définit l'IA comme une « technologie d'extraction : des minerais tirés de la terre, du travail prélevé sur des travailleurs sous-payés, des données captées sur chaque action et expression » (CRAWFORD, 2021, p. 15, ma traduction). Son projet Calculating Empires, réalisé avec Vladan Joler et récompensé par le Lion d'Argent à la Biennale d'architecture de Venise 2025, cartographie cette généalogie extractive sur cinq siècles — montrant que l'IA n'est pas une rupture mais l'intensification d'un régime colonial de longue durée. Les ressources terrestres, le travail humain, les œuvres protégées, les données comportementales — tout est aspiré dans une logique extractive qui précède et rend possible la mise en commun statistique. Ce qui est présenté comme « intelligence » est le produit d'une chaîne d'appropriations dont les coûts sont externalisés vers les périphéries : les pays du Sud qui fournissent les minerais et le micro-travail, les communautés qui subissent les pollutions, les créateurs dont les œuvres sont pillées, les utilisateurs dont l'attention est captée.

Le défaut prismatique prend ici une dimension supplémentaire. Ce n'est pas le commun statistique lui-même qui pose problème — c'est l'invisibilisation systématique des conditions de sa production et la privatisation de ses bénéfices. L'archive se liquéfie doublement : dans sa forme (le flux remplace le document) et dans sa matérialité (l'infrastructure disparaît sous la métaphore du cloud). Réintroduire le prisme, c'est rendre visibles ces chaînes d'extraction — et c'est aussi poser la question de la gouvernance : qui décide des règles d'usage du commun ? Qui en partage les bénéfices ?


### 3. L'archive de sang : travail fantôme et extractivisme

Derrière la liquidité de l'archive se cache une solidité géopolitique. Comme le soulignent Mary L. Gray et Siddharth Suri dans *Ghost Work*, le prisme génératif ne fonctionne que grâce à l'étayage d'une force de travail invisible — modérateurs, annotateurs, micro-travailleurs qui « nettoient » l'archive liquide, étiquettent les images, filtrent le contenu toxique, corrigent les hallucinations (GRAY et SURI, 2019, p. 8-12). Ce travail est massif, sous-payé, souvent délocalisé dans les périphéries du capitalisme mondial.

L'asymétrie est structurelle : la transparence de l'image générée — son lissage, sa perfection, sa haute résolution — est proportionnelle à l'opacité du travail nécessaire pour la produire. Le système rend l'image hyper-visible tout en frappant d'invisibilité les millions de mains qui ont trié les données pour que le « miracle » opère.

Le colonialisme cognitif ne porte plus seulement sur les corps ou les matières premières, mais sur la faculté de juger. On extrait la perception de travailleurs précaires pour « dresser » le modèle. L'espace latent est donc produit par l'exploitation, même si le commun statistique qu'il engendre — ce mécanisme par lequel le traitement probabiliste transforme le privé en ressource partagée — pourrait être politiquement réapproprié. Le défaut prismatique est ici social : il y a une aberration dans le système qui présente comme « magie algorithmique » ce qui est en réalité le produit de millions d'heures de travail humain invisibilisé.

### 4. De la gravitation à l'holographie : la Platform Physics

Le concept de platform physics, développé par le collectif New Models (Caroline Busta et Lil Internet), permet de comprendre que l'environnement numérique n'est pas un espace vide, mais un champ de forces. Lil Internet définit ces « physiques de plateforme » comme « les affordances, limitations et lois qui gouvernent la traction, la vitesse, la visibilité et même la permanence d'une idée ou d'un contenu » (NEW MODELS, 2025, ma traduction). Chaque plateforme possède un ensemble de lois codées en dur — algorithmes de tri, limitations d'interface, systèmes de récompense — qui déterminent le comportement des utilisateurs et la morphologie du contenu, comme la gravité détermine le mouvement des corps. Caroline Busta précise que « la physique des plateformes et la gamification nous obligent à nous aligner sur les intérêts de la plateforme, et toute activité allant à l'encontre de ces intérêts sera punie » (NEW MODELS, 2025, ma traduction). Cette intuition rejoint le concept de médiarchie développé par Yves Citton : les régimes médiatiques ne transmettent pas seulement des contenus, ils structurent les conditions attentionnelles et les rapports de pouvoir (CITTON, 2017). L'IA générative serait alors une nouvelle forme de médiarchie où le pouvoir s'exerce par la préemption de l'imaginable.

L'ère newtonienne (Web 2.0) était fondée sur des vecteurs de force clairs : le *like*, le partage, le lien hypertexte. Une physique de l'action et de la réaction, mécanique et prévisible. La viralité obéissait à des lois identifiables ; la polarisation était un effet calculable.

L'ère holographique (IA) marque un basculement vers une physique de la simultanéité et de l'intrication. Dans un média holographique, l'information n'est plus une ligne (un article, une photo indexée), mais un nuage de probabilités. Chaque image générée contient l'« ADN » de l'ensemble du dataset. On ne regarde plus une scène — on regarde un *vibe*, une unité esthétique où la cohérence interne du style l'emporte sur la vérité factuelle du référent.

Les médias linéaires — du livre imprimé au début du web social — se caractérisaient par la séquentialité (début, milieu, fin), la causalité (A entraîne B, les sources sont citables), l'indexation (le contenu réfère à un contexte vérifiable). Les médias holographiques dissolvent ces propriétés. Le contenu est perçu comme totalité immédiate ; l'origine des données est dissoute dans les poids du modèle ; l'information devient texture ambiante. Une image générée par Midjourney n'est pas « lue » séquentiellement ; elle frappe comme manifestation instantanée d'un style global. Le *vibe* — cette cohérence esthétique immédiate — devient le vecteur de vérité. On n'argumente plus, on résonne.

### 5. Le récit neuronal : l'occupation du possible

L'extension politique de cette physique est le concept de *Neural Narrative*. Si les médias holographiques fonctionnent par vibes et probabilités, le contrôle de la société ne passe plus par la censure — effacer un fait linéaire — mais par l'optimisation des distributions statistiques dans l'espace latent collectif.

L'occupation cognitive opère par préemption. Si un modèle est entraîné à considérer que « photographe » est statistiquement associé à « homme blanc », il devient mathématiquement difficile, voire impossible, de faire émerger une autre figure dans l'espace latent sans un effort de friction délibéré. Le biais n'est pas une erreur ponctuelle — c'est une architecture de confinement où le futur est déjà pré-calculé par les sédiments du passé.

Le pouvoir ne consiste plus à dire ce qui est vrai, mais à rendre certaines pensées statistiquement improbables. L'espace latent devient un territoire occupé : on y circule, mais les chemins les plus praticables sont ceux que le modèle a appris à privilégier. Les « queues de distribution » — les pensées rares, les formes étranges, les associations improbables — deviennent des zones de résistance, difficiles d'accès mais cruciales.


---

## IV. Thermodynamique de la culture

LAION-5B contient plus de 5,85 milliards de paires image-texte (SCHUHMANN et al., 2022) — plusieurs siècles de production photographique humaine, réduits en quelques téraoctets de poids neuronaux. *L'archive liquide* n'est pas métaphorique : c'est la dissolution effective de milliards d'images singulières dans un bain statistique commun.

Or ce bain se dégrade. Le Model Collapse décrit ce qui se passe lorsque les modèles sont entraînés sur des données synthétiques générées par des modèles précédents. Shumailov et al. parlent de « model autophagy disorder » — un désordre d'autophagie par analogie avec les maladies à prions (SHUMAILOV et al., 2023). Les modèles ont besoin de données à haute variance pour apprendre la distribution réelle du monde ; or ils tendent par nature à lisser cette distribution, à privilégier les résultats les plus probables. Après seulement cinq à sept générations d'entraînement récursif, le modèle produit des résultats « dégénérés » — une perte totale de nuance sémantique. Sept itérations suffisent pour transformer un modèle capable de produire la diversité du monde en une machine à générer du même.
Le processus opère en deux temps. D'abord, le modèle perd les « queues » de la distribution — les données rares, marginales. Les esthétiques minoritaires cessent d'être générables. Puis la variance converge vers zéro : le modèle ne produit plus qu'une seule forme, répétitive. Le liquide se fige.

Ce processus a une manifestation esthétique visible : le Yellowing. Les images générées tendent vers une teinte dominante jaune/ambre, une saturation excessive, un éclairage hyper-contrasté (HEIKKILA, 2023). Le modèle, en mélangeant toutes les couleurs pour atteindre une moyenne consensuelle, produit cette teinte boueuse — comme mélanger toutes les peintures d'une palette donne du marron. Ce contenu jauni et générique a reçu un nom : le Slop — le spam visuel de l'ère de l'IA, l'enfer statistique du « Moyen ».

Face à cette physique du lissage, la friction devient l'unique levier politique. Réintroduire ce que le système élimine : de l'opacité (revendiquer, avec Glissant, le droit de ne pas être compris par la machine), de la singularité (chercher les outliers que le modèle considère comme « bruit »), de l'écart (l'erreur volontaire, l'ambiguïté assumée). La friction n'est plus seulement une méthode de résistance — elle est la condition de possibilité d'une politique de l'image à l'ère des communs statistiques. Contre le jaunissement, contre le vidage du milieu, la dimension prismatique permettrait de décomposer le spectre plutôt que de le fondre en boue ambrée.

---

## V. Étude de cas : l'atelier comme révélateur

### 1. Le dispositif 

L'atelier s'est déroulé dans une école de photographie, avec des étudiant.e.s formées à l'indexicalité de l'image. Mais le dispositif ne se limitait pas à une initiation technique aux outils génératifs. Il s'ancrait dans une démarche de continuité rétroactive — le *retcon*, terme emprunté à la culture populaire (comic books, séries télévisées) où il désigne la réécriture a posteriori d'une continuité narrative.

Le choix de Midjourney n'était pas innocent. Il répondait à trois critères : une référence technologique (au moment de l'atelier, Midjourney représentait l'état de l'art accessible en génération d'images), une contrainte pragmatique (le serveur distant via Discord évitait les aléas des installations locales et garantissait une expérience homogène), et une valeur symptomatique (Midjourney incarne un certain *zeitgeist* — son esthétique saturée, sa facilité d'usage, sa viralité en font l'image même de ce que l'IA générative produit comme imaginaire dominant). L'outil n'était pas adopté avec enthousiasme mais observé de manière critique — comme on dissèque un spécimen pour comprendre l'écosystème qui l'a produit.

Le point de départ était le Black Mountain College (1933-1957) — ce foyer d'expérimentation totale où se sont croisés Josef et Anni Albers, John Cage, Ruth Asawa ou encore Dorothy Rockburne. Le BMC n'était pas convoqué comme monument historique à contempler, mais comme archive latente à réactiver. L'enjeu était de demander à Midjourney de « compléter » l'archive, d'imaginer des moments non documentés, des bifurcations possibles de l'utopie. C'était une tentative d'éprouver le « Ça-aurait-pu-être » au sein d'un espace latent nourri par les sédiments de l'avant-garde.

Le *retcon*, ici, n'était pas une falsification historique — il était conçu comme une diffraction temporelle : faire interférer le passé (l'archive BMC) et le présent (l'espace latent de Midjourney) pour observer les motifs d'interférence. Quelles images le modèle génère-t-il quand on lui demande de prolonger une utopie pédagogique des années 1950 ? Que révèle cette génération sur les biais du dataset, sur les sédiments esthétiques incorporés ? Le cadre proposé était celui d'un roman graphique : les étudiantes y articuleraient leurs propres questionnements à la matière historique du BMC.

### 2. La résistance de l'archive face au lissage

L'usage de Midjourney a très rapidement révélé ses limites structurelles. Confronté à la spécificité visuelle du BMC — photographies en noir et blanc, granulosité des tirages d'époque, architectures provisoires, corps en mouvement dans des espaces de travail —, l'algorithme a produit une forme de lissage entropique.

Là où l'archive du BMC est faite de grain, de friction, d'accidents et de singularités radicales, Midjourney a renvoyé des simulacres « propres », des versions esthétisées et consensuelles. La dimension expérimentale — la tension entre ordre et chaos qui caractérisait le quotidien du College — a été aplatie en *vibes* nostalgiques, proches des catégories listées dans l'Aesthetics Wiki : un « Academia » générique, un « Vintage Education » lissé. La machine n'a pas su générer de la friction ; elle a généré du décor.

Le cadre du roman graphique n'a pas été investi par les étudiant.e.s, et l'invitation à la recherche personnelle a été prise au pied de la lettre. L'usage de l'IA a transformé l'utopie expérimentale en une série de vignettes décoratives. Le principe même du prompt s'est révélé inadéquat : comment formuler en quelques mots la complexité d'un projet pédagogique qui articulait travail manuel, création artistique, gouvernance démocratique et vie communautaire ? Le prompt impose une compression sémantique qui écrase précisément ce qui faisait la singularité du BMC — son caractère total, irréductible à des mots-clés.

### 3. L'effondrement du foyer utopique

Le point de basculement le plus révélateur de l'atelier réside dans la réception du récit du BMC par les étudiant.e.s. Le concept de  "foyer utopique" — ce lieu de vie et de création totale, où l'enseignement et l'existence se confondaient — n'a pas opéré comme moteur d'imaginaire. Il a été reçu avec une forme de perplexité polie, voire de suspicion.

Pour une génération confrontée au « vidage du milieu » (*Voiding of the Mid*), l'utopie du BMC semble inaudible. La liquidité de l'IA, en rendant tout « possible » et « immédiat », dissout la notion même d'utopie — qui requiert une projection dans un futur construit par l'effort, la décision collective, le temps long. L'utopie suppose un écart entre le réel et le souhaitable ; l'espace latent, lui, ne connaît que des variations autour d'une moyenne. Quand tout est également probable, rien n'est véritablement désirable.

Les étudiant.e.s n'ont pas perçu le BMC comme un modèle à suivre ou un imaginaire à prolonger, mais comme un ensemble d'archives lointaines qu'il s'agissait de « traiter » — au sens technique du terme. La relation au passé a été instrumentale, non spirituelle. C'est ici que la dimension cosmotechnique de Yuk Hui trouve sa pertinence : le lien entre le geste technique et un ordre du monde a fait défaut. L'archive a été manipulée, mais non habitée.

Il serait trop simple de conclure à un « déficit d'utopie » chez les étudiantes. Ce qui s'est manifesté est plus subtil : une méfiance envers les grands récits d'émancipation collective, une préférence pour les tactiques individuelles de survie (au sens de Michel de Certeau), une difficulté à projeter un commun désirable. Le Black Mountain College, avec son optimisme moderniste et sa foi dans la transformation sociale par l'art, appartient à un régime d'espérance qui ne fait plus évidence. L'atelier a révélé ce hiatus générationnel — sans le résoudre.

**4. La crise de l'intentionnalité : du clic au prompt**

Au-delà du dispositif BMC, l'atelier a confirmé une crise de l'intentionnalité propre à l'usage des outils génératifs. Les étudiant.e.s sont formées à la décision de l'instant — le fameux « clic », ce moment où l'œil, le corps et l'appareil convergent pour fixer une fraction de seconde. Henri Cartier-Bresson parlait de l'« instant décisif » ; Robert Frank de la capacité à « voir ce que les autres ne voient pas ». Toute la tradition documentaire repose sur cette économie de la rareté : on ne peut pas tout photographier, il faut choisir.

Face à l'IA générative, cette économie s'inverse. Le « clic » devient le « prompt » — et le prompt n'est pas une décision instantanée mais une hyper-décision différée et itérative. On peut tout demander, tout reformuler, tout régénérer. L'abondance remplace la rareté. Paradoxalement, cette inflation des possibles ne libère pas — elle peut paralyser.

Ce que l'atelier a révélé, c'est que l'hyper-choix produit un effondrement de la capacité décisionnelle. Face à l'infini liquide des variations possibles, les étudiantes ont majoritairement opté pour deux formes de repli. D'une part, le recours à des esthétiques déjà identifiées (le « Liminal », le « Cottagecore »), des représentations littérales et descriptives (« une femme dans une forêt »), rarement des images cinétiques — c'est-à-dire prises dans un récit intentionnel, orientées par un projet. D'autre part, et de manière plus frappante encore, un retour obsessionnel à l'autoportrait — comme si, face à la dissolution des critères, le seul ancrage restant était le propre visage.

**5. L'obsession du self : le miroir statistique**

Cette tendance à l'autoreprésentation mérite qu'on s'y arrête. Elle n'est pas propre à l'atelier : elle traverse l'ensemble des pratiques photographiques que l'on observe dans les écoles d'art, exacerbée par les réseaux sociaux et la culture du selfie. Mais l'IA générative lui donne une dimension nouvelle et troublante.

Quand un.e étudiant.e demande à Midjourney de générer « moi dans le style de... », elle ne produit pas une image d'elle-même — elle produit une moyenne statistique de ce que le modèle associe à son prompt. Le visage généré n'est pas le sien : c'est une approximation vectorielle, un composite de millions de visages encodés dans l'espace latent. L'autoportrait génératif est un miroir déformant qui renvoie non pas le sujet, mais ce que le dataset « pense » du sujet.

Or cette déformation est rarement perçue comme telle. Les étudiantes ont souvent exprimé une satisfaction devant ces images — une version « améliorée », « idéalisée » d'elles-mêmes. Le modèle, en lissant les singularités vers la moyenne esthétique, produit des visages conformes aux standards de beauté encodés dans ses données d'entraînement. L'autoportrait génératif n'est pas une exploration de soi — c'est une soumission à la norme statistique déguisée en expression personnelle.

Cette obsession du *self* révèle en creux l'absence de projet. Quand tout est possible mais que rien ne résiste, le sujet se replie sur la seule certitude qui lui reste : sa propre image. Mais cette image, médiatisée par l'espace latent, n'est déjà plus la sienne, et d'une crise esthétique peut amener une déstabilisation difficile à surmonter pour les étudiant.e.s.

**6. Du témoin au curateur : la désincarnation du geste**

Dans la tradition documentaire, le photographe est un témoin : il est présent sur le lieu, il regarde à travers l'objectif, il porte physiquement l'appareil. Son corps est engagé dans la production de la preuve. Dorothea Lange marchait dans les camps de migrants ; Robert Capa courait sous les balles ; Nan Goldin vivait parmi ses sujets. La photographie documentaire est une pratique incarnée.

L'IA générative opère une désincarnation radicale. L'étudiante ne regarde plus à travers l'objectif — elle trie des flux sur un écran. Elle ne produit plus la preuve — elle sélectionne parmi des probabilités. Le geste créatif se déplace de la production vers la curation. Or le « tout est possible » empêche la formation de la décision. Quand cinq milliards d'images sont compressées dans un espace vectoriel, sur quel critère en choisir une plutôt qu'une autre ? La tradition photographique offrait des critères : la lumière, le cadre, le moment, la relation au sujet. L'IA générative dissout ces critères dans la texture statistique du modèle.

Dans le cas du BMC, cette désincarnation était d'autant plus problématique que le College était précisément un lieu où le corps était central : travail agricole, danse, construction des bâtiments, repas collectifs. Tenter de prolonger cette archive par le prompt, c'était nier la dimension corporelle qui en faisait la singularité — et risquer de substituer à l'utopie incarnée une nostalgie désincarnée, filtrée par les biais esthétiques du modèle.

### 6. L'échec du glitch : l'accident neutralisé

Face à cette liquidité, certaines étudiant.e.s ont tenté une stratégie de résistance : « hacker » l'IA pour retrouver de l'accident, du bruit, de l'imprévu. Le glitch — cette erreur visuelle qui trahit la machine — a longtemps fonctionné comme preuve d'humanité par défaut : là où la machine échoue, l'humain peut s'engouffrer.

Mais cette stratégie s'est révélée impraticable. Les modèles génératifs actuels sont précisément optimisés pour éliminer le glitch. Le lissage, l'hyper-résolution, la cohérence sémantique : tout le travail d'ingénierie vise à effacer les traces de la machine. Le glitch, quand il survient (mains à six doigts, textes illisibles), n'est pas une ouverture créative — c'est un bug que la prochaine version du modèle corrigera.

L'esthétique de l'accident, qui avait nourri tout un pan de l'art numérique (du *glitch art* au *datamoshing*), se trouve ainsi neutralisée. La friction n'émerge plus spontanément de la confrontation avec la machine. Elle doit être réintroduite délibérément — ce qui suppose une conscience critique que l'outil génératif, par sa fluidité même, tend à dissoudre.

### 7. Le défaut prismatique en acte

Cet « échec » — s'il faut l'appeler ainsi — est en réalité le résultat le plus précieux de l'atelier. Il manifeste le défaut prismatique dans sa triple dimension :

L'outil devient un filtre réducteur. Midjourney a agi comme un prisme défectueux qui écrase la pluralité radicale du Black Mountain pour la ramener à la moyenne statistique. Les singularités de l'archive — le grain, la tension, l'expérimentation — ont été lissées en vignettes décoratives. L'outil ne sait pas diffracter ; il sait seulement moyenner.

La méthode nécessite une canalisation politique. Le *retcon*, sans un engagement du corps et une « canalisation politique » explicite, n'est qu'une manipulation de pixels sans épaisseur mémorielle. Il reste en surface — il est remix, pas réécriture. La continuité rétroactive suppose une prise de position : pourquoi réactiver cette archive ? Pour qui ? Contre quoi ? Sans ces questions, le *retcon* n'est que du traitement d'image.

L'utopie du BMC s'est liquéfiée parce que l'IA ne sait pas générer de l'« inattendu radical » ; elle ne sait que générer du « probable confortable ». L'utopie, par définition, est ce qui n'a pas (encore) de lieu — ce qui est statistiquement improbable. L'espace latent, optimisé pour le vraisemblable, ne peut que rater l'utopie.

Ce triple défaut dessine, en creux, ce que serait une archive prismatique du Black Mountain College : une archive qui préserverait le grain contre le lissage, qui articulerait les gestes techniques à un projet politique explicite, qui maintiendrait l'écart utopique contre la moyenne. L'atelier n'a pas produit cette archive — mais il a révélé les conditions de sa possibilité.

C'est là, précisément, sa réussite pédagogique. Les étudiant.e.s n'ont pas appris à « utiliser Midjourney » — elles ont appris à le lire, à en identifier les régimes de visibilité et d'invisibilité, à reconnaître dans le jaunissement et le lissage les symptômes d'une économie politique de l'image. Ils-Elles ont fait l'expérience, dans leur propre pratique, de la différence entre générer et créer, entre sélectionner et décider, entre le flux et le geste. Plusieurs ont explicitement choisi, à l'issue de l'atelier, de réintroduire la friction dans leur travail — retour à l'argentique, refus du post-traitement, attention renouvelée au hors-champ. D'autres ont entrepris de documenter les « ratés » du modèle comme autant de révélateurs de ses présupposés. L'outil, observé de manière critique, est devenu un diagnostic : non pas un moyen de produire des images, mais un analyseur des conditions contemporaines de leur production. En ce sens, l'atelier a accompli ce que le Black Mountain College lui-même pratiquait : faire de l'échec apparent le lieu d'un apprentissage réel, transformer l'obstacle en méthode.


---

## VI. Vers une écologie de la friction ## 

### 1. Le défaut prismatique comme diagnostic ###

*L'archive liquide* n'est pas un horizon indépassable. Elle est le résultat d'un défaut d'ajustement spécifique : l'absence d'une dimension politique permettant la recombinaison des perspectives. Le commun statistique existe — il est même massif, planétaire, en expansion constante. Mais il est non gouverné, livré aux forces de l'optimisation et de l'entropie.

La liquidité désigne cette perte d'épaisseur institutionnelle et de régulation collective. Ce n'est pas sa fluidité en soi qui importe, mais le fait qu'elle ne prend pas forme — faute d'un plan d'agrégation et de résistance. Le danger n'est pas la liquidité mais la planéité : tout devient flux, mais aucun flux n'a de canalisation politique.

*L'archive prismatique* viserait une régulation énergétique du sens : rendre visibles et gouvernables les interférences entre couches — données, affects, histoires. Elle traiterait chaque perspective non comme un bruit à moyenner mais comme une dimension à préserver. Concrètement, cela implique de penser des protocoles de contribution et de recombinaison — des règles d'usage du commun statistique qui ne soient pas dictées uniquement par les propriétaires des modèles.

### 2. La technique comme triple régime : traçabilité, transmission, bricolage ###

Mais *l'archive prismatique* n'est pas seulement un concept critique — elle est elle-même une technique. Et toute technique est simultanément liée à trois dimensions irréductibles.

La dimension de traçabilité : toute technique observe, enregistre, capture. Le silex qui taille laisse une trace ; l'écriture fixe la parole ; l'algorithme vectorise le geste. L'archive prismatique n'échappe pas à cette logique : elle rend visible les biais, les sources, les chaînes causales — y compris ce qui voudrait rester opaque.

La dimension de transmission : toute technique entretient un rapport au sens qui excède sa fonction instrumentale. Yuk Hui nomme cosmotechnique cette articulation entre un ordre technique et un ordre cosmologique (HUI, 2016). L'IA générative encode une cosmologie : celle de la probabilité comme horizon de l'être, de la moyenne comme norme. L'archive prismatique doit assumer sa propre dimension transmissive : quelle relation au temps, à la mémoire, à l'altérité propose-t-elle ?

La dimension du bricolage : toute technique est appropriation, détournement, improvisation. Michel de Certeau a montré comment les usagers ordinaires « braconnent » dans les dispositifs techniques, inventant des tactiques qui détournent les stratégies des pouvoirs (DE CERTEAU, 1980). L'archive prismatique ne prétend pas construire un système parfait ex nihilo — elle recompose avec les moyens du bord des espaces de résistance et de création.

Reconnaître ces trois dimensions, c'est refuser deux naïvetés symétriques : la technophilie qui voudrait une technique émancipatrice « pure » de tout rapport au pouvoir ; la technophobie qui réduirait toute technique à un instrument de domination. L'archive prismatique est une technique située et individée — elle doit s'individuer dans un contexte spécifique, avec ses acteurs, ses enjeux, ses contraintes (SIMONDON, 1958/2012).

### 3. Le droit à l'opacité ###

Édouard Glissant offre un concept décisif pour penser la résistance. Dans Poétique de la relation, il écrit : « Consentir à l'opacité de l'Autre, c'est déjà l'aimer. » La transparence est une exigence occidentale de réduction de l'Autre à une clarté compréhensible, maîtrisable, assimilable. Contre cette volonté de tout rendre lisible, Glissant revendiquait le droit d'être opaque — de ne pas être entièrement compris, traduit, vectorisé (GLISSANT, 1990).

Appliqué à l'IA générative, ce concept devient stratégie de résistance. Contre la volonté du modèle de tout vectoriser, on peut revendiquer le droit d'être illisible pour l'algorithme. Cette résistance dispose aujourd'hui d'outils concrets. Des chercheurs ont développé Glaze et Nightshade — des systèmes qui appliquent une couche de bruit invisible à l'image, imperceptible pour l'œil humain mais qui perturbe l'apprentissage de l'IA. L'artiste peut ainsi « empoisonner » ses propres données, empêchant le modèle de copier son style.

Cela passe aussi par des gestes moins techniques : *prompts* qui visent les bords de la distribution plutôt que le centre ; préservation d'espaces non-indexés (la « forêt sombre » de la théorie Dark Forest) ; documentation des processus plutôt que des seuls résultats.

## VII. Pédagogie prismatique ## 

### 1. L'enquête comme forme de vie ### 

Imaginer une pédagogie de l'image en 2025 exige de ne plus enseigner l'IA comme un simple « outil de création de plus », mais comme un nouveau régime de vérité et de gouvernementalité. L'enjeu se déplace : il ne s'agit plus seulement d'apprendre à faire des images, mais de comprendre comment elles nous font.

John Dewey, dans Democracy and Education (1916), développe une conception de l'éducation comme reconstruction continue de l'expérience. Apprendre, ce n'est pas recevoir passivement un savoir constitué ; c'est s'engager dans une enquête qui transforme simultanément le sujet et son environnement. La confrontation avec l'IA générative doit être l'occasion d'une telle enquête — sur l'outil, le dataset, les biais, les effets sociaux, et la transformation du sujet qui s'y engage.

Paulo Freire, dans Pédagogie des opprimés (1968), nomme conscientisation le passage d'une conscience naïve — qui subit le monde comme donné naturel — à une conscience critique qui perçoit les structures d'oppression. Appliquée à l'IA, la conscientisation exige de passer d'un usage naïf — où l'on « prompte » sans interroger la boîte noire — à une conscience des conditions de production de l'image. Qui a collecté les données ? Quels travailleurs invisibles ont annoté les images ? Quels biais sont encodés dans l'espace latent ?
Jacques Rancière, dans Le Maître ignorant (1987), radicalise la question. L'émancipation intellectuelle suppose un postulat d'égalité des intelligences : l'élève n'est pas un incapable à qui le maître transmettrait un savoir, mais un égal qui peut apprendre par lui-même. Le prompt, tel qu'il est généralement enseigné, n'est pas émancipateur : il maintient l'opacité de la boîte noire. L'émancipation supposerait de saisir la logique du modèle, ses limites, ses biais — de comprendre que l'on ne crée pas une image ex nihilo, mais que l'on actualise une coordonnée statistique dans un espace de probabilités.

### 2. Culture technique et pharmacologie ###

Gilbert Simondon, dans Du mode d'existence des objets techniques (1958), diagnostique une « aliénation technique » de la culture contemporaine. La machine est perçue soit comme esclave utile, soit comme menace — jamais comme réalité ayant son propre mode d'existence. Cette méconnaissance produit une minorité technique : nous utilisons des machines sans comprendre leur genèse ni leur fonctionnement.

Pour l'IA générative, l'aliénation se manifeste dans le discours magique : « intelligence » artificielle, « créativité » de la machine, « hallucinations » du modèle. Ces métaphores anthropomorphiques occultent la réalité technique : des opérations statistiques sur des distributions de probabilités. La culture technique consisterait à dissiper cette magie — non pour désenchanter le monde, mais pour rendre possible une relation adulte avec l'outil.

Bernard Stiegler, héritier critique de Simondon, développe le concept de pharmacologie : toute technique est un pharmakon, à la fois poison et remède. L'IA générative démocratise la production d'images mais elle prolétarise le savoir-voir ; elle ouvre des possibles mais elle lisse le sensible. Comme le note Pierre Cassou-Noguès, ces technologies « fonctionnent pour le moment comme des instruments qui privent les cerveaux de leur conscience, c'est-à-dire de leur rapport au savoir ». La pédagogie doit être déprolétarisante — elle doit reconstruire les savoirs que la technique tend à dissoudre.

### 3. Technodiversité et convivialité ###

Yuk Hui, dans ses travaux sur la technodiversité, critique l'uniformisation technologique mondiale. La modernisation a imposé une conception unique de la technique, effaçant les cosmotechniques locales — les manières dont chaque culture a articulé technique et cosmos (HUI, 2016). Les grands modèles (Midjourney, DALL-E, Stable Diffusion) sont des infrastructures uniformisantes : ils imposent une esthétique moyenne, un vibe globalisé, une vision du monde encodée dans les datasets occidentaux.

La technodiversité consisterait à développer des modèles situés — entraînés sur des archives locales, reflétant des esthétiques spécifiques, gouvernés par des communautés particulières. Un collectif de photographes qui entraîne un modèle sur ses propres archives, avec ses propres annotations, produit une cosmotechnique locale — une manière de faire des images qui résiste à l'uniformisation de l'espace latent globalisé.

Ivan Illich, dans La Convivialité (1973), distingue les outils conviviaux — qui augmentent l'autonomie de l'utilisateur — des outils manipulatoires — qui créent de la dépendance et confisquent les savoirs. L'IA générative, dans son état actuel, est largement manipulatoire. Une pédagogie illichienne viserait à identifier les conditions d'une IA conviviale : transparente, appropriable, gouvernable par ses utilisateurs.

### 4. Méthodes et postures ###

Ces fondements se traduisent en pratiques concrètes. La cartographie de l'espace latent : visualiser les « paysages » de l'IA, repérer les zones de vide — les silences statistiques — là où l'IA ne sait rien produire. Le *reverse prompting* : plutôt que chercher l'image parfaite, chercher l'image qui « craque », pousser le modèle vers ses limites pour analyser pourquoi il produit systématiquement du « jaune » ou du « lisse ». Les micro-datasets souverains : collecter quelques centaines d'images sur une thématique située, les annoter, entraîner un petit modèle (LoRA), observer la différence de « vibe » avec l'IA généraliste — un exercice de technodiversité concrète. La traçabilité : exiger que chaque image puisse être « diffractée », documenter les processus plutôt que les seuls résultats. L'éthique de la ressource : Jussi Parikka rappelle que le « cloud » dissimule une géologie lourde — chaque image générée a un coût en eau, en minerais, en électricité. La pédagogie de l'image devient pédagogie de la Terre.

Dans ce cadre, l'enseignant ne peut plus être celui qui transmet un savoir-faire stabilisé. Il devient le curateur des tensions entre *l'archive liquide* et le prisme politique — celui qui organise les conditions de l'enquête deweyenne, qui pose les problèmes et accompagne sans diriger. Il est le « maître ignorant » de Rancière, le passeur de la culture technique simondonienne. Il est aussi celui qui maintient la mémoire de ce que l'IA dissout : le corps photographique, le regard incarné, la décision de l'instant. L'enseignant de l'ère algorithmique transmet un savoir-naviguer et un savoir-résister — naviguer dans l'espace latent comme dans un territoire occupé, résister à la liquéfaction en réintroduisant de la friction, de l'opacité, de la singularité.

### Coda : Récursivité des motifs ###

Ce texte a fait circuler quatre motifs à différentes échelles : la liquidité, l'entropie, la friction, le prisme. Ils sont revenus dans chaque section, sous des angles différents — généalogique, matériel, économique, thermodynamique, pédagogique. Cette récurrence tente de performer, dans l'écriture même, ce que serait une *archive prismatique* : chaque passage par le même concept l'éclaire autrement, le maintient en suspension productive plutôt que de le fixer en définition.

Ces quatre motifs forment un système dynamique où chacun appelle les autres. La liquidité sans prisme devient entropie. L'entropie sans friction devient *slop*. La friction sans prisme devient refus stérile. Le prisme sans acceptation de la liquidité devient nostalgie. Il me semble que c'est dans leur articulation que se joue la possibilité d'une culture visuelle à l'ère des *communs statistiques*.

L'atelier a donné chair pédagogique à ces motifs abstraits. La crise de l'intentionnalité, le passage du témoin au curateur, l'obsession du *self*, l'échec du *glitch* : autant de symptômes locaux d'une mutation globale. Ce qui s'est joué dans cette salle de classe est ce qui se joue partout où des humains formés à des traditions visuelles se trouvent confrontés à des machines qui dissolvent les conditions mêmes de ces traditions.

La pédagogie prismatique n'est pas seulement une méthode. Pour les enseignant.e.s des écoles d'art elle s'enracine dans l'enquête deweyenne, la conscientisation freirienne, l'émancipation ranciérienne, la culture technique simondonienne, la pharmacologie stieglérienne, la technodiversité de Yuk Hui, la convivialité illichienne, et bien d'autres méthodes encore. Cette constellation n'est pas un programme à appliquer — c'est une boîte à outils pour l'enquête. Chaque contexte appellera ses propres articulations, ses propres inventions.

L'archive ne se liquéfie que lorsqu'elle perd sa dimension politique. Lui rendre cette dimension, c'est apprendre à diffracter — et à revendiquer, avec Glissant, le droit de ne pas être compris par la machine.

---

## Références

AESTHETICS WIKI. *Fandom*, 2024. https://aesthetics.fandom.com

ALEMOHAMMAD, Sina, CASCO-RODRIGUEZ, Josue, LUZI, Lorenzo, et al. « Self-Consuming Generative Models Go MAD ». *arXiv preprint*, 2023. arXiv:2307.01850.

AMORALES, Carlos. *Liquid Archive*. Projet artistique, 1998-2009. https://www.carlosamorales.com

AMRUTE, Sareeta. *Encoding Race, Encoding Class: Indian IT Workers in Berlin*. Durham (NC): Duke University Press, 2016.

BARAD, Karen. *Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning*. Durham (NC): Duke University Press, 2007.

BARTHES, Roland. *La Chambre claire : note sur la photographie*. Paris : Gallimard/Seuil, 1980.

BAUMAN, Zygmunt. *Liquid Modernity*. Cambridge: Polity Press, 2000.

BAUMAN, Zygmunt. *Liquid Times: Living in an Age of Uncertainty*. Cambridge ; Malden (MA): Polity Press, 2007.

BENJAMIN, Walter. « L'Œuvre d'art à l'époque de sa reproductibilité technique » [1935]. In: *Œuvres III*. Trad. Maurice de Gandillac, Rainer Rochlitz et Pierre Rusch. Paris : Gallimard, 2000.

BENJAMIN, Walter. « Petite histoire de la photographie » [1931]. In: *Œuvres II*. Trad. Maurice de Gandillac, Rainer Rochlitz et Pierre Rusch. Paris : Gallimard, 2000.

BRIDLE, James. « The New Aesthetic ». *Tumblr*, 2011-2013. https://new-aesthetic.tumblr.com

BRIDLE, James. *New Dark Age: Technology and the End of the Future*. London: Verso, 2018.

CASSOU-NOGUÈS, Pierre. « Désynchronisation des consciences et travail zombie ». *Le Portique*, 2024, n° 43.

CHATONSKY, Grégory. *La Quatrième Mémoire*. Installation, 2025. Présentée dans l'exposition « Le monde selon l'IA », Jeu de Paume, Paris.

CITTON, Yves. *Pour une écologie de l'attention*. Paris : Seuil, 2014.

CITTON, Yves. *Médiarchie*. Paris : Seuil, 2017.

CRAWFORD, Kate. *Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence*. New Haven: Yale University Press, 2021.

CUBITT, Sean. *Finite Media: Environmental Implications of Digital Technologies*. Durham (NC): Duke University Press, 2017.

DE CERTEAU, Michel. *L'Invention du quotidien. 1. Arts de faire*. Paris : Union Générale d'Éditions, 1980. [Rééd. Paris : Gallimard, coll. « Folio essais », 1990.]

DEWEY, John. *Democracy and Education: An Introduction to the Philosophy of Education*. New York: Macmillan, 1916.

DEWEY, John. *Art as Experience*. New York: Minton, Balch & Company, 1934.

DEWEY, John. *Experience and Education*. New York: Macmillan, 1938.

DÍAZ, Eva. *The Experimenters: Chance and Design at Black Mountain College*. Chicago: University of Chicago Press, 2015.

DUBERMAN, Martin. *Black Mountain: An Exploration in Community*. New York: E.P. Dutton, 1972. [Rééd. Northwestern University Press, 2009.]

EDWARDS, Benj. « The AI "Yellowing" Problem ». *Ars Technica*, 2024.

FAROCKI, Harun. « Phantom Images ». *Public*, 2004, n° 29, p. 12-22.

FLUSSER, Vilém. *Towards a Philosophy of Photography*. London: Reaktion Books, 2000. [Éd. fr. : *Pour une philosophie de la photographie*. Trad. Marc Partouche. Paris : Circé, 1996.]

FONTCUBERTA, Joan. *La fureur des images : notes sur la post-photographie*. Paris : Galilée, 2017.

FOUCAULT, Michel. *Surveiller et punir. Naissance de la prison*. Paris : Gallimard, 1975.

FREIRE, Paulo. *Pédagogie des opprimés*. Trad. NSIAL. Paris : Maspero, 1974. [Éd. orig. : *Pedagogia do oprimido*. Rio de Janeiro: Paz e Terra, 1968.]

GLISSANT, Édouard. *Poétique de la relation*. Paris : Gallimard, 1990.

GLISSANT, Édouard. *Traité du Tout-Monde*. Paris : Gallimard, 1997.

GRAY, Mary L. et SURI, Siddharth. *Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass*. Boston: Houghton Mifflin Harcourt, 2019.

HARAWAY, Donna. « Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective ». *Feminist Studies*, 1988, vol. 14, n° 3, p. 575-599.

HARAWAY, Donna. « A Cyborg Manifesto ». In: *Simians, Cyborgs and Women: The Reinvention of Nature*. New York: Routledge, 1991.

HARRIS, Mary Emma. *The Arts at Black Mountain College*. Cambridge (MA): MIT Press, 1987.

HEIKKILA, Melissa. « Why Does AI Art Look So Yellow? ». *MIT Technology Review*, 2023.

HUI, Yuk. *The Question Concerning Technology in China: An Essay in Cosmotechnics*. Falmouth: Urbanomic, 2016.

ILLICH, Ivan. *La Convivialité*. Paris : Seuil, 1973.

LÉVI-STRAUSS, Claude. *La Pensée sauvage*. Paris : Plon, 1962.

MANOVICH, Lev. *AI Aesthetics*. Moscow: Strelka Press, 2018.

MOLESWORTH, Helen (dir.). *Leap Before You Look: Black Mountain College 1933-1957*. Catalogue d'exposition. Boston: Institute of Contemporary Art ; New Haven: Yale University Press, 2015.

NEW MODELS (Caroline BUSTA et Lil INTERNET). « Platform Physics ». *New Models Podcast*, 2020. https://newmodels.io

NEW MODELS. « Holographic Media ». *New Models Podcast*, 2021. https://newmodels.io

NEW MODELS. « Artist Profile: New Models ». Do Not Research, octobre 2025. URL : https://donotresearch.substack.com/p/artist-profile-new-models

NOBLE, Safiya Umoja. *Algorithms of Oppression: How Search Engines Reinforce Racism*. New York: NYU Press, 2018.

PAGLEN, Trevor. « Invisible Images (Your Pictures Are Looking at You) ». *The New Inquiry*, 2016.

PARIKKA, Jussi. *A Geology of Media*. Minneapolis ; London: University of Minnesota Press, 2015.

PASQUINELLI, Matteo et JOLER, Vladan. « The Nooscope Manifested: AI as Instrument of Knowledge Extractivism ». *AI & Society*, 2021, vol. 36, n° 4, p. 1263-1280.

RANCIÈRE, Jacques. *Le Maître ignorant : cinq leçons sur l'émancipation intellectuelle*. Paris : Fayard, 1987.

RANCIÈRE, Jacques. *Le Partage du sensible : esthétique et politique*. Paris : La Fabrique, 2000.

SCHOLZ, Trebor (dir.). *Digital Labor: The Internet as Playground and Factory*. New York: Routledge, 2013.

SCHUHMANN, Christoph, BEAUMONT, Romain, VENCU, Richard, et al. « LAION-5B: An Open Large-Scale Dataset for Training Next Generation Image-Text Models ». *arXiv preprint*, 2022. arXiv:2210.08402.

SHUMAILOV, Ilia, SHUMAYLOV, Zakhar, ZHAO, Yiren, GALES, Mark, PAPERNOT, Nicolas et ANDERSON, Ross. « The Curse of Recursion: Training on Generated Data Makes Models Forget ». *arXiv preprint*, 2023. arXiv:2305.17493.

SIMONDON, Gilbert. *Du mode d'existence des objets techniques*. Paris : Aubier, 1958. [Rééd. Paris : Aubier, 2012.]

SOMAINI, Antonio (commissaire). *Le monde selon l'IA*. Exposition, Jeu de Paume, Paris, 11 avril – 21 septembre 2025.

SONTAG, Susan. *On Photography*. New York: Farrar, Straus and Giroux, 1977. [Éd. fr. : *Sur la photographie*. Trad. Philippe Blanchard. Paris : Seuil, 1979.]

STAROSIELSKI, Nicole. *The Undersea Network*. Durham (NC): Duke University Press, 2015.

STEYERL, Hito. *Duty Free Art: Art in the Age of Planetary Civil War*. London: Verso, 2017.

STIEGLER, Bernard. *La technique et le temps 3. Le temps du cinéma et la question du mal-être*. Paris : Galilée, 2001.

STIEGLER, Bernard. *Prendre soin. De la jeunesse et des générations*. Paris : Flammarion, 2008.

WAGON, Gwenola et DEGOUTIN, Stéphane. *Globodrome*. Paris : B42, 2018. [Projet initié en 2013.]

WAGON, Gwenola et DEGOUTIN, Stéphane. *World Brain*. Film documentaire, 2015. 75 min.

---
